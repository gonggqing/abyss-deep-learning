#!/usr/bin/env python3
import argparse
import os
import sys

import numpy as np
import PIL.Image
import tensorflow as tf
from pycocotools.coco import COCO
from tensorflow.contrib.tensorboard.plugins import projector
from abyss_deep_learning.keras.tensorboard import produce_embeddings_tsv
import json

from abyss_deep_learning.utils import imread

def images_to_sprite(data):
    """Creates the sprite image along with any necessary padding

    Args:
      data: NxHxW[x3] tensor containing the images.

    Returns:
      data: Properly shaped HxWx3 image with any necessary padding.
    """
    if len(data.shape) == 3:
        data = np.tile(data[..., np.newaxis], (1, 1, 1, 3))
    data = data.astype(np.float32)
    min = np.min(data.reshape((data.shape[0], -1)), axis=1)
    data = (data.transpose(1, 2, 3, 0) - min).transpose(3, 0, 1, 2)
    max = np.max(data.reshape((data.shape[0], -1)), axis=1)
    data = (data.transpose(1, 2, 3, 0) / max).transpose(3, 0, 1, 2)
    # Inverting the colors seems to look better for MNIST
    #data = 1 - data

    n = int(np.ceil(np.sqrt(data.shape[0])))
    padding = ((0, n ** 2 - data.shape[0]), (0, 0), (0, 0)) + ((0, 0), ) * (data.ndim - 3)
    data = np.pad(data, padding, mode='constant', constant_values=0)
    # Tile the individual thumbnails into an image.
    data = data.reshape(
        (n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))
    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])
    data = (data * 255).astype(np.uint8)
    return data


def save_embeddings(log_dir, features, labels=None, sprite=None, sprite_shape=None):
    metadata = os.path.join(log_dir, 'metadata.tsv')
    features = tf.Variable(features, name='features')

    produce_embeddings_tsv(os.path.join(log_dir, 'metadata.tsv'), headers=['label'], labels=labels)

    #if labels is not None:
    #    with open(metadata, 'w') as metadata_file:
    #        for row in labels:
    #            metadata_file.write('%d\n' % row)
    if sprite is not None:
        PIL.Image.fromarray(sprite).save(os.path.join(log_dir, 'sprite.png'))
    with tf.Session() as sess:
        saver = tf.train.Saver([features])
        sess.run(features.initializer)
        saver.save(sess, os.path.join(log_dir, 'features.ckpt'))

        config = projector.ProjectorConfig()
        # One can add multiple embeddings.
        embedding = config.embeddings.add()
        embedding.tensor_name = features.name
        if labels is not None:
            # Link this tensor to its metadata file (e.g. labels).
            embedding.metadata_path = metadata
        if sprite is not None:
            embedding.sprite.image_path = os.path.join(log_dir, 'sprite.png')
            embedding.sprite.single_image_dim.extend(sprite_shape)
        # Saves a config file that TensorBoard will read during startup.
        projector.visualize_embeddings(tf.summary.FileWriter(log_dir), config)

def say(*args):
    print(*args, file=sys.stderr)

def image_arg_to_coco(image_arg):
    """Gets the image argument and converts it to a COCO format dataset.
    The image argument can either be a coco file, or a sequence of images.

    Args:
        image_arg (list): The image arguments

    Returns:
        COCO: The coco dataset

    """
    if image_arg[0].endswith('.json'):
        coco = COCO(image_arg[0])
    else:
        image_list = []
        for ipath in image_arg:
            with PIL.Image.open(filepath) as img:
                width, height = img.size
            image = {
                'filename': os.path.basename(ipath),
                'path': ipath,
                'height': height,
                'width': width
            }
            image_list.append(image)
        dataset = {'images': image_list}
        coco = COCO()
        coco.dataset = dataset
        coco.createIndex()
    return coco

def main(args):
    say("Loading COCO")
    coco = image_arg_to_coco(args.images)
    say("Loading images")
    images = np.array([
            imread(
                image["path"],
                size=args.image_size, dtype=np.uint8)
            for image in coco.loadImgs(coco.getImgIds())], dtype=np.uint8)
    say("Creating tumbnails of {:d} images".format(len(images)))
    thumbs = np.array([
        np.array(PIL.Image.fromarray(image).resize(args.thumb_size))
        for image in images], dtype=np.uint8)
    images = images.astype(np.float32) / 127.5 - 1

    say("Loading model...")
    if args.model_definition is not None:
        model = tf.keras.models.model_from_json(open(args.model_definition).read(),custom_objects = {'tf': tf})
        model.load_weights(args.model_weights)
    else:
        model = tf.keras.models.load_model(args.model_weights, custom_objects = {'tf': tf})

    say("Model loaded!")

    layer_name = args.layer_name
    if layer_name is not None:
        output = model.get_layer(layer_name).output
        model = tf.keras.models.Model(inputs=model.input,
                                  outputs=output)
    say("Predicting...")
    features = model.predict(images)
    features = np.mean( np.mean(features, axis=1), axis=1 ) # compute the mean embedding vector across all pixels

    say("Saving embeddings...")
    save_embeddings(
        args.tensorboard_dir, features,
        labels=np.zeros((len(images),1)), sprite=images_to_sprite(thumbs), sprite_shape=args.thumb_size)

    say('Done!')

    say("To view embeddings, launch tensorboard with the command 'tensorboard --logdir %s'" %args.tensorboard_dir)

def get_args(cmd_line=None):
    '''Get args from the command line args'''
    parser = argparse.ArgumentParser(
        description="Cluster images using various algorithms and display the results on the TensorBoard Projector")
    parser.add_argument(
        "tensorboard_dir", help="Where to write the tensorboard embeddings")
    parser.add_argument("images", nargs='+', help="images or a COCO JSON to cluster")
    parser.add_argument(
        "--image-size", help="CSV height, width to load and resize each image to feed into the network", default=None)
    parser.add_argument(
        "--thumb-size", default='256,256', help="CSV height, width for the TensorBoard thumbnails")
    parser.add_argument(
        "--image-dir", help="The directory to relatively path the images with (COCO only)")
    parser.add_argument(
        "--model-definition", help="The model definition .json")
    parser.add_argument("--model-weights", help="path to model weights file, saved in keras .h5 format", required=True)
    parser.add_argument("--layer-name", help="The layer to calculate the embeddings on, e.g. 'decoder_conv1_pointwise_BN'", required=True)
    args = parser.parse_args(args=cmd_line)
    if args.image_size is not None:
        args.image_size = tuple(int(i) for i in args.image_size.split(','))
    args.thumb_size = tuple(int(i) for i in args.thumb_size.split(',')) \
        if args.thumb_size else tuple(i // 2 for i in args.image_size)
    return args

if __name__ == "__main__":
    main(get_args())
