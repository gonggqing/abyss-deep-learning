#!/usr/bin/env python3
import argparse
import os
import sys

import numpy as np
import PIL.Image
import tensorflow as tf
from pycocotools.coco import COCO
from tensorflow.contrib.tensorboard.plugins import projector
from abyss_deep_learning.keras.tensorboard import produce_embeddings_tsv
import json
import pandas as pd
from tqdm import tqdm

from abyss_deep_learning.utils import imread

def images_to_sprite(data):
    """Creates the sprite image along with any necessary padding

    Args:
      data: NxHxW[x3] tensor containing the images.

    Returns:
      data: Properly shaped HxWx3 image with any necessary padding.
    """
    if len(data.shape) == 3:
        data = np.tile(data[..., np.newaxis], (1, 1, 1, 3))
    data = data.astype(np.float32)
    min = np.min(data.reshape((data.shape[0], -1)), axis=1)
    data = (data.transpose(1, 2, 3, 0) - min).transpose(3, 0, 1, 2)
    max = np.max(data.reshape((data.shape[0], -1)), axis=1)
    data = (data.transpose(1, 2, 3, 0) / max).transpose(3, 0, 1, 2)
    # Inverting the colors seems to look better for MNIST
    #data = 1 - data

    n = int(np.ceil(np.sqrt(data.shape[0])))
    padding = ((0, n ** 2 - data.shape[0]), (0, 0), (0, 0)) + ((0, 0), ) * (data.ndim - 3)
    data = np.pad(data, padding, mode='constant', constant_values=0)
    # Tile the individual thumbnails into an image.
    data = data.reshape(
        (n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))
    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])
    data = (data * 255).astype(np.uint8)
    return data

def save_metadata_to_tsv(save_path, meta_df):
    meta_df.to_csv(save_path, sep='\t', index=False)

def save_embeddings(log_dir, features, metadata=None, labels=None, sprite=None, sprite_shape=None):
    metadata_path = os.path.join(log_dir, 'metadata.tsv')
    features = tf.Variable(features, name='features')
    if metadata is not None:
        save_metadata_to_tsv(metadata_path, metadata)
    # produce_embeddings_tsv(os.path.join(log_dir, 'metadata.tsv'), headers=['label'], labels=labels)

    #if labels is not None:
    #    with open(metadata, 'w') as metadata_file:
    #        for row in labels:
    #            metadata_file.write('%d\n' % row)
    if sprite is not None:
        PIL.Image.fromarray(sprite).save(os.path.join(log_dir, 'sprite.png'))
    with tf.Session() as sess:
        saver = tf.train.Saver([features])
        sess.run(features.initializer)
        saver.save(sess, os.path.join(log_dir, 'features.ckpt'))

        config = projector.ProjectorConfig()
        # One can add multiple embeddings.
        embedding = config.embeddings.add()
        embedding.tensor_name = features.name
        if labels is not None:
            # Link this tensor to its metadata file (e.g. labels).
            embedding.metadata_path = metadata_path
        if sprite is not None:
            embedding.sprite.image_path = os.path.join(log_dir, 'sprite.png')
            embedding.sprite.single_image_dim.extend(sprite_shape)
        # Saves a config file that TensorBoard will read during startup.
        projector.visualize_embeddings(tf.summary.FileWriter(log_dir), config)

def say(*args):
    print(*args, file=sys.stderr)

def image_arg_to_coco(image_arg, do_patches=False, patch_size=[512,512]):
    """Gets the image argument and converts it to a COCO format dataset.
    The image argument can either be a coco file, or a sequence of images.

    Args:
        image_arg (list): The image arguments

    Returns:
        COCO: The coco dataset

    """
    image_list = []
    if image_arg[0].endswith('.json'):
        coco = COCO(image_arg[0])
    elif do_patches:
        # we will subsample the images, and create multiple patches per image
        n = 0
        for _, ipath in enumerate(tqdm(image_arg)):
            with PIL.Image.open(ipath) as img:
                width, height = img.size
                # work out sub-sampling stats
                num_patches = (width // patch_size[0]) * (height // patch_size[1])
                for m in range(num_patches):
                    patch_path = os.path.splitext(ipath)[0] + \
                                                    '.' + str(patch_size[0] *  np.mod(m, width // patch_size[0])) + \
                                                    '.' + str(patch_size[0] * ( m // (width // patch_size[1]))) + '.png'
                    image = {
                        'filename': ipath,
                        'path': os.path.basename(patch_path),
                        'height': patch_size[0],
                        'width': patch_size[1],
                        'id': n
                    }
                    image_list.append(image)
                    n = n + 1
        dataset = {'images': image_list, 'categories': [], 'annotations': []}
        coco = COCO()
        coco.dataset = dataset
        coco.createIndex()
    else:
        # input is assumed to be a list of images, and a coco will be created for it
        for n, ipath in enumerate(image_arg):
            with PIL.Image.open(ipath) as img:
                width, height = img.size
            image = {
                'filename': os.path.basename(ipath),
                'path': ipath,
                'height': height,
                'width': width,
                'id': n
            }
            image_list.append(image)
        dataset = {'images': image_list, 'categories': [], 'annotations': []}
        coco = COCO()
        coco.dataset = dataset
        coco.createIndex()
    return coco

def get_data_from_coco(coco, args, load_images=True):
    img_list = []
    hots = []
    img_ids = []
    paths = []

    for image in coco.loadImgs(coco.getImgIds()):
        if load_images:
            img = imread(image['path'], size=args.image_size, dtype=np.uint8)
            # TODO revise - use category map?
            hot = np.zeros([len(coco.getCatIds())])
            for ann in coco.loadAnns(coco.getAnnIds(imgIds=[image['id']])):
                hot[ann['category_id']] = 1

            img_list.append(img)
            hots.append(hot)
            img_ids.append(image['id'])
            paths.append(image['path'])
        else:
            paths.append(image['path'])
            img_ids.append(image['id'])
    data = {
        'imgs': img_list,
        'ImgIds': img_ids,
        'Path': paths
    }

    hots = np.asarray(hots)
    cid_to_name = {cat['id']:cat['name'] for cat in coco.loadCats(coco.getCatIds())}
    for k,v in cid_to_name.items():
        data[v] = hots[:, k]


    return data

def create_metadata_df(data, args):
    meta = data
    meta['FileName'] = [os.path.basename(path) for path in data['Path']]
    try:
        del meta['imgs']
        del meta['Path']
    except KeyError:
        pass

    meta_df = pd.DataFrame.from_dict(meta)

    meta_df = add_additional_metadata(meta_df, args)
    return meta_df

def add_additional_metadata(meta_df, args):
    if not args.metadata_csv:
        return meta_df
    add_df = pd.read_csv(args.metadata_csv)

    # Gets the spherical name from the full filename
    def index_column_from_row(row):
        return "_".join(row['FileName'].split('.')[0].split('_')[:-1])

    # Set the spherical name
    meta_df.loc[:, 'filename_index'] = meta_df.apply(index_column_from_row, axis=1)

    output_df = meta_df.merge(add_df, left_on='filename_index', right_on='SphericalName', how='left')

    return output_df


def main(args):
    say("Loading COCO")
    coco = image_arg_to_coco(args.images, do_patches=False, patch_size=args.image_size)
    if args.from_cube_face:
        patches_coco = image_arg_to_coco(args.images, do_patches=True, patch_size=args.image_size)
    say("Loading model...")
    if args.model_definition is not None:
        model = tf.keras.models.model_from_json(open(args.model_definition).read(),custom_objects = {'tf': tf})
        model.load_weights(args.model_weights)
    else:
        model = tf.keras.models.load_model(args.model_weights, custom_objects = {'tf': tf})

    layer_name = args.layer_name
    if layer_name is not None:
        output = model.get_layer(layer_name).output
        model = tf.keras.models.Model(inputs=model.input,
                                  outputs=output)
    say("Model loaded!")

    thumbs = None
    say("Loading images")
    data = get_data_from_coco(patches_coco, args, load_images=not(args.from_cube_face))
    if not(args.from_cube_face):
        images = np.array(data['imgs'], dtype=np.uint8)
        say("Creating thumbnails of {:d} images".format(len(images)))
        thumbs = np.array([
            np.array(PIL.Image.fromarray(image).resize(args.thumb_size))
            for image in images], dtype=np.uint8)
        images = images.astype(np.float32) / 127.5 - 1

    say("Predicting...")
    if args.from_cube_face:
        thumbs = []
        for image in tqdm(patches_coco.loadImgs(patches_coco.getImgIds())):
            # we need to generate patches, sprites, metadata on the fly?
            # TODO: we are reading the same image mulitple times. Read once for all patches, and batch get patches.
            # also this is all done, slow and sequentially. Major speed ups available if done from generators.
            crop_index = np.asarray([[int( image['path'].split('.')[-3]),
                                      int( image['path'].split('.')[-3]) + int( args.image_size[0])],
                                     [int( image['path'].split('.')[-2]),
                                      int( image['path'].split('.')[-2]) + int( args.image_size[1])]])

            img = imread(image['filename'], dtype=np.uint8)[crop_index[0,0]:crop_index[0,1],
                                                            crop_index[1,0]:crop_index[1,1]]
            thumbs.append(np.array(PIL.Image.fromarray(img).resize(args.thumb_size), dtype=np.uint8))
            feature = model.predict(np.expand_dims(img, axis=0).astype(np.float32) / 127.5 - 1)
            try:
                features = np.concatenate((features, feature), axis=0)
            except NameError:
                features = feature
    else:
        features = model.predict(images)

    if args.pooling == 'avg':
        features = np.mean( np.mean(features, axis=1), axis=1) # compute the mean embedding vector across all pixels
    elif args.pooling == 'max':
        features = np.max( np.max(features, axis=1), axis=1 ) # compute the max embedding vector across all pixels
    else:
        raise ValueError("Only avg,max pooling methods are supported")

    if args.save_embeddings_to_csv:
        say('Saving embeddings to csv...')
        np.savetxt(os.path.join(args.tensorboard_dir, 'embeddings-features.csv'), features)

    say("Saving embeddings...")
    os.makedirs(args.tensorboard_dir, exist_ok=True)
    save_embeddings(
        args.tensorboard_dir, features,
        metadata=create_metadata_df(data, args),
        labels=np.zeros((len(features),1)),
        sprite=images_to_sprite(np.asarray(thumbs)) if thumbs is not None else None,
        sprite_shape=args.thumb_size if thumbs is not None else None)

    say('Done!')

    say("To view embeddings, launch tensorboard from the %s directory with: '" %args.tensorboard_dir)
    say("tensorboard --logdir ./")

def get_args(cmd_line=None):
    '''Get args from the command line args'''
    parser = argparse.ArgumentParser(
        description="Cluster images using various algorithms and display the results on the TensorBoard Projector")
    parser.add_argument(
        "tensorboard_dir", help="Where to write the tensorboard embeddings")
    parser.add_argument(
        "images", nargs='+', help="images, COCO JSON, or list of capture stub directories to cluster")
    parser.add_argument(
        "--image-size", help="CSV height, width to load and resize each image to feed into the network", default=None)
    parser.add_argument(
        "--thumb-size", default='256,256', help="CSV height, width for the TensorBoard thumbnails")
    parser.add_argument(
        "--image-dir", help="The directory to relatively path the images with (COCO only)")
    parser.add_argument(
        "--model-definition", help="The model definition .json")
    parser.add_argument(
        "--model-weights", help="path to model weights file, saved in keras .h5 format", required=True)
    parser.add_argument(
        "--layer-name", help="The layer to calculate the embeddings on, e.g. 'decoder_conv1_pointwise_BN'", required=True)
    parser.add_argument(
        "--pooling", help="The type of pooling to use, options are {avg,max}", default="avg")
    parser.add_argument(
        "--metadata-csv", help="Additional metadata contained in a .csv file, indexed by filename")
    parser.add_argument(
        "--save-embeddings-to-csv", help="Optionally, save embeddings as a csv.", action='store_true')
    parser.add_argument(
        "--from-cube-face", help="Optionally, sub-divide (tile) input images (i.e., cube-faces), so embeddings can be "
                             "computed for unlabelled cube-faces.", action='store_true')
    args = parser.parse_args(args=cmd_line)
    if args.image_size is not None:
        args.image_size = tuple(int(i) for i in args.image_size.split(','))
    args.thumb_size = tuple(int(i) for i in args.thumb_size.split(',')) \
        if args.thumb_size else tuple(i // 2 for i in args.image_size)
    return args

if __name__ == "__main__":
    main(get_args())
