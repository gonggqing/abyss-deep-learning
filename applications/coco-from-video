#!/usr/bin/python3

import argparse
import glob
import json
import logging
import os
import re
import sys
from inspect import currentframe
from pathlib import Path

import cv2
from pycocotools.coco import COCO

description = """

Read JSON file(s) defined on command line or a list of JSON files on stdin,
output COCO JSON files in respective subdirectories in the current directory,
optionally, split videos into PNG frames

examples
    coco-from-video coco.cloud.001.json --dir /mnt/ssd1/processed/industry/what/not --cloud
    find . -name my-coco.json | coco-from-video --dir /mnt/ssd1/processed/industry/what/not --cloud

"""


# TODO:
#   ! output video details in info/dataset section
#   ! output bare minimum (see confluence) of fields in images section
#   ? pad frame numbers in filenames? 00001234.png vs 1234.png?
#   ? paths to images absolute by default
#   ? add --relative option?
#   ? add --absolute option?

# TODO: must be able to handle .avi video format?


def main():
    logging.basicConfig(filename='error.log', filemode='w', level=logging.DEBUG)

    args = get_args()

    if not args.video_dir:
        print("No video directory specified to search for video/s")
        sys.exit(1)

    for json_file in args.json_files:
        print("Creating COCO object for {}".format(os.path.basename(json_file)))
        coco = COCO(json_file)
        if len(get_unique_list_of_videos(coco)) != 1:
            continue
            raise EnvironmentError("JSON has more than one video")
        video_basename = os.path.basename(get_unique_list_of_videos(coco)[0])

        # Open the video
        video_path = recursive_search(video_basename, args.video_dir)

        if not video_path:
            print("Unable to locate {}".format(video_basename))
            continue

        video_name, video_ext = os.path.splitext(video_basename)

        cap = cv2.VideoCapture(video_path)

        # Retrieve sub-directories if they exist
        path = Path(video_path)
        rel_dir = path.relative_to(args.video_dir)
        sub_dir, video_basename = os.path.split(rel_dir)

        # Create output data set folder that contains the coco.json file
        output_data_set_dir = os.path.join(args.output_dir, sub_dir, video_name)
        if not os.path.exists(output_data_set_dir):
            os.makedirs(output_data_set_dir)

        img_dir = None

        if args.make_images:
            # Create image folder
            img_dir = os.path.join(output_data_set_dir, 'images')
            if not os.path.exists(img_dir):
                os.makedirs(img_dir)

        # Retrieve first image id number in data set to ensure image ids begin from 0
        img_id_offset = int(coco.dataset['images'][0]['id'])
        # Iterate through existing images in coco dataset
        for im_idx, im in enumerate(coco.dataset['images']):
            # Original image path
            img_path = im['path']

            if ':' not in img_path:
                raise EnvironmentError("COCO path variable contains no ':', cannot derive frame number")

            # Retrieve image frame number
            img_frame_number = int(img_path.split(":")[-1])

            # Set the frame in the video
            cap.set(cv2.CAP_PROP_POS_FRAMES, img_frame_number)

            # Read the Image
            ret, img = cap.read()

            # Default is video path and frame number
            img_path = video_path + ":" + str(img_frame_number)

            # If image folder exists, extract image in png format
            if ret and img_dir:
                img_file_name = str(img_frame_number).zfill(8) + ".png"
                # New Path
                img_path = os.path.join(img_dir, img_file_name)

                # Write the image to the new path
                if not os.path.exists(img_path):
                    cv2.imwrite(img_path, img)
                else:
                    print("coco-from-video: Image {} exists".format(img_path))

                if args.relative_path:
                    img_path = os.path.join(os.path.basename(img_dir), img_file_name)
            elif not ret:
                logging.debug("Failed to get frame {} for image {} from {}".format(img_frame_number, im_idx, video_path))

            # New Coco Dataset
            coco.dataset['images'][im_idx] = {
                'id': int(im['id'] - img_id_offset),
                'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
                'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                'original_uri': video_path + "?begin=" + str(img_frame_number) + "&end=" + str(img_frame_number),
                'path': img_path,
            }

            print('Converting image {}'.format(im_idx), end='\r')

        # if 'dataset' not in coco.dataset['info']: # Unsure if necessary 'if' statement
        coco.dataset['info']['dataset'] = {
            "license": 1,
            "video": {
                "height": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
                "width": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                "frame_total": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
                "frame_rate": cap.get(cv2.CAP_PROP_FPS)
            },
            "date_captured": "",
            "uri": video_path,
        }

        if args.keep_segmentation:
            return NotImplementedError("Not yet implemented")

        annotations = []
        if 'categories' in coco.dataset:
            # Converting instances to captions
            categories = coco.dataset.pop('categories')
            caption_map_r = {cat['id']: cat['name'] for cat in categories}
            # Retrieve first annotation id to offset existing annotations by that amount to ensure ann ids begin from 0
            ann_id_offset = int(coco.dataset['annotations'][0]['id'])
            for ann in coco.dataset['annotations']:
                new_ann = {
                    'caption': translate_caption("", caption_map_r[ann['category_id']]),
                    'id': int(ann['id'] - ann_id_offset),
                    'image_id': int(ann['image_id'] - img_id_offset)
                }
                annotations.append(new_ann)
        else:
            # Converting old CSV captions to new captions
            for ann in coco.dataset['annotations']:
                for caption in ann['caption'].split(','):
                    new_ann = {
                        'caption': translate_caption("", caption),
                        'id': len(annotations),
                        'image_id': int(ann['image_id'] - img_id_offset)
                    }
                    annotations.append(new_ann)
        coco.dataset['annotations'] = annotations

        remove_redundant_fields_in_coco(coco)

        # Write the new data set
        with open(os.path.join(output_data_set_dir, 'coco.json'), 'w') as outfile:
            json.dump(coco.dataset, outfile, sort_keys=True, indent=4)

    sys.exit(0)


def debug_print(arg):
    """Debugging tool to print line number followed by normal print statement arguments

    """
    frame_info = currentframe()
    print('Line', frame_info.f_back.f_lineno, ':', arg)


def get_unique_list_of_videos(coco):
    """Gets a unique list of all videos in the dataset

    Args:
        coco (COCO): A coco dataset

    Returns:
        list: List of strings of all videos in the dataset

    """
    video_list = []
    img_ids = coco.getImgIds(imgIds=[])  # Load all images
    for img_id in img_ids:
        video_path = coco.loadImgs(img_id)[0]['path']
        # debug_print("video path is {}".format(video_path))
        video_name = os.path.basename(video_path).split(':')[0]
        video_name = re.sub(r' \([0-9]+\)', '', video_name)
        # debug_print(video_name)
        video_list.append(video_name)
    return list(set(video_list))


def recursive_search(video_basename: str, root_dir: str) -> str:
    """

    Args:
        video_basename: Base video file name
        root_dir: Root directory to search recursively in sub directories for video file

    Returns: Full file path to specified video base name

    """
    for file_path in glob.iglob(os.path.join(root_dir, "**", video_basename), recursive=True):
        return file_path


def get_args():
    parser = argparse.ArgumentParser(description=description, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument("json_files", nargs='+', type=str, help="Path to JSON file")
    parser.add_argument("--video-dir", "--video", "-v", type=str,
                        help="Path under which all the videos referenced in JSON file(s) expected to be found")
    parser.add_argument("--output-dir", "--output", "-o", type=str,
                        help="Output directory path for database", default=os.getcwd())
    parser.add_argument("--keep-segmentation", "--seg", "-s", action='store_true',
                        help="Keep segmentation regions, otherwise assume to be classification task (and discard "
                             "regions)")
    # TODO: Check to see what differs between cloud factory format and other formats
    parser.add_argument("--cloud-factory", "--cloud", "-c", action="store_true",
                        help="Input JSON files are in (deprecated) cloud factory format flavour")
    parser.add_argument("--make-images", "--image", "-i", action="store_true",
                        help="Extract images from video and save as PNG")
    parser.add_argument("--relative-path", "--relative", "-r", action="store_true",
                        help="Image paths will be relative to the "
                             "coco.json file in output data set "
                             "directory")
    return parser.parse_args()


# TODO: check with seva & jackson on good way to do this
def translate_caption(input_format, label):
    return label


def remove_redundant_fields_in_coco(coco: COCO):
    """
    Filter old formatted COCO object to new format

    Args:
        coco: COCO object

    """
    remove_redundant_fields(coco.dataset, ['info', 'images', 'annotations'])
    for img in coco.dataset['images']:
        remove_redundant_fields(img, ["height", "width", "id", "path", "original_uri"])
    remove_redundant_fields(coco.dataset['info'], ["url",
                                                   "year",
                                                   "contributor",
                                                   "total_time",
                                                   "description",
                                                   "version",
                                                   "date_created",
                                                   "dataset",
                                                   ])


def remove_redundant_fields(dictionary: dict, fields: list):
    """

    Args:
        dictionary: Standard dictionary inside a COCO object
        fields: Fields of interest to keep

    """
    for field in list(dictionary):
        if field not in fields:
            del dictionary[field]


if __name__ == "__main__":
    main()
