#!/usr/bin/env python3
import argparse
import csv
import json
import logging
import os
import signal
import sys

import pandas as pd
import numpy as np
from PIL import Image


__author__ = 'Kent Hu'
__maintainer__ = 'Kent Hu'
DESCRIPTION = \
    """
    Generate COCO JSON file from CSV file.
    
    Required CSV file fields are:
    video frame classification: path,begin_frame,end_frame,caption
    bounding boxes: path,x1,y1,x2,y2,score,category_id
    
    examples
        bounding boxes
            cat retina-predictions.csv | coco-from-csv --fields path,,x1,y1,x2,y2,score,category_id --map class-mapping.csv > retina-predictions.json
            cat input.csv | coco-from-csv --fields path,,x,y,w,h,score,category_id --map class-mapping.csv > output.json
            
        categories
            cat images.csv | coco-from-csv -f path --categories some-coco.json
            cat images.csv | coco-from-csv -f path --categories <( echo medium,1; echo high,2 )
            cat images.csv | coco-from-csv -f path --categories <( echo '[ { "id": 1, "name": "medium" }, { "id": 2, "name": "high" } ]' )
            cat images.csv | coco-from-csv -f path --categories <( echo '{ "categories": [ { "id": 1, "name": "medium" }, { "id": 2, "name": "high" } ] }' )

        segmentation
            cat contours.csv | coco-from-csv --fields 'path,index,parent,x,y,category_id' --map class-mapping.csv

    """
EMPTY = 0
signal.signal(signal.SIGPIPE, signal.SIG_DFL)  # default sigpipe to terminate program instead of raising exception


def print_error(modes):
    logging.error(
        "Could not find required fields options are:\n{}".format(
            '\n'.join(['{} = {}'.format(m[0], ','.join(m[1])) for m in modes])))
    sys.exit(1)


def main(args):
    logging.basicConfig(format='%(filename)s: %(asctime)s.%(msecs)d: %(levelname)s: %(message)s',
                        datefmt='%Y-%m-%d %H:%M:%S',
                        level=args.verbose)
    logging.info("--verbose enabled")
    #buffer = sys.stdin.read().strip()
    #if not buffer: logging.error(
    #    "expected input from stdin: received empty characters {}".format(repr(buffer))); sys.exit(1)
    #csv_ = StringIO(buffer)

    modes = [
        ('bbox', ['path', 'x1', 'y1', 'x2', 'y2', 'category_id']),
        ('bbox', ['path', 'x', 'y', 'w', 'h', 'category_id']),
        ('video', ['path', 'begin_frame', 'end_frame', 'caption']),
        ('contours', ['path', 'index','parent','x','y','category_id']),
        ('path', ['path'])
    ]
    mode = None
    try:
        if args.fields:
            fields = args.fields.split(',')
            for m in modes:
                if all(field in fields for field in m[1]):
                    mode = m
                    break
            names = [f for i,f in enumerate(fields) if f != '']
            usecols = [i for i,f in enumerate(fields) if f != '']
            if mode is None:
                print_error(modes)
            df = pd.read_csv(sys.stdin, names=names, usecols=usecols, header=None)
        else:
            df = pd.read_csv(sys.stdin)
            for m in modes:
                if all(field in fields for field in df):
                    mode = m
                    break
            if mode is None:
                print_error(modes)
    except pd.errors.ParserError as e:
        logging.error(e, "Mismatch in expected and received fields in csv")
        sys.exit(1)
    if mode[0] == 'bbox':
        if 'w' not in df or 'h' not in df:
            df['w'] = df['x2'] - df['x1']
            df['h'] = df['y2'] - df['y1']
            df.rename(columns={'x1': 'x', 'y1': 'y'}, inplace=True)
        logging.info("Generating from bounding boxes")
        coco_json = generate_from_bounding_boxes(df, args)
    elif mode[0] == 'video':
        logging.info("Generating from video")
        coco_json = generate_from_video_frames(df, args)
    elif mode[0] == 'contours':
        logging.info("Generating from contours")
        coco_json = generate_from_contours(df, args)
    elif mode[0] == 'path':
        logging.info("Generating from path only")
        coco_json = make_images(df, args)
    else:
        logging.error(
            "Could not find required fields\n {}".format('\n'.join([ '{} = {}'.format(m[0], ','.join(m[1])) for m in modes])))
        sys.exit(1)

    json.dump(coco_json, sys.stdout, indent=args.indent)
    sys.exit(0)


def make_image(row, width, height, id, args):
    image_path = row['path']
    image_file_name = os.path.basename(image_path)
    image = {
        'id': row['image_id'] if 'image_id' in row else id,
        'file_name': image_file_name,
        'path': image_path,
    }
    if width is None:
        try:
            width, height = Image.open(image_path).size
        except IOError:
            if args.force:
                logging.warning(
                    "could not get image size from [{}]; no image width/height will be in coco".format(image_path))
            else:
                logging.error(
                    "could not get image size from [{}]; use --force to override".format(image_path))
                sys.exit(1)
            width = height = None
    if width:
        image['width'] = width
        image['height'] = height
    return image


def make_images(df, args):
    coco_json = {
        'categories': get_categories_from_fd(args.map),
        'annotations': [],
        'images': [],
    }
    if args.image_size:
        width, height = args.image_size.split(',')
        width = int(width)
        height = int(height)
    else:
        width = None
        height = None

    for _,group in df.groupby(['path'], sort=False):
        coco_json['images'].append(make_image(group.iloc[0], width, height, len(coco_json['images']), args))
    return coco_json


def generate_from_contours(df, args):
    logging.info("Make images")
    coco_json = make_images(df, args)
    logging.info("group contours")
    image_name_to_id = { image['path']: image['id'] for image in coco_json['images'] }

    df.sort_values(by=['path', 'index', 'parent'], inplace=True)

    all_points = df[['x','y', 'index']].to_numpy()
    end = 0

    for path, path_group in df.groupby(['path'], sort=False):
        image_id = image_name_to_id[path]
        for index, index_group in path_group.groupby(['parent'], sort=False):
            # this operation is very slow, extract from numpy by index instead
            # points = index_group[['x', 'y', 'parent']].to_numpy()
            start = end
            end = end + index_group['parent'].count()
            points = all_points[start:end]

            contours = np.split(points[:, 0:2], np.unique(points[:, 2], return_index=True)[1][1:])
            segmentation = list()
            for c in contours:
                segmentation.append([int(x) for x in np.reshape(c, -1)])

            outer = contours[0]

            min_xy = outer.min(0)
            max_xy = outer.max(0)
            wh = max_xy-min_xy

            coco_json['annotations'].append({
                'id': len(coco_json['annotations']),
                'image_id': int(image_id),
                "category_id": int(index_group['category_id'].iloc[0]),
                "segmentation": segmentation,
                "bbox": [ int(min_xy[0]), int(min_xy[1]), int(wh[0]), int(wh[1]) ],
                "area": int(wh[0]*wh[1]) # TODO actual area
            })

    return coco_json
    

def generate_from_bounding_boxes(df, args):  # def generate_from_bounding_boxes(df: pd.DataFrame) -> dict:
    coco_json = make_images(df, args)
    image_name_to_id = { image['path']: image['id'] for image in coco_json['images']}
   
    for _,row in df.iterrows():
        category_id = int(row['category_id'])
        if category_id < 0:
            continue
        img_path = row['path']
        bbox = [int(row['x']), int(row['y']), int(row['w']), int(row['h'])]
        coco_json['annotations'].append({
            'id': len(coco_json['annotations']),
            'image_id': image_name_to_id[img_path],
            'category_id': category_id,
            'segmentation': [bbox_to_segmentation(bbox)],
            'area': int(bbox[2] * bbox[3]),
            'bbox': bbox,
            'iscrowd': 0,
            'score': row.get('score', 1),
        })
    return coco_json


def get_categories_from_fd(mapping):
    if mapping is None:
        logging.warning("no --categories specified, empty catergories will be output")
        return []
    with open(mapping) as f:
        buf = f.read().strip()
        if buf[0] in '{':
            categories = json.loads(buf)['categories']
            for category in categories:
                if 'supercategory' not in category:
                    category['supercategory'] = ''
        elif buf[0] in '[':
            categories = json.loads(buf)
        else:
            categories = []
            buf = buf.split('\n')
            #reader = csv.reader(buf)
            for row in buf:
                s = row.split(',')
                if len(s) < 2: logging.error(
                    "--categories: expected at least <name>,<id>, got: '{}'".format(row)); sys.exit(1)
                category, id, supercategory = s if len(s) > 2 else s + ['']
                categories.append({
                    'id': int(id),
                    'name': category,
                    'supercategory': supercategory,
                })
    return categories


def bbox_to_segmentation(bbox: list) -> list:
    x, y, width, height = bbox
    return [x, y, x + width, y, x + width, y + height, x, y + height]


def generate_from_video_frames(df: pd.DataFrame, args) -> dict:
    logging.info("Generating from video frames")
    coco_json = {
        'file_name': '',
        'segments': [],
    }
    for idx, row in df.iterrows():
        if 'file_name' in row:
            coco_json['file_name'] = row['file_name']
        coco_json['segments'].append({
            'id': idx,
            'begin_frame': row['begin_frame'],
            'end_frame': row['end_frame'],
            'caption': row['caption'],
        })
    return coco_json


def get_args():
    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--fields', '-f', type=str, help="Comma separated field names for CSV file")
    parser.add_argument('--force', action='store_true', help="ignore warnings")
    parser.add_argument('--indent', type=int, help="json indent, if none, output minimised json default: %(default)s",
                        default=4)
    parser.add_argument('--map', '--categories',
                        type=str,
                        help="Path to original COCO json or category mapping csv file of category and category ids; csv as <name>,<id>[,<supercategory>]")
    parser.add_argument('-s', '--image-size', type=str, help="<width>,<height> values to use to give to all images")
    parser.add_argument('-v', '--verbose', action='store_const', const=logging.INFO, help="More output to stderr")
    return parser.parse_args()


if __name__ == '__main__':
    main(get_args())
