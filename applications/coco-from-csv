#!/usr/bin/env python3
import logging

__author__ = 'Kent Hu'
__maintainer__ = 'Kent Hu'
import argparse
import csv
import json
import os
import sys
from datetime import datetime
from io import StringIO

import pandas as pd
from PIL import Image

DESCRIPTION = \
    """
    Generate COCO JSON file from CSV file.
    
    Required CSV file fields are:
        video frame classification: file_name,begin_frame,end_frame,caption
        bounding boxes: file_name,image_id,x1,y1,x2,y2,score,category_id
            image_id is an optional field
    """


def main(args):
    logging.basicConfig(format='%(filename)s: %(asctime)s.%(msecs)d: %(levelname)s: %(message)s',
                        datefmt='%Y-%m-%d %H:%M:%S',
                        level=args.verbose)
    logging.info("--verbose enabled")

    # Empty file check
    buffer = sys.stdin.read().strip()
    if buffer:
        csv_ = StringIO(buffer)
    else:
        raise IOError("Expecting input from stdin: received empty characters {}".format(repr(buffer)))

    try:
        if args.fields:
            df = pd.read_csv(csv_, names=args.fields.split(','), header=None)
        else:
            df = pd.read_csv(csv_)
    except pd.errors.ParserError as e:
        logging.error(e, "Mismatch in expected and received fields in csv")
        sys.exit(1)

    coco_json = {}
    if all(field in df for field in ['file_name', 'x1', 'y1', 'x2', 'y2', 'category_id']):
        coco_json = generate_from_bounding_boxes(df, args)
    elif all(field in df for field in ['file_name', 'begin_frame', 'end_frame', 'caption']):
        coco_json = generate_from_video_frames(df, args)
    else:
        logging.error("Could not find required fields")

    json.dump(coco_json, sys.stdout, indent=args.indent)
    sys.exit(0)


def generate_from_bounding_boxes(df, args):  # def generate_from_bounding_boxes(df: pd.DataFrame) -> dict:
    logging.info("Generating from bounding boxes")
    coco_json = {
        'info'       : {
            'year'        : int(datetime.now().year),
            'version'     : '1.0',
            'description' : 'This is a dataset configured by Abyss Solutions.',
            'contributor' : 'Abyss Solutions',
            'url'         : 'http://www.abysssolutions.com.au',
            'date_created': datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
        },
        'images'     : [],
        'annotations': [],
        'licenses'   : [
            {
                "id"  : 0,
                "name": "Attribution-NonCommercial-ShareAlike License",
                "url" : "http://creativecommons.org/licenses/by-nc-sa/2.0/",
            }
        ],
        'categories' : get_categories_from_fd(args.map)
    }

    seen_imgs = set()
    img_file_name_2_img_id = {}
    for idx, row in df.iterrows():
        category_id = int(row['category_id'])
        if category_id < 0:
            continue

        img_path = row['file_name']
        img_file_name = os.path.basename(img_path)

        if img_file_name not in seen_imgs:
            img_id = row['image_id'] if 'image_id' in row else (len(seen_imgs))
            seen_imgs.add(img_file_name)

            # PIL.Image.open does lazy loading so raster data will not be loaded in
            try:
                width, height = Image.open(img_path).size
            except IOError:
                logging.info("img_path [{}] could not be found".format(img_path))
                logging.info("Using width and height values from command line argument --image-size")
                if args.image_size:
                    width, height = args.image_size.split(',')
                else:
                    width = height = None
                    logging.info("no width and height values supplied")
                    logging.warning("width and height values will be omitted from image [{}]".format(img_id))

            img = {
                'id'           : img_id,
                'file_name'    : img_file_name,
                'license'      : 0,
                'date_captured': '',
                'path'         : img_path,
            }
            if width and height:
                img['width'] = width
                img['height'] = height
            coco_json['images'].append(img)
            img_file_name_2_img_id[img_file_name] = img_id

        x = row['x1']
        y = row['y1']
        width = row['x2'] - x
        height = row['y2'] - y
        bbox = [int(x), int(y), int(width), int(height)]
        coco_json['annotations'].append({
            'id'          : len(coco_json['annotations']),
            'image_id'    : img_file_name_2_img_id[img_file_name],
            'category_id' : category_id,
            'segmentation': [bbox_to_segmentation([x, y, width, height])],
            'area'        : int(width * height),
            'bbox'        : bbox,
            'iscrowd'     : 0,
            'score'       : row.get('score', 1),
        })
    return coco_json


def get_categories_from_fd(mapping):
    categories = []
    with open(mapping) as f:
        buf = f.read().strip()
        if buf[0] in '{[':
            categories += json.load(f)['categories']
        else:
            buf = buf.split('\n')
            reader = csv.reader(buf)
            try:
                if len(next(reader)) == len(next(reader)) > 1:
                    for row in buf:
                        category, id = row.split(',')
                        categories.append({
                            'id': id,
                            'name': category,
                            'supercategory': '',
                        })
            except StopIteration:
                pass
    return categories


def bbox_to_segmentation(bbox: list) -> list:
    x, y, width, height = bbox
    return [x, y, x + width, y, x + width, y + height, x, y + height]


def generate_from_video_frames(df: pd.DataFrame, args) -> dict:
    logging.info("Generating from video frames")
    coco_json = {
        'file_name': '',
        'segments' : [],
    }
    for idx, row in df.iterrows():
        if 'file_name' in row:
            coco_json['file_name'] = row['file_name']
        coco_json['segments'].append({
            'id'         : idx,
            'begin_frame': row['begin_frame'],
            'end_frame'  : row['end_frame'],
            'caption'    : row['caption'],
        })
    return coco_json


def get_args():
    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('fields', type=str, help="Comma separated field names for CSV file")
    parser.add_argument('--map', '--categories',
                        type=str,
                        help="Path to original COCO json or category mapping csv file of category and category ids")
    parser.add_argument('-s', '--image-size', type=str, help="<width>,<height> values to use to give to all images")
    parser.add_argument('-m', '--min', action='store_const', help="Output minimised json", const=None, default=4,
                        dest='indent')
    parser.add_argument('-v', '--verbose', action='store_const', const=logging.INFO, help="More output to stderr")
    return parser.parse_args()


if __name__ == '__main__':
    main(get_args())
