#!/usr/bin/env python3
import argparse
import json
import logging
import os
import signal
import sys

import pandas as pd
import numpy as np
from PIL import Image
from typing import Iterator
import cv2
from abyss_deep_learning.utils import flatten_holes

__author__ = 'Kent Hu'
__maintainer__ = 'Kent Hu'
DESCRIPTION = \
    """
    Generate COCO JSON file from CSV file.
    
    Required CSV file fields are:
    video frame classification: path,begin_frame,end_frame,caption
    bounding boxes: path,x1,y1,x2,y2,score,category_id
    
    examples
        bounding boxes
            cat retina-predictions.csv | coco-from-csv --fields path,,x1,y1,x2,y2,score,category_id --map class-mapping.csv > retina-predictions.json
            cat input.csv | coco-from-csv --fields path,,x,y,w,h,score,category_id --map class-mapping.csv > output.json
            
        categories
            cat images.csv | coco-from-csv -f path --categories some-coco.json
            cat images.csv | coco-from-csv -f path --categories <( echo medium,1; echo high,2 )
            cat images.csv | coco-from-csv -f path --categories <( echo '[ { "id": 1, "name": "medium" }, { "id": 2, "name": "high" } ]' )
            cat images.csv | coco-from-csv -f path --categories <( echo '{ "categories": [ { "id": 1, "name": "medium" }, { "id": 2, "name": "high" } ] }' )

        points
            cat points.csv | coco-from-csv --fields path,x,y,score --map <( echo point,0 )

        segmentation
            cat contours.csv | coco-from-csv --fields 'path,index,parent,x,y,category_id' --map class-mapping.csv

    """
EMPTY = 0
signal.signal(signal.SIGPIPE, signal.SIG_DFL)  # default sigpipe to terminate program instead of raising exception


def print_error(modes):
    logging.error(
        "Could not find required fields options are:\n{}".format(
            '\n'.join(['{} = {}'.format(m[0], ','.join(m[1])) for m in modes])))
    sys.exit(1)


def main(args):
    logging.basicConfig(format='%(filename)s: %(asctime)s.%(msecs)d: %(levelname)s: %(message)s',
                        datefmt='%Y-%m-%d %H:%M:%S',
                        level=args.verbose)
    logging.info("--verbose enabled")
    #buffer = sys.stdin.read().strip()
    #if not buffer: logging.error(
    #    "expected input from stdin: received empty characters {}".format(repr(buffer))); sys.exit(1)
    #csv_ = StringIO(buffer)

    # Required columns in CSV data. Names are provided by user on command line
    modes = [
        ('bbox', ['path', 'x1', 'y1', 'x2', 'y2', 'category_id']),
        ('bbox', ['path', 'x', 'y', 'w', 'h', 'category_id']),
        ('video', ['path', 'begin_frame', 'end_frame', 'caption']),
        ('contours', ['path', 'index','parent','x','y','category_id']),
        ('point', ['path', 'x', 'y']),
        ('path', ['path'])
    ]
    mode = None
    try:
        if args.fields:
            fields = args.fields.split(',')
            for m in modes:
                if all(field in fields for field in m[1]):
                    mode = m
                    break
            names = [f for i,f in enumerate(fields) if f != '']
            usecols = [i for i,f in enumerate(fields) if f != '']
            if mode is None:
                print_error(modes)
            df = pd.read_csv(sys.stdin, names=names, usecols=usecols, header=None)
        else:
            df = pd.read_csv(sys.stdin)
            for m in modes:
                if all(field in fields for field in df):
                    mode = m
                    break
            if mode is None:
                print_error(modes)
    except pd.errors.ParserError as e:
        logging.error(e, "Mismatch in expected and received fields in csv")
        sys.exit(1)
    if mode[0] == 'bbox':
        if 'w' not in df or 'h' not in df:
            df['w'] = df['x2'] - df['x1']
            df['h'] = df['y2'] - df['y1']
            df.rename(columns={'x1': 'x', 'y1': 'y'}, inplace=True)
        logging.info("Generating from bounding boxes")
        coco_json = generate_from_bounding_boxes(df, args)
    elif mode[0] == 'video':
        logging.info("Generating from video")
        coco_json = generate_from_video_frames(df, args)
    elif mode[0] == 'contours':
        logging.info("Generating from contours")
        coco_json = generate_from_contours(df, args)
    elif mode[0] == 'point':
        logging.info("Generating from points")
        coco_json = generate_from_point(df, args)
    elif mode[0] == 'path':
        logging.info("Generating from path only")
        coco_json = make_images(df, args)
    else:
        logging.error(
            "Could not find required fields\n {}".format('\n'.join([ '{} = {}'.format(m[0], ','.join(m[1])) for m in modes])))
        sys.exit(1)

    json.dump(coco_json, sys.stdout, indent=args.indent)
    sys.exit(0)


def make_image(row, width, height, id, args):
    image_path = row['path']
    image_file_name = os.path.basename(image_path)
    image = {
        'id': row['image_id'] if 'image_id' in row else id,
        'file_name': image_file_name,
        'path': image_path,
    }
    if width is None:
        try:
            width, height = Image.open(image_path).size
        except IOError:
            if args.force:
                logging.warning(
                    "could not get image size from [{}]; no image width/height will be in coco".format(image_path))
            else:
                logging.error(
                    "could not get image size from [{}]; use --force to override".format(image_path))
                sys.exit(1)
            width = height = None
    if width:
        image['width'] = width
        image['height'] = height
    return image


def make_images(df, args):
    coco_json = {
        'categories': get_categories_from_fd(args.map),
        'annotations': [],
        'images': [],
    }
    if args.image_size:
        width, height = args.image_size.split(',')
        width = int(width)
        height = int(height)
    else:
        width = None
        height = None

    for _,group in df.groupby(['path'], sort=False):
        coco_json['images'].append(make_image(group.iloc[0], width, height, len(coco_json['images']), args))
    return coco_json


class CsvToPolygon:

    def __init__(self, df, point_key, polygon_group_key):
        self.polygon_group_key = polygon_group_key
        self.all_points = df[[point_key[0], point_key[1], 'index', polygon_group_key]].to_numpy()
        self.image_grouping = df.groupby(['path'], sort=False)

    @property
    def images(self) -> Iterator[object]:
        end = 0
        for path, path_group in self.image_grouping:
            polygons = list()
            for index, index_group in path_group.groupby([self.polygon_group_key], sort=False):
                start = end
                end = end + index_group[self.polygon_group_key].count()
                points = self.all_points[start:end]

                if any(points[:, 3] != index):
                    logging.error('mismatch numpy pandas')
                    sys.exit(1)

                contours = np.split(points[:, 0:2], np.unique(points[:, 2], return_index=True)[1][1:])

                area = cv2.contourArea(contours[0].astype(np.float32))
                for i in range(1, len(contours)):
                    area -= cv2.contourArea(contours[i].astype(np.float32))

                polygons.append({
                    'id': index_group[self.polygon_group_key].iloc[0],
                    'category_id': index_group['category_id'].iloc[0],
                    'contours': contours,
                    'area': area
                })
            yield {"path": path, 'polygons': polygons}


def generate_from_contours(df, args):
    logging.info("Make images")
    coco_json = make_images(df, args)
    logging.info("group contours")
    image_name_to_id = { image['path']: image['id'] for image in coco_json['images'] }

    df.sort_values(by=['path', 'parent', 'index'], inplace=True)

    csv_to_polygon = CsvToPolygon(df, ('x','y'), 'parent')

    for image in csv_to_polygon.images:
        path = image['path']
        image_id = image_name_to_id[path]
        for polygon in image['polygons']:
            contours = polygon['contours']
            category_id = polygon['category_id']
            area = polygon['area']
            segmentation = [np.reshape(c, -1).tolist() for c in contours]

            outer = contours[0]
            min_xy = outer.min(0)
            max_xy = outer.max(0)
            wh = max_xy-min_xy
            # area = int(wh[0] * wh[1])

            coco_json['annotations'].append({
                'id': len(coco_json['annotations']),
                'image_id': int(image_id),
                "category_id": int(category_id),
                "segmentation": flatten_holes(segmentation) if args.flatten_holes else segmentation,
                "bbox": [ int(min_xy[0]), int(min_xy[1]), int(wh[0]), int(wh[1]) ],
                "area": area
            })

    return coco_json
    

def generate_from_bounding_boxes(df: pd.DataFrame, args):  # def generate_from_bounding_boxes(df: pd.DataFrame) -> dict:
    coco_json = make_images(df, args)
    image_name_to_id = { image['path']: image['id'] for image in coco_json['images']}
   
    for _,row in df.iterrows():
        category_id = int(row['category_id'])
        if category_id < 0:
            continue
        img_path = row['path']
        bbox = [int(row['x']), int(row['y']), int(row['w']), int(row['h'])]
        coco_json['annotations'].append({
            'id': len(coco_json['annotations']),
            'image_id': image_name_to_id[img_path],
            'category_id': category_id,
            'segmentation': [bbox_to_segmentation(bbox)],
            'area': int(bbox[2] * bbox[3]),
            'bbox': bbox,
            'iscrowd': 0,
            'score': row.get('score', 1),
        })
    return coco_json


def get_categories_from_fd(mapping):
    if mapping is None:
        logging.warning("no --categories specified, empty categories will be output")
        return []
    with open(mapping) as f:
        buf = f.read().strip()
        if buf[0] in '{':
            categories = json.loads(buf)['categories']
            for category in categories:
                if 'supercategory' not in category:
                    category['supercategory'] = ''
        elif buf[0] in '[':
            categories = json.loads(buf)
        else:
            categories = []
            buf = buf.split('\n')
            #reader = csv.reader(buf)
            for row in buf:
                s = row.split(',')
                if len(s) < 2: logging.error(
                    "--categories: expected at least <name>,<id>, got: '{}'".format(row)); sys.exit(1)
                category, id, supercategory = s if len(s) > 2 else s + ['']
                categories.append({
                    'id': int(id),
                    'name': category,
                    'supercategory': supercategory,
                })
    return categories


def bbox_to_segmentation(bbox: list) -> list:
    x, y, width, height = bbox
    return [x, y, x + width, y, x + width, y + height, x, y + height]


def generate_from_point(df: pd.DataFrame, args):
    coco_json = make_images(df, args)
    image_name_to_id = {image['path']: image['id'] for image in coco_json['images']}

    for _, row in df.iterrows():
        img_path = row['path']

        bbox = [int(row['x']), int(row['y']), 1, 1]

        coco_json['annotations'].append({
            'id': len(coco_json['annotations']),
            'image_id': image_name_to_id[img_path],
            'category_id': row.get('category_id', 0),
            'annotation_type': 'point',
            'segmentation': [bbox_to_segmentation(bbox)],
            'area': int(bbox[2] * bbox[3]),
            'bbox': bbox,
            'iscrowd': 0,
            'score': row.get('score', 1),
        })

    return coco_json


def generate_from_video_frames(df: pd.DataFrame, args) -> dict:
    logging.info("Generating from video frames")
    coco_json = {
        'file_name': '',
        'segments': [],
    }
    for idx, row in df.iterrows():
        if 'file_name' in row:
            coco_json['file_name'] = row['file_name']
        coco_json['segments'].append({
            'id': idx,
            'begin_frame': row['begin_frame'],
            'end_frame': row['end_frame'],
            'caption': row['caption'],
        })
    return coco_json


def get_args():
    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--fields', '-f', type=str, help="Comma separated field names for CSV file")
    parser.add_argument('--force', action='store_true', help="ignore warnings")
    parser.add_argument('--indent', type=int, help="json indent, if none, output minimised json default: %(default)s",
                        default=4)
    parser.add_argument('--map', '--categories',
                        type=str,
                        help="Path to original COCO json or category mapping csv file of category and category ids; csv as <name>,<id>[,<supercategory>]")
    parser.add_argument('-s', '--image-size', type=str, help="<width>,<height> values to use to give to all images")
    parser.add_argument('--flatten-holes', action='store_true', help="flatten 2-level hierarchy contour into single contour")
    parser.add_argument('-v', '--verbose', action='store_const', const=logging.INFO, help="More output to stderr")
    return parser.parse_args()


if __name__ == '__main__':
    main(get_args())
