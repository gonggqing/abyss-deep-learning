#!/usr/bin/env python3
from argparse import ArgumentParser
import json
import sys
import abyss_deep_learning.draw
import cv2
import errno
import os


DESCRIPTION = \
"""
Draws annotations on images provided from a coco-json file. The json file is taken in from stdin and processed
\n
eg. cat coco-file.json | coco-draw


"""


JSON_SAMPLE = """
{
    "colors":[
        {"name": "PF",  "color":"255,255,0"},
        {"name": "JD",  "color":"0,255,0"},
        {"name": "AA",  "color":"255,0,0"}
    ]
}

"""



def main(args=None):
    

    if args.sample_colors:
        print(JSON_SAMPLE)
        return

    coco_file = json.load(sys.stdin)
    category_dict = {}
    default_color_pallette = [
        [255,0,0],
        [0,255,0],
        [255,0,255],
        [255,255,0],
        [0,255,255]*10
    ]


    active_color_pallette = default_color_pallette
    for category in coco_file['categories']:
        category_dict[category['id']] = category['name']



    # Colours loops over the category ids and override the colour pallette for a given category id
    if args.colors:
        color_json = json.load(open(args.colors,"r"))
        for ent in color_json['colors']:
            for cat in coco_file['categories']:
                if cat['name'] == ent['name']:
                    ab = ent['color'].split(',')
                    default_color_pallette[cat['id']-1] = [int(ab[0]), int(ab[1]), int(ab[2])]
                    print("using custom color for {}".format(ent['name']))

    for image in coco_file['images']:
        labels = [] # Labels either bbox or segmentation
        text_labels = [] # Text Labels with Text and origin
        cv2_image = cv2.imread(image['path'],cv2.IMREAD_UNCHANGED)
        if cv2_image is None:
            print("coco-draw : error, image not found \"{}\"".format(image['path']), file=sys.stderr)
            continue

        for annotation in coco_file['annotations']:

            if 'score' in annotation:
                annotation_text = "{} -  score: {}".format(category_dict[annotation['category_id']],str(annotation['score']))
            else:
                annotation_text = "{}".format(category_dict[annotation['category_id']])

            if image['id'] == annotation['image_id']:
                if args.bbox:
                    # convert from x,y,w,h to x1,y1 x2,y2
                    bb_ann = annotation['bbox']
                    labels.append([bb_ann[0], bb_ann[1], bb_ann[0]+bb_ann[2], bb_ann[1]+bb_ann[3], annotation['category_id']-1])
                    text_labels.append([bb_ann[0],bb_ann[1]-8,annotation_text,annotation['category_id']-1])
                else:
                    seg_ann = annotation['segmentation']
                    labels.append([seg_ann[0],annotation['category_id']-1])
                    if len(seg_ann) > 0:
                        text_labels.append([seg_ann[0][0],seg_ann[0][1],annotation_text,annotation['category_id']-1])


        if args.bbox:
            cv2_image = abyss_deep_learning.draw.boxes(labels,
                                                       cv2_image,
                                                       args.fill,
                                                       True,
                                                       active_color_pallette,
                                                       args.annotation_alpha,
                                                       args.image_alpha,
                                                       args.border)                                      
        else:
            cv2_image = abyss_deep_learning.draw.polygons(labels,
                                            cv2_image,
                                            args.fill,
                                            True,
                                            active_color_pallette,
                                            args.annotation_alpha,
                                            args.image_alpha,
                                            args.border)

        if not args.no_text:
            cv2_image = abyss_deep_learning.draw.text(text_labels,cv2_image,active_color_pallette,font=cv2.FONT_HERSHEY_SIMPLEX, alpha=1.0, image_alpha=1, scale=args.text_scale,thickness=1)
        
        if args.view_only:
            cv2.imshow("View Only",cv2_image)
            cv2.waitKey(0)
        else:
            if args.output:
                # todo! fix: paths like this: "a/b/c/../../d/../i.png"
                s = image['path'].split('/')
                while s == '' or s[0] == '.' or s[0] == '..': s = s[1:]
                if args.path_basename:
                    output_path = os.path.split( image['path'].split('/')[1] )
                elif not args.path_trim_depth is None:
                    s = image['path'].split('/')
                    if len( s ) <= args.path_trim_depth: print("coco-draw: expected path depth of at least " + str( args.path_trim_depth ) + "; got: '" + image['path'] + "'", file=sys.stderr); sys.exit(1)
                    output_path = '/'.join( s[args.path_trim_depth:] )
                else:
                    output_path = '/'.join( s )
                output_path = args.output + "/" + output_path
                if os.path.abspath(image['path']) == os.path.abspath(output_path):
                    print( "coco-draw: input image path '" + image['path'] + "' and output image path '" + output_path + "' point to the same file; it may be a bug in coco-draw, but most likely you have a problem with your --output-directory or coco file", file=sys.stderr )
                    sys.exit( 1 )
                try:
                    os.makedirs(os.path.split(output_path)[0])
                except OSError as err:
                    if err.errno != errno.EEXIST: raise
                cv2.imwrite(output_path,cv2_image)
            else:
                if os.path.isfile(image['path']) and not args.force:
                    print("coco-draw: attempting to overwrite images. These images may be potentially your source images!!!. Please be careful\napply --force to override. Exiting.", file=sys.stderr)
                    sys.exit(1)
                else:
                    cv2.imwrite(image['path'],cv2_image)

def parse_cli():
    parser = ArgumentParser(
        description=DESCRIPTION)
    parser.add_argument('--path-basename', '--basename', action='store_true', help="output image filenames will be basenames of images")
    parser.add_argument('-o', '--output', type=str,
                        help="If specified, sets the output directory of the images, otherwise the current directory will be used as the output")
    parser.add_argument('-c', '--colors','--colours', type=str,
                        help="If specified uses json file to determine the colours for each label, otherwise deterministic defaults are used.")
    parser.add_argument('-f', '--force', action='store_true' ,
                        help="Force Overwriting of files when writing to output")
    parser.add_argument('-l', '--fill', action='store_true' ,
                        help="Fills the annotations, if this is not specified only an outline is drawn")
    parser.add_argument('--sample-colors', '--sample-colours', action='store_true' ,
                    help="Prints an example json file to stdout") 
    parser.add_argument('--view-only', '-d', action='store_true' ,
                    help="Only view images, do not write")                      
    parser.add_argument('-b', '--bbox', action='store_true' ,
                        help="If specified, draws only bounding boxes, otherwise will default to segmentation")
    parser.add_argument('--no-text', action='store_true', help="just draw, do not add text labels")
    parser.add_argument('-t', '--border', type=int, default=1,
                        help="Specifies border thinkness of annotations")
    parser.add_argument('--path-trim-depth', '--trim-depth', '--depth', type=int,
                        help="trim the initial portion of a given length from the file path")
    parser.add_argument('-u', '--annotation-alpha', type=float,default=0.4,
                        help="Sets the alpha channel of annotations. value is from 0 to 1")
    parser.add_argument('-v', '--image-alpha', type=float, default=1,
                        help="Sets the alpha channel of image. value is from 0 to 1")
    parser.add_argument('-s', '--text-scale', type=float, default=0.4,
                        help="Sets the text scale of annotations")
    return parser.parse_args()

if __name__ == '__main__':
    main(args=parse_cli())
