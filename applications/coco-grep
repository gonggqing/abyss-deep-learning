#!/usr/bin/env python3
from __future__ import print_function

import argparse
import itertools
import json
import os
import sys

from contextlib import redirect_stdout
from operator import itemgetter

from abyss_deep_learning.datasets.coco import CocoDataset

DESCRIPTION = """

Read JSON file(s) defined on command line or a list of JSON files on stdin and apply a search for images given a 
boolean expression of captions to search for. 

Examples:
    coco-grep coco.json --expression "JD and F"
    coco-merge coco_a.json coco_b.json | coco-grep --expression "RI and F"

"""


def main(args):
    json_string = ''

    # TODO: What are edge cases for this function isatty()?
    if not sys.stdin.isatty():
        for line in sys.stdin:
            stripped_line = line.strip()
            if os.path.exists(stripped_line):
                args.json_files.append(stripped_line)
            else:
                json_string += stripped_line

    # Create temporary json file and append file name to list of json files to store data to be read from COCO()
    if json_string:
        args.json_files.append(json_string)

    for json_file in args.json_files:
        with redirect_stdout(sys.stderr):
            coco_ds = CocoDataset(json_file)
            new_dataset = {
                'images': [],
                'annotations': [],
            }

        # TODO: How to handle case when user searches for caption that does not exist in data set
        # Pre-parse the dataset for all available keys
        unique_captions = {value['caption']: False for key, value in coco_ds.coco.anns.items()}

        # Find the minimum set combination satisfies the expression so as to find images that have the minimum
        # required captions

        # TODO: Refactor code, not very efficient, could be implemented better
        if args.exact_match:
            min_expr = None
            for i in range(len(unique_captions) + 1):
                combs = list(itertools.combinations(unique_captions.keys(), i))
                for comb in combs:
                    for caption in comb:
                        globals()[caption] = True
                    if eval(args.expression):
                        min_expr = set(comb)
                        break
                    for caption in comb:
                        globals()[caption] = False
                if min_expr is not None:
                    break

        globals().update(unique_captions)

        # Sort the annotations
        anns = coco_ds.coco.loadAnns(coco_ds.coco.getAnnIds())
        anns.sort(key=itemgetter('image_id', 'id'))

        curr_img_id = None
        captions = []
        for idx, ann in enumerate(anns):
            # Captions have been merged for current image
            if curr_img_id != ann['image_id']:
                if args.exact_match:
                    if set(captions) != min_expr:
                        curr_img_id = ann['image_id']
                        captions.clear()
                        continue

                for caption in captions:
                    globals()[caption] = True

                if eval(args.expression):
                    # Add the image annotations and image to the new COCO file
                    # Choose to either add all associated annotations, or only annotations in grep
                    start_id = idx - len(captions)
                    end_id = idx
                    for i in range(start_id, end_id):
                        if anns[i]['caption'] in unique_captions:
                            new_dataset['annotations'].append(anns[i])

                # Reset global captions
                for caption in captions:
                    globals()[caption] = False

                # Empty caption list for next image
                curr_img_id = ann['image_id']
                captions.clear()

            captions.append(ann['caption'])

        # Iterate through annotations and add associated images to new dataset
        for img in coco_ds.coco.loadImgs(coco_ds.coco.getImgIds()):
            img_ids = [ann['image_id'] for ann in new_dataset['annotations']]
            if img['id'] in img_ids:
                # Skip images that have been added already
                if img in new_dataset['images']:
                    continue

                new_dataset['images'].append(img)

        json.dump(new_dataset, sys.stdout, indent=4)

    sys.exit(0)


def get_args():
    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('json_files', nargs='*', type=str, help="JSON files to grep from")
    parser.add_argument('-e', '--expression', type=str, help="Boolean expression to search for image captions in an "
                                                             "image")
    parser.add_argument('-x', '--exact-match', action='store_true',
                        help="Include only images with exact match to the given label (ie not roots & joint, just roots")
    args = parser.parse_args()
    return args


if __name__ == '__main__':
    main(get_args())
