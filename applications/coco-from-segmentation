#!/usr/bin/env python3
import json
import os
import sys
from argparse import ArgumentParser
from datetime import datetime

import numpy as np
from abyss_deep_learning.utils import imread
from skimage import measure

#np.set_printoptions(threshold=np.inf)


def main(args=None):
    if args.category_id == 'from-mask':
        if args.num_classes is None:
            raise ValueError("--num-classes must be specified when passing 'from-mask' to --category-id")
        else:
            thresholds = [i / args.num_classes for i in range(1, args.num_classes + 1)]

    original_json = json.load(sys.stdin)
    with open(args.mask_file) as f:
        mask_json = json.load(f)

    coco_json = {
        'info':        original_json.get('info',
                                         {
                                             'contributor':  'Abyss Solutions',
                                             'total_time':   '00h00m00s',
                                             'year':         str(datetime.now().year),
                                             'date_created': str(datetime.now()),
                                             'description':  'This is a dataset configured by Abyss Solutions.',
                                             'version':      '1.0',
                                             'url':          'http://www.abysssolutions.com.au',
                                             }
                                         ),
        'images':      original_json.get('images', []),
        'annotations': [],
        'categories':  original_json.get('categories', []),
        'licenses':    original_json.get('licenses', [
            {
                'id':   1,
                'url':  'http://creativecommons.org/licenses/by-nc-sa/2.0/',
                'name': 'Attribution-NonCommercial-ShareAlike License',
                }
            ]
                                         )
        }
    output_annotations = coco_json['annotations']

    padding = 1
    id_2_original = {entry['id']: entry for entry in original_json['images']}
    for mask_entry in mask_json['images']:
        curr_id = mask_entry['id']
        original_entry = id_2_original.get(curr_id, None)
        if original_entry is None:
            continue
        original_mask = load_input(mask_entry)
        padded_mask = load_input(mask_entry, padding=padding)
        if args.fill_above:
            padded_mask[padded_mask > args.low_thresh] = 1.0

        category_ids = []
        category_contours = []
        mask_indices = []
        if args.category_id == 'from-mask':
            for i in range(len(thresholds)):
                category_id = i + 1
                category_ids.append(category_id)
                copy = np.array(padded_mask)
                # Mask lower threshold of previous class
                if i != 0:
                    copy[copy <= (thresholds[i - 1] + np.finfo(copy.dtype).eps)] = 0.0
                # Mask upper threshold of next class
                try:
                    copy[copy >= (thresholds[i + 1] - np.finfo(copy.dtype).eps)] = 0.0
                except IndexError:
                    pass

                found_contours = measure.find_contours(copy, thresholds[i] - np.finfo(copy.dtype).eps, fully_connected=args.fully_connected)
                category_contours.append([np.around(contour) - padding for contour in found_contours])
                mask_indices.append(copy[1:-1, 1:-1].astype(np.bool))
        else:
            padded_mask[padded_mask > args.up_thresh] = 0.0
            found_contours = (measure.find_contours(padded_mask, args.low_thresh, fully_connected=args.fully_connected))
            category_contours.append([np.around(contour) - padding for contour in found_contours])
            category_ids.append(int(args.category_id))
        for contours, category_id, mask_index in zip(category_contours, category_ids, mask_indices):
            # Mask out unnecessary pixels for score calculation
            # Segmentations that were originally holes should have a score of approximately 0
            # Segmentations that were NOT holes should have a score of approximately 1
            # This is relevant for semantic segmentation
            copy = np.zeros(original_mask.shape)
            copy[mask_index] = 1
            for contour in contours:
                approximated = measure.approximate_polygon(contour, args.tolerance)
                poly_mask = measure.grid_points_in_poly(original_mask.shape[:2], approximated)
                segmentation = np.flip(approximated, axis=1).ravel().tolist()
                points = [segmentation[n:n + 2] for n in range(0, len(segmentation), 2)]
                # polygon points found in approximated do not lie exactly on the original binary mask
                if True not in np.unique(poly_mask):
                    continue
                score = get_score(copy, poly_mask)
                # Score is rounded only if 'from-mask' is specified, i.e. if the binary mask input are from the SemanticPredictions:0 layer
                # Otherwise, score is just averaged of pixel confidence / area
                if args.category_id == 'from-mask':
                    score = round(score)
                output_annotations.append({"segmentation": [segmentation],
                                           "area":         get_area(poly_mask),
                                           "iscrowd":      0,
                                           "image_id":     original_entry['id'],
                                           "bbox":         bounding_box(points),
                                           "score":        score,
                                           "category_id":  category_id,
                                           "id":           len(output_annotations)
                                           })

    json.dump(coco_json, sys.stdout, indent=4)
    sys.exit(0)


def print_debug(*args, **kwargs):
    print("{}:".format(os.path.basename(__file__)), *args, file=sys.stderr, **kwargs)


def load_input(mask_entry, padding=0):
    width = int(mask_entry['width'])
    height = int(mask_entry['height'])
    img = np.zeros((width + padding * 2, height + padding * 2))
    _, ext = os.path.splitext(mask_entry['path'])
    if 'bin' in ext:
        img_buf = np.fromfile(mask_entry['path'], dtype=np.float32)
        img_buf = np.reshape(img_buf, (width, height))
    elif ext in {'png', 'jpg'}:
        img_buf = imread(mask_entry['path'], dtype=np.float32) / 255
    else:
        print("{}: file type {} unsupported".format(os.path.basename(__file__), ext), file=sys.stderr)
        sys.exit(1)
    img[padding: padding + height, padding: padding + width] = img_buf[:, :]
    return img


def get_area(mask):
    return np.count_nonzero(mask)


def get_score(original_mask, poly_mask):
    return original_mask[poly_mask].sum() / get_area(poly_mask)


def bounding_box(polygon, w=None, h=None):
    """Return the bounding box of a given polygon"""
    min_x, min_y = np.min(polygon, axis=0)
    max_x, max_y = np.max(polygon, axis=0)
    # Convert to native Python scalars
    # Should be a better way to do this I think
    min_x = min_x.item()
    min_y = min_y.item()
    max_x = max_x.item()
    max_y = max_y.item()
    if w is not None and h is not None:
        min_x = max(0, min_x)
        min_y = max(0, min_y)
        max_x = min(w, max_x)
        max_y = min(h, max_y)
    return [min_x, min_y, max_x - min_x, max_y - min_y]


def get_args():
    parser = ArgumentParser(
        description="The utility takes in a coco file and applies the segementations from the mask file provided as a command line argument and outputs the new coco json to stdout. If a binary file is give, assumes values are normalized between 0 and 1")
    parser.add_argument('mask_file', type=str, help="Mask JSON File")
    parser.add_argument('-c', '--category-id', type=str,
                        help="The id of the category to set the mask can be an int or from-mask. from-mask infers category based on how many unique values there are for the pixels in a segmentation mask",
                        required=True)
    parser.add_argument('-n', '--num-classes', type=int,
                        help="Number of possible classes that can be detected from the network (excluding background). Used in conjunction with from-mask.")
    parser.add_argument('-l', '--low-thresh', '--lower-threshold', type=float, default=0.0,
                        help="The lower score to threshold the image by, default: %(default)s")
    parser.add_argument('-u', '--up-thresh', '--upper-threshold', type=float, default=1.0,
                        help="The upper score to threshold the image by, default: %(default)s")
    parser.add_argument('-t', '--tolerance', '--polygon-tolerance', type=float, default=0.0,
                        help="Threshold tolerance for polygon precision (see skimage.metrics.approximate_polygon(), default: %(default)s")
    parser.add_argument('--fully-connected', help="Passed to skimage.measure.find_contours, default: %(default)s",
                        choices=['low', 'high'], default='low')
    parser.add_argument('-b', '--fill-above', '--fill-above-thresh', action='store_true',
                        help="This argument will fill the mask with 1 values if the pixel is above the threshold")
    return parser.parse_args()


if __name__ == '__main__':
    main(args=get_args())
