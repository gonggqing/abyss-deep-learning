#!/usr/bin/env python3
import argparse
import collections
import csv
import json
import sys
import copy
from contextlib import redirect_stdout

import pandas as pd
from pycocotools.coco import COCO

# TODO
# - remove
#   - coco-to-csv.deprecated
#   - coco-to-yolo3
#   - coco-to-retina-to-csv

DESCRIPTION = \
    """
Convert COCO json file and output csv formatted COCO data to stdout.

Can perform join operations between different coco sections based on arguments given to positional argument section and 
optional argument -f/--fields

examples
    General usage:
        cat coco.json | coco-to-csv annotations -f id,bbox,area,categories/name,categories/supercategory,images/file_name > annotations.csv
        cat coco.json | coco-to-csv categories -f id,name --index-from 1 > categories.csv
        cat coco.json | coco-to-csv annotations -f id,bbox, --bbox-position absolute > annotations.csv

    Retinanet usage:
        cat coco.json | coco-to-csv annotations -w retinanet > training.csv
        cat coco.json | coco-to-csv categories -w retinanet > class_mappings.csv
"""


def main(args=None):
    coco = load_coco(sys.stdin.read())
    section = coco.dataset[args.section]
    csv_writer = csv.writer(sys.stdout)

    dataset = copy.deepcopy(coco.dataset)
    for i in dataset['annotations']:
        i['annotation_id'] = i.pop('id')
    for i in dataset['categories']:
        i['category_id'] = i.pop('id')
    for i in dataset['images']:
        i['image_id'] = i.pop('id')
        i['license_id'] = i.pop('license')
    for i in dataset['licenses']:
        i['license_id'] = i.pop('id')

    if args.section != 'info':
        for i, j in zip(section, dataset[args.section]):
            j['id'] = i['id']

    section = dataset[args.section]
    fields = []
    joined = set()
    for field in args.fields:
        if len(field) == 2:
            section_to_join, field_to_index = field
            fields.append(field_to_index)
            if section_to_join in joined:
                continue
            joined.add(section_to_join)
            say("extra section found, trying to merge between {section} and {section_to_join}".format(
                section_to_join=section_to_join, section=args.section), verbose=args.verbose)
            intersection = set(section[0]).intersection(set(dataset[section_to_join][0]))
            if len(intersection) == 1:
                common_key = intersection.pop()
            elif len(intersection) > 1:
                die(
                    "More than one common key [{keys}] was found in the join for {section} and {section_to_join}".format(keys=list(intersection), section=args.section, section_to_join=section_to_join))
            else:
                die("No common key was found in the join between {section} and {section_to_join}".format(
                    section=args.section, section_to_join=section_to_join))
            i, j = pd.DataFrame(section), pd.DataFrame(dataset[section_to_join])
            df = pd.merge(i, j, on=common_key)
            section = df.to_dict('records')
        else:
            fields.append(*field)

    # Find bbox index in list
    try:
        bbox_index = fields.index('bbox')
    except ValueError:
        bbox_index = None

    # Find key index for category id
    if args.index_from is not None:
        if args.section == 'annotations':
            key = 'category_id'
        elif args.section == 'categories':
            key = 'id'
        else:
            key = None

        try:
            key_index = fields.index(key)
        except ValueError:
            key_index = None
        except TypeError:
            key_index = None

        min_value = min(coco.getCatIds())
        offset = args.index_from - min_value

    # Unpack info or license section
    if isinstance(section, dict):
        # Print headers
        if args.header:
            headers = section.keys()
            if fields:
                headers = [header for header in fields if header in section]
                non_headers = list(set(fields) - set(headers))
                if not headers:
                    die('cannot find keys {fields} in dict {section}'.format(fields=fields, section=args.section))
                if non_headers:
                    say('cannot find keys {fields} in dict {section}'.format(fields=non_headers,
                                                                             section=args.section),
                        verbose=args.verbose)
            csv_writer.writerow(headers)

        # Print values
        if fields:
            fields = [field for field in fields if field in section]
            if fields:
                values = [section[field] for field in fields]
                non_values = list(set(fields) - set(fields))
                if non_values:
                    say('cannot find keys {fields} in dict {section}'.format(fields=non_values,
                                                                             section=args.section),
                        verbose=args.verbose)
                if values:
                    csv_writer.writerow(values)
                else:
                    die('cannot find keys {fields} in dict {section}'.format(fields=values, section=args.section))
        else:
            csv_writer.writerow(section.values())

    # Unpack images, annotations or categories section
    elif isinstance(section, list):
        # Print headers
        if args.header:
            if fields:
                headers = [field for field in fields if field in section[0]]
                non_headers = list(set(fields) - set(headers))
                if not headers:
                    die('cannot find keys {fields} in dict {section}'.format(fields=fields, section=args.section))
                if non_headers:
                    say('cannot find keys {fields} in dict {section}'.format(fields=non_headers, section=args.section),
                        verbose=True)
            else:
                headers = section[0].keys()

            if bbox_index is not None:
                headers[bbox_index] = ['x', 'y', 'width', 'height'] if args.bbox_position == 'relative' else ['x1',
                                                                                                              'y1',
                                                                                                              'x2',
                                                                                                              'y2']

            csv_writer.writerow(flatten(headers))

        for entry in section:
            if fields:
                fields = [field for field in fields if field in entry]
                non_fields = list(set(fields) - set(fields))
                if fields:
                    values = [entry[field] for field in fields]
                    if bbox_index is not None:
                        x, y, width, height = bbox = values[bbox_index]
                        if args.bbox_position == 'absolute':
                            bbox[2] = x + width
                            bbox[3] = y + height
                        values[bbox_index] = bbox

                    if args.index_from is not None and key_index is not None:
                        values[key_index] += offset

                    csv_writer.writerow(flatten(values))
                else:
                    die('cannot find keys {fields} in dict {section}'.format(fields=fields, section=args.section))

                if non_fields:
                    say('cannot find keys {fields} in dict {section}'.format(fields=non_fields,
                                                                             section=args.section),
                        verbose=args.verbose)
            else:
                csv_writer.writerow(entry.values())

    sys.exit()


def say(*args, verbose=False, **kwargs):
    if verbose:
        print(*args, file=sys.stderr, **kwargs)


def die(*args, **kwargs):
    say(*args, ": quitting", verbose=True, **kwargs)
    sys.exit(1)


def get_args():
    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('section',
                        nargs='?',
                        default='annotations',
                        choices=['annotations', 'categories', 'info', 'images', 'licenses'],
                        help="General fields to extract from COCO json to csv; default: %(default)s",
                        )
    parser.add_argument('-f', '--fields', type=str, help="Comma separated values of COCO fields to extract from the "
                                                         "json file and export to a csv format. Performs a join "
                                                         "between two different sections if a '/' character is given "
                                                         "separating section and field")
    parser.add_argument('-w', '--what', choices=['retinanet'], help="Format the csv output to be compatible with one "
                                                                    "of the supported options")
    parser.add_argument('-p', '--bbox-position', type=str, default='relative', choices=['absolute', 'relative'],
                        help="Output values of bbox as either x1,y1,x2,y2 or x,y,width,height; default: %(default)s")
    parser.add_argument('-i', '--index-from', type=int, help="Change category indexing values to start "
                                                             "from specified value; default: %(default)s")
    parser.add_argument('-head', '--header', '--field-names', action='store_true',
                        help="The first row of the csv output will contain "
                             "the field names")
    parser.add_argument('-v', '--verbose', action='store_true', help="More output to stderr")
    args = parser.parse_args()

    if args.what == 'retinanet':
        if args.section == 'annotations':
            args.fields = 'images/file_name,bbox,categories/name'
            args.bbox_position = 'absolute'
        elif args.section == 'categories':
            args.fields = 'name,id'
            args.index_from = 0

    args.fields = list(map(lambda x: x.split('/'), args.fields.split(',')))

    return args


def flatten(l):
    result = []
    for el in l:
        if isinstance(el, collections.Iterable) and not isinstance(el, (str, bytes)):
            result.extend(flatten(el))
        else:
            result.append(el)
    return result


class Verbose:
    @staticmethod
    def write(line):
        line = line.strip()
        if line:
            say(line)


def load_coco(json_buffer):
    with redirect_stdout(Verbose):
        coco = COCO()
        coco.dataset = json.loads(json_buffer)
        coco.createIndex()
    return coco


if __name__ == '__main__':
    main(args=get_args())
