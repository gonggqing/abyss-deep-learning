#!/usr/bin/env python3
import argparse
import os
import sys
import importlib
from pprint import pprint
from contextlib import redirect_stdout

import numpy as np

def sanity_check_masks(dataset, num_images=4):
    import matplotlib.pyplot as plt
    # Load and display random samples
    image_ids = np.random.choice(dataset.image_ids, num_images)
    for image_id in image_ids:
        image = dataset.load_image(image_id)
        mask, class_ids = dataset.load_mask(image_id)
        visualize.display_top_masks(
            image, mask, class_ids, dataset.class_names)
        plt.show()


def train(config, args):
    config.NUM_CLASSES = args.dataset_train.num_classes
    config.STEPS_PER_EPOCH = int(
        np.ceil(args.dataset_train.num_images * args.step_mult))

    model = modellib.MaskRCNN(
        mode="training", config=config, model_dir=args.model_dir)
    exclude = ["mrcnn_class_logits", "mrcnn_bbox_fc",
               "mrcnn_bbox", "mrcnn_mask"] if args.fresh_heads else []

    if args.weights == 'last':
        model.load_weights(model.find_last()[1], by_name=True, exclude=exclude)
        print("Loaded weights. Excluded: {:s}.".format(
            str(exclude)), file=sys.stderr)
    elif args.weights == 'none':
        print(
            "WARNING: Not loading any pre-trained weights. Training fresh.", file=sys.stderr)
    elif args.weights is not None:
        model.load_weights(args.weights, by_name=True, exclude=exclude)
        print("Loaded weights. Excluded: {:s}.".format(
            str(exclude)), file=sys.stderr)
    model.train(
        args.dataset_train, args.dataset_val,
        learning_rate_multiplier=args.lr_mult,
        epochs=args.epochs,
        layers=args.layers
    )


def main(args):
    if args.cpu:
        os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
        os.environ["CUDA_VISIBLE_DEVICES"] = ""
    with redirect_stdout(sys.stderr):
        args.dataset_train = dataset_model()
        args.coco_train = args.dataset_train.load_coco(
            args.dataset_train_path, args.image_dir,
            class_ids=args.categories,
            return_coco=True
        )
        args.dataset_train.prepare()
        print('Total num classes: ', args.dataset_train.num_classes)
        # print("Loaded coco_train {:d} images".format(len(args.coco_train.imgs)))
        args.dataset_val = dataset_model()
        args.coco_val = args.dataset_val.load_coco(
            args.dataset_val_path, args.image_dir,
            class_ids=args.categories,
            return_coco=True
        )
        args.dataset_val.prepare()
        # print("Loaded coco_val {:d} images".format(len(args.coco_val.imgs)))
    if args.config is None:
        config = DefaultConfig()
    else:
        spec = importlib.util.spec_from_file_location(
            "maskrcnn_config", args.config)
        config_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(config_module)
        config = config_module.TrainConfig()
    if args.sanity_check:
        pprint(args)
        config.display()
        sanity_check_masks(args.dataset_train)
        sanity_check_masks(args.dataset_val)
    train(config, args)


def get_args():
    '''Get args from the command line args'''
    parser = argparse.ArgumentParser(
        description="Simultaneous training and validation of Resnet Mask RCNN")
    parser.add_argument(
        "config", help="Use this config file (see default MaskRCNN.config.py)", default=None)
    parser.add_argument("dataset_train_path",
                        help="Path to the coco JSON for the training set.")
    parser.add_argument("dataset_val_path",
                        help="Path to the coco JSON for the validation set.")
    parser.add_argument("epochs", help="Train this many epochs", default=1)
    parser.add_argument("model_dir", help="Path to save and load models from.")
    parser.add_argument(
        "weights",
        help="Path to pretrained weights, 'last' to load last model trained, or 'none' to train fresh.",
        default=None
    )
    parser.add_argument(
        "--categories", help="Only train on images that have this group of categories", default=None)
    parser.add_argument(
        "--cpu", help="Use CPU instead of GPU", action='store_true')
    parser.add_argument(
        "--fresh-heads", help="Randomly initialize the heads", action='store_true')
    parser.add_argument(
        "--image-dir",
        help="Base dir of the images referred to relatively from the COCO JSON",
        default=None
    )
    parser.add_argument(
        "--layers",
        help="Train only specified portion of the network, either the network heads, resnet layers 3, 4, or 5 onwards, or all the network. {heads, all, 3+, 4+, 5+}",
        default='heads'
    )
    parser.add_argument(
        "--lr-mult", help="Multiply the config LR by this", type=float, default=1.0)
    parser.add_argument(
        "--step-mult", help="Multiply the number of images per step by this", type=float, default=1.0)
    parser.add_argument(
        "--sanity-check",
        help="Show train and validation datasets to ensure that data is valid.",
        action='store_true'
    )
    # parser.add_argument("--seed", help="Set the random number generator seed.", default=False, type=int)
    # parser.add_argument("--no-augmentation", help="Do not perorm any data augmentation", action='store_true')
    args = parser.parse_args()
    args.seed = None  # Not yet implemented in Keras with Tensorflow backend
    if args.categories != None:
        args.categories = [int(i) for i in args.categories.split(',')]
    args.epochs = int(args.epochs)
    return args


if __name__ == '__main__':
    # Put ahead to make --help faster
    ARGS = get_args()

from abyss_deep_learning.abyss_dataset import CocoDataset as dataset_model
from mrcnn.config import Config as DefaultConfig
import mrcnn.model as modellib
import mrcnn.utils as utils
import mrcnn.visualize as visualize

if __name__ == '__main__':
    main(ARGS)
