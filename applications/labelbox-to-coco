#!/usr/bin/env python3
from __future__ import print_function
from contextlib import redirect_stdout
from math import floor
from urllib.parse import unquote, urlparse
from sys import stderr, stdout
import json
import os
import urllib.request

from bedrock.utils import JsonNumpyEncoder
from PIL import Image
import numpy as np
import pycocotools.mask as pcm

VERBOSE = 0

def print_v(*args, level=0):
    if VERBOSE >= level:
        print(*args, file=stderr)


def geometry_to_coco_bbox(point_list):
    """
    Converts a list of point dictionaries from LabelBox to a COCO bbox

    Args:
        point_list: list of point dictionaries with x,y as keys.

    Returns: [x,y,width,height]

    """
    x_points = [p['x'] for p in point_list]
    y_points = [p['y'] for p in point_list]
    min_x = min(x_points)
    min_y = min(y_points)
    max_x = max(x_points)
    max_y = max(y_points)
    bbox = [min_x, min_y, max_x - min_x, max_y - min_y]
    return bbox


def geometry_to_coco_mask(point_list):
    points = []
    for p in point_list:
        points.append([p['x'], p['y']])
    raise NotImplementedError("TODO") # TODO - make this work


def download_images(uris, destination='./images'):
    if destination != '.':
        os.makedirs(destination, exist_ok=True)
    for uri in uris:
        filename = os.path.basename(urlparse(unquote(uri)).path)
        file_dest = os.path.join(destination, filename)
        if not os.path.exists(file_dest): # Don't re-download
            print_v("Downloading: {:s}".format(filename), level=1)
            urllib.request.urlretrieve(uri, file_dest)


def main_coco(dataset, args):
    def demangle_coco(coco, prefix=None):
        """Note: This mutates the coco parameter"""
        def fixed_filename(file_name, prefix=None):
            basename = os.path.basename(urlparse(unquote(file_name)).path)
            return os.path.join(prefix, basename) if prefix else basename
        
        image_id_map = {image['id']: 1 + new_id for new_id, image in enumerate(coco['images'])}
        annotation_id_map = {annotation['id']: 1 + new_id for new_id, annotation in enumerate(coco['annotations'])}
        for i, _ in enumerate(image_id_map):
            coco['images'][i]['id'] = image_id_map[coco['images'][i]['id']]
            coco['images'][i]['file_name'] = fixed_filename(coco['images'][i]['file_name'], prefix=prefix)
            del coco['images'][i]['flickr_url']
            del coco['images'][i]['coco_url']
        for i, _ in enumerate(annotation_id_map):
            coco['annotations'][i]['id'] = annotation_id_map[coco['annotations'][i]['id']]
            coco['annotations'][i]['image_id'] = image_id_map[coco['annotations'][i]['image_id']]
        return coco

    if args.download:
        download_images(
            [image['coco_url'] for image in dataset['images']],
            args.download)
    return demangle_coco(dict(dataset), prefix=args.prefix)

def demangle_json(labelbox, args):
    def download_mask(mask_uri):
        req = urllib.request.urlopen(mask_uri)
        mask = np.array(Image.open(req), order='F')[..., -1] > 0
        rle = pcm.encode(mask.astype(np.uint8))
        rle['counts'] = str(rle['counts'], encoding='utf-8')
        return rle
    images = []
    annotations = []
    categories = {}
    print_v("Downloading {:d} images".format(len(labelbox)), level=1)

    for image_id, record in enumerate(labelbox):
        parts = urlparse(record['Labeled Data'])
        file_name = unquote(parts.path)[1:]
        print_v("Downloading masks: {:s}".format(file_name), level=1)

        if args.prefix:
            file_name = os.path.join(args.prefix, file_name)

        if os.path.exists(file_name):
            im = Image.open(file_name)
        else:
            # Try JPG
            if file_name.endswith('png'):
                im = Image.open(file_name.replace('png', 'jpg'))
            elif file_name.endswith('jpg'):
                im = Image.open(file_name.replace('jpg', 'png'))
            else:
                raise ValueError("File could not be found")

        width, height = im.size
        images.append({
            'id': image_id + 1,
            'file_name': file_name,
            "width": width,
            "height": height,
            "license": 0,
            "date_captured": record['Created At'],
        })
        if record['Label'] == 'Skip':
            continue
        if 'segmentationMasksByName' in record['Label']:
            for class_name, label in record['Label']['segmentationMasksByName'].items():
                if class_name == 'Background':
                    continue
                mask = download_mask(label)
                if class_name not in categories:
                    categories[class_name] = {
                        'id': len(categories) + 1,
                        'name': class_name,
                        'supercategory': '',
                    }
                annotations.append({
                    'id': len(annotations) + 1,
                    'image_id': image_id + 1,
                    'category_id': categories[class_name]['id'],
                    'segmentation': mask,
                    'area': int(pcm.area(mask)),
                    'bbox': pcm.toBbox(mask),
                    'iscrowd': 0
                })
        else:  # A vector annotation - its a list of classes
            for class_name, labels in record['Label'].items():
                if class_name not in categories:
                    categories[class_name] = {
                        'id': len(categories) + 1,
                        'name': class_name,
                        'supercategory': '',
                    }
                for lab in labels:
                    bbox = geometry_to_coco_bbox(lab['geometry'])
                    annotations.append({
                        'id': len(annotations) + 1,
                        'image_id': image_id + 1,
                        'category_id': categories[class_name]['id'],
                        # 'segmentation': geometry_to_coco_mask(),
                        'area': bbox[2]*bbox[3],
                        'bbox': bbox,
                        'iscrowd': 0
                    })


    coco = {
        'images': images,
        'annotations': annotations,
        'categories': list(categories.values())
    }
    return coco

def main_json(dataset, args):
    if args.download:
        download_images(
            [image['Labeled Data'] for image in dataset],
            args.download)
    return demangle_json(dataset, args)
    
def main(args):
    with open(args.input_path, "r") as file_in:
        dataset = json.load(file_in)

    if args.format == 'coco':
        # Convert Labelbox COCO to Abyss COCO
        coco = main_coco(dataset, args)
    elif args.format == 'json':
        # Convert Labelbox JSON to Abyss COCO (pixelwise only)
        coco = main_json(dataset, args)
    else:
        raise ValueError("Unknown dataset format '{:s}'".format(args.format))
    stdout.write(json.dumps(coco, cls=JsonNumpyEncoder))
    

def get_args():
    global VERBOSE
    import argparse

    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawTextHelpFormatter,
        description="""
Convert a LabelBox COCO JSON into an Abyss COCO JSON.

The following changes are made:
    * Remap image and annotation IDs from string to int
    * Remap image filename from URL to image basename
    * Remove image flickr URL and COCO URL
Additionally, with options:
    --prefix: Add this prefix to the image file_name (change relative path or make absolute)
    --download: Download the dataset into given dir, before continuing."""
    )
    parser.add_argument(
        'input_path', type=str,
        help="Path to the coco JSON.")
    parser.add_argument(
        'format', type=str,
        help="The type of labelbox format, one of {coco, json}")
    parser.add_argument(
        '--output-dir',
        default="./annotations", type=str,
        help="Path to output the annotations (default ./annotations)")
    parser.add_argument(
        '--prefix',
        default=None, type=str,
        help="If present, set the path attribute for each image to '<prefix>/<file_name>'."
    )
    parser.add_argument(
        '--download',
        default=None, type=str,
        help="Download dataset to this path")
    parser.add_argument(
        '--verbose', action='store_true', help="verbose output to stderr")
    args = parser.parse_args()
    VERBOSE = int(args.verbose)
    return args


if __name__ == '__main__':
    main(get_args())
