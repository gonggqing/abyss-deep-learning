#!/usr/bin/env python3

__author__ = 'Kent Hu, and Seva'
__maintainer__ = 'Kent Hu'
import argparse
import array
import copy
import json
import logging
import math
import numbers
import sys
import time
import typing
from collections import namedtuple
from abyss_deep_learning.datasets.coco_utilities import coco_is_valid

import pandas as pd

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.expand_frame_repr', False)
pd.set_option('max_colwidth', -1)

_DESCRIPTION = \
    """
Read COCO json file piped in from stdin and write to stdout COCO json output.

Select on two keywords image or annotation:
    if on == 'images':
        evaluate the expression on a per image basis and select all their associated annotations
        
    elif on == 'annotations':
        evaluate the expression on a per annotation basis and select the associated image

Generate an expression based on existing fields in COCO format
    annotations can be searched by
        a.id    Search by id
        a.bbox  Search by bbox
        a.area  Search by area
        etc
        
    images can be searched by
        i.id    Search by id
        i.path  Search by path
        i.width Search by width
        etc
        
    categories can be searched by
        c.id    Search by id
        c.name  Search by name

examples:
    cat pf.json | coco-select annotations "a.id == 4"
    cat pf.json | coco-select annotations "c.id == 4"
    cat pf.json | coco-select annotations "c.name == 'PF-H'"
    
    cat pf.json | coco-select images "c.name == 'PF-H'"
    cat pf.json | coco-select images "c.id == 4"   
"""


def main(args):
    logging.basicConfig(format='%(filename)s: %(asctime)s.%(msecs)d: %(levelname)s: %(message)s',
                        datefmt='%Y-%m-%d %H:%M:%S',
                        level=args.loglevel)
    # pd.set_option('display.expand_frame_repr', False)
    tic = time.perf_counter()
    logging.info("Search expressions is [{}]".format(args.expression))

    # Empty file check
    if len(args.input_file) > 0:
        with open(args.input_file, 'r') as file_handle:
            buffer = file_handle.read().strip()
            data = json.loads(buffer)
    else:
        buffer = sys.stdin.read().strip()
        if buffer:
            data = json.loads(buffer)
        else:
            logging.error("Expecting input from stdin: received empty characters {}".format(repr(buffer)))
            sys.exit(1)

    if not coco_is_valid('stdin', data, args.validation):
        sys.exit(1)

    if args.on == 'annotations' and len(data.get('annotations', [])) == 0:
        logging.warning("Got empty annotations, input passed through to stdout")
        json.dump(data, sys.stdout, indent=args.indent)
        sys.exit(0)

    for annotation in data.get('annotations', []):
        annotation['annotation_id'] = annotation.pop('id')

    for image in data.get('images', []):
        image['image_id'] = image.pop('id')

    for category in data.get('categories', []):
        category['category_id'] = category.pop('id')

    df_annotations = create_data_frame(data.get('annotations', []))
    df_images = create_data_frame(data.get('images', []))
    df_categories = create_data_frame(data.get('categories', []))

    annotation_keys = df_annotations.keys()
    image_keys = df_images.keys()
    category_keys = df_categories.keys()

    logging.info("Joining annotations, categories and images")

    if not df_categories.empty and not df_annotations.empty:
        df = pd.merge(left=df_images, right=df_annotations, on='image_id', how='left')
        df = pd.merge(left=df, right=df_categories, on='category_id', how='left')
    else:
        df = df_images

    Keys = namedtuple("Keys", ['ann_keys', 'img_keys', 'cat_keys'])
    keys = Keys(ann_keys=annotation_keys, img_keys=image_keys, cat_keys=category_keys)

    logging.info("Evaluating on {}".format(args.on))
    if args.on == 'images':
        df = eval_on(df, args, keys, 'image_id')
    elif args.on == 'annotations':
        df = eval_on(df, args, keys, 'annotation_id')

    annotations = []
    df_annotations = df[annotation_keys].drop_duplicates(['annotation_id'])
    if not df_annotations.empty:
        for record in df_annotations.itertuples():
            if not math.isnan(record.annotation_id):
                annotation = record_to_dict(record, 'annotation_id')
                # Remove nan fields: val == val is always true unless val is NaN
                annotation = {key: val for key, val in annotation.items() if val == val}
                annotations.append(annotation)
    data['annotations'] = annotations

    if not args.keep_images:
        images = []
        df_images = df[image_keys].drop_duplicates(['image_id'])
        if not df_images.empty:
            for record in df_images.itertuples():
                if not math.isnan(record.image_id):
                    image = record_to_dict(record, 'image_id')
                    # Remove nan fields: val == val is always true unless val is NaN
                    image = {key: val for key, val in image.items() if val == val}
                    images.append(image)
        data['images'] = images

    if not args.keep_categories:
        categories = []
        df_categories = df[category_keys].drop_duplicates(['category_id'])
        if not df_categories.empty:
            for record in df_categories.itertuples():
                if not math.isnan(record.category_id):
                    category = record_to_dict(record, 'category_id')
                    # Remove nan fields: val == val is always true unless val is NaN
                    category = {key: val for key, val in category.items() if val == val}
                    categories.append(category)
        data['categories'] = categories

    logging.info("Printing to stdout")
    json.dump(data, sys.stdout, indent=args.indent)
    logging.info("Done in {elapsed_time}s".format(elapsed_time=time.perf_counter() - tic))
    sys.exit(0)


def create_data_frame(data: dict) -> pd.DataFrame:
    df = pd.DataFrame(data)
    values = {}
    invalid_values = []
    for column_name in df:
        try:
            values[column_name] = df[column_name].mode()[0]
        except IndexError:
            invalid_values.append(column_name)
        except TypeError:
            invalid_values.append(column_name)
    return df


def to_tuple(entry_: list):
    return tuple(to_tuple(i) if isinstance(i, list) else i for i in entry_)


def drop_duplicates_by_id(list_: list):
    id_set = set()
    result = list()
    for entry in list_:
        id = entry['id']
        if id not in id_set:
            id_set.add(id)
            result.append(entry)
    return  result


def record_to_dict(record: namedtuple, re_id: str) -> dict:
    dict_ = record._asdict()
    dict_['id'] = dict_.pop(re_id)
    dict_.pop('Index')
    return dict_


def eval_on(df: pd.DataFrame, args: argparse.Namespace, keys: namedtuple, on_id: str) -> pd.DataFrame:
    ids = set()
    df_images = df[keys.img_keys].rename(index=str, columns={'image_id': 'id'})
    df_categories = df[keys.cat_keys].rename(index=str, columns={'category_id': 'id'})
    df_annotations = df[keys.ann_keys].rename(index=str, columns={'annotation_id': 'id'})

    try:
        exec(args.init)
    except TypeError:
        pass

    for a, i, c in zip(df_annotations.itertuples(), df_images.itertuples(), df_categories.itertuples()):
        idx = int(a.Index)
        if eval(args.expression, locals()):
            ids.add(df.iloc[idx][on_id])

    # Index later so that indexing into list doesn't go out of bounds as df shrinks
    df = df.loc[df[on_id].isin(ids)]
    return df


def get_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=_DESCRIPTION,
                                     formatter_class=argparse.RawTextHelpFormatter, )
    parser.add_argument('on',
                        type=str,
                        choices={'images', 'annotations'},
                        help="How to search and select images and annotations. If on is 'image', then evaluate the "
                             "expression on a per image basis and for images that satisfy the expression, select all "
                             "associated annotations. If on is 'annotation', then evaluate the expression on a per "
                             "annotation basis and for annotations that satisfy the expression, select all associated "
                             "images.")
    parser.add_argument('expression', type=str, help="General expression to search for images.", )
    parser.add_argument('-i', '--init', type=str, help="General python code to run at the start of the script")
    parser.add_argument('-in', '--input_file', type=str, help="Read COCO JSON from file (default stdin)", default="")
    parser.add_argument('-m', '--min', action='store_const', const=None, default=4, dest='indent',
                        help="Disable JSON pretty print.")
    parser.add_argument('--keep-categories', action='store_true',
                        help='Carry over all categories from original COCO JSON file.')
    parser.add_argument('--keep-images', action='store_true',
                        help='Carry over all images from original COCO JSON file.')
    parser.add_argument('--validation',
                        type=str,
                        default='standard',
                        choices={'standard', 'strict', 'skip'},
                        help="Check if input coco is valid:\n"
                             "standard: quick checks(default)\n"
                             "strict: more in-depth cross-reference checks\n"
                             "skip: if you know coco is valid and want quicker execution.")

    logging_group = parser.add_mutually_exclusive_group()
    logging_group.add_argument('-v', '--verbose', action='store_const', const=logging.INFO, dest='loglevel', help="Verbose output to stderr.")


    logging_group.add_argument('-d', '--debug', action='store_const', const=logging.DEBUG, dest='loglevel', help="Debug output to stderr")
    return parser.parse_args()


if __name__ == '__main__':
    main(get_args())
