#!/usr/bin/env python3
import argparse
import json
import os
import sys
from abyss_deep_learning import metrics

description = """

calculate metrics on predictions vs labels

run coco-metrics <operation> --help for operation option    
"""

tfpn_description = """

take predictions.json, truth.json, output to stdout coco annotations labeled as TP, FP, TN

usage: cat predictions.json | coco-metrics --truth truth.json > tfpn.json

limitations:
    - categories in predictions.json and truth.json should be the same, no checks performed
    - output annotation ids do NOT match the prediction or ground thruth ids, since there is
      no way to make them unique across output; todo: work out required semantics (e.g.
      optionally output one category, e.g. TP, only)
"""

def tfpn(args):
    predictions = json.loads(sys.stdin.read())
    f = open(args.truth)
    truth = json.loads(f.read())
    category_ids = []
    for c in truth['categories']: category_ids.append(c['id'])
    images = {}
    iou_matrix = None
    if args.bounding_boxes:
        for annotation in predictions['annotations']:
            if 'score' in annotation and annotation['score'] < args.score_threshold: continue
            image_id = annotation['image_id']
            category_id = annotation['category_id']
            if not category_id in category_ids:
                print( 'coco-metrics: expected category id in', category_ids, '; got:', category_id, '; discarded', file = sys.stderr )
                continue
            if not image_id in images: images[image_id] = {}
            if not category_id in images[image_id]: images[image_id][category_id] = ( [], [], [], [] )
            bbox = annotation['bbox']
            images[image_id][category_id][0].append( [ bbox[1], bbox[0], bbox[1] + bbox[3], bbox[0] + bbox[2] ] )
            images[image_id][category_id][1].append( annotation['id'] ) # quick and dirty
        for annotation in truth['annotations']:
            image_id = annotation['image_id']
            if image_id not in images: images[image_id] = {}
            category_id = annotation['category_id']
            if not category_id in images[image_id]: images[image_id][category_id] = ( [], [], [], [] )
            bbox = annotation['bbox']
            images[image_id][category_id][2].append( [ bbox[1], bbox[0], bbox[1] + bbox[3], bbox[0] + bbox[2] ] )
            images[image_id][category_id][3].append( annotation['id'] ) # quick and dirty
        iou_matrix = metrics.bbox_iou_matrix
    if iou_matrix is None: print( 'coco-metrics: only bounding boxes are currently supported', file = sys.stderr ); sys.exit( 1 )
    match = eval( 'metrics.' + args.match ) # quick and dirty
    result = {}
    result['annotations'] = []
    id = 0
    def bbox_to_coco( box ): return [ box[1], box[0], box[3] - box[1], box[2] - box[0] ]
    for image_id, image in images.items():
        for category_id, annotations in image.items():
            if len( annotations[0] ) == 0:
                fp = []
                tn = []
                fn = [ *range( len( annotations[2] ) ) ]
            else:
                if len( annotations[2] ) == 0:
                    fp = [ *range( len( annotations[0] ) ) ]
                    tn = []
                    fn = []
                else:
                    ious = iou_matrix( annotations[0], annotations[2] ) # todo: if too slow, remove; used only to calculate score as iou
                    tp, fp, tn, fn = metrics.tp_fp_tn_fn( annotations[0], annotations[2], args.iou_threshold, match )
                    category_id_offset = 0 if args.flat_categories else ( category_id - 1 ) * 4
                    for k in range( len( tp[0] ) ):
                        result['annotations'].append( { "image_id": image_id
                                                      , "bbox": bbox_to_coco( annotations[0][tp[0][k]] )
                                                      , "id": id # annotations[1][tp[0][k]]
                                                      , "score": ious[tp[0][k],tp[1][k]]
                                                      , "category_id": 1 + category_id_offset } )
            for j in fp:
                result['annotations'].append( { "image_id": image_id
                                              , "bbox": bbox_to_coco( annotations[0][j] )
                                              , "id": id # annotations[1][j]
                                              , "category_id": 2 + category_id_offset } )
            for j in tn:
                result['annotations'].append( { "image_id": image_id
                                              , "bbox": bbox_to_coco( annotations[2][j] )
                                              , "id": id # annotations[3][j]
                                              , "category_id": 3 + category_id_offset } )
            for j in fn:
                result['annotations'].append( { "image_id": image_id
                                              , "bbox": bbox_to_coco( annotations[2][j] )
                                              , "id": id # annotations[3][j]
                                              , "category_id": 4 + category_id_offset } )
            id += 1
    result['categories'] = []
    if args.flat_categories:
        result['categories'] += [ { 'name': 'TP', 'supercategory': '', 'id': 1 }
                                , { 'name': 'FP', 'supercategory': '', 'id': 2 }
                                , { 'name': 'TN', 'supercategory': '', 'id': 3 }
                                , { 'name': 'FN', 'supercategory': '', 'id': 4 } ]
    else:
        for c in truth['categories']:
            category_id_offset = ( c['id'] - 1 ) * 4
            result['categories'] += [ { 'name': c['name'] + ',TP', 'supercategory': c['name'], 'id': category_id_offset + 1 }
                                    , { 'name': c['name'] + ',FP', 'supercategory': c['name'], 'id': category_id_offset + 2 }
                                    , { 'name': c['name'] + ',TN', 'supercategory': c['name'], 'id': category_id_offset + 3 }
                                    , { 'name': c['name'] + ',FN', 'supercategory': c['name'], 'id': category_id_offset + 4 } ]
    result['images'] = truth['images']
    json.dump(result, sys.stdout, indent=4)

def get_args():
    parser = argparse.ArgumentParser(description=description, formatter_class=argparse.RawDescriptionHelpFormatter)
    subparsers = parser.add_subparsers(title="operations", help="available operations")
    tfpn_parser = subparsers.add_parser('tfpn', description=tfpn_description, help="take predictions.json, truth.json, output to stdout coco annotations labeled as TP, FP, TN", formatter_class=argparse.RawDescriptionHelpFormatter)
    tfpn_parser.set_defaults( func=tfpn )
    tfpn_parser.add_argument( '--bounding-boxes', '--bbox', '-b', action='store_true', help="match bounding boxes" )
    tfpn_parser.add_argument( '--flat-categories', '--flat', action='store_true', help="output just four categories: TP, FP, TN, and FN" )
    tfpn_parser.add_argument( '--iou-threshold', default=0.5, type=float, help="iou threshold; default: %(default)s" )
    tfpn_parser.add_argument( '--match', default='one_to_one', type=str, help="how to match, 'one_to_one' or 'one_to_many'; default: %(default)s" )
    tfpn_parser.add_argument( '--score-threshold', default=0.5, type=float, help="score threshold: default: %(default)s" )
    tfpn_parser.add_argument( '--truth', '-t', type=str, help="ground truth coco.json file" )
    return parser.parse_args()

def main():
    args = get_args()
    args.func(args)
    
if __name__ == '__main__':
    main()
