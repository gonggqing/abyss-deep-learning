#!/usr/bin/env python3
from __future__ import print_function
from contextlib import redirect_stdout
from pprint import pprint
import argparse
import importlib
import json
import os
import sys

from scipy.ndimage.measurements import center_of_mass
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from abyss.utils import JsonNumpyEncoder
from abyss_deep_learning.metrics import result_to_series, calc_image_stats

def sanity_check_masks(dataset, num_images=4):
    # Load and display random samples
    image_ids = np.random.choice(dataset.image_ids, num_images)
    for image_id in image_ids:
        image = dataset.load_image(image_id)
        mask, class_ids = dataset.load_mask(image_id)
        visualize.display_top_masks(
            image, mask, class_ids, dataset.class_names)


def get_ax(rows=1, cols=1, size=8):
    return plt.subplots(rows, cols, figsize=(size*cols, size*rows))[1]

def display_gt(dataset, image_id, ax=None):
    image = dataset.load_image(image_id)
    mask, class_ids = dataset.load_mask(image_id)
    bbox = utils.extract_bboxes(mask)
    visualize.display_instances(
        image, bbox, mask, class_ids, dataset.class_names, ax=ax)

def calc_position_error(mask1, mask2):
    pos1 = np.array(center_of_mass(mask1 > 0))
    pos2 = np.array(center_of_mass(mask2 > 0))
    return np.sqrt(np.sum((pos1 - pos2) ** 2.0))

def compute_centroid_errors(gt_boxes, gt_class_ids, gt_masks,
                            pred_boxes, pred_class_ids, pred_scores, pred_masks,
                            iou_thresh=0.5):
    raise NotImplementedError()

def calc_stats(dataset):
    TP, FP, FN = dataset['TP'].sum(), dataset['FP'].sum(), dataset['FN'].sum()
    return {
        'precision': TP / (TP + FP),
        'recall': TP / (TP + FN), # True positive rate
        'F1': 2 * TP / (2*TP + FP + FN),
    }

def calc_dataset_metrics(dataset, matching='one-to-one'):
    dataset_stats = []
    for class_id, group in dataset[dataset['match'] == matching].groupby('class_id'):
        class_stats = calc_stats(group)
        class_stats['class_id'] = class_id
        dataset_stats.append(class_stats)
    return pd.DataFrame(dataset_stats).set_index('class_id')

def test(config, args):
    config.NUM_CLASSES = args.dataset_test.num_classes
    model = modellib.MaskRCNN(
        mode="inference", config=config, model_dir=args.model_dir)
    if args.weights == 'last':
        model.load_weights(model.find_last()[1], by_name=True)
    elif args.weights is not None:
        model.load_weights(args.weights, by_name=True)
    print("Loaded weights! Beginning testing.", file=sys.stderr)

    class_names = [
        i[1] for i in
        sorted([
            (cat['id'], cat['name'])
            for cat in args.dataset_test.class_info],
            key=lambda x: x[0]
        )
    ]
    match_kinds = ['one-to-one', 'many-to-one', 'many-to-many']
    dataset_stats = []
    for image_id in args.dataset_test.image_ids:
        # Load image and ground truth data
        image, image_shape, gt_class_ids, gt_bbox, gt_mask = \
            modellib.load_image_gt(
                args.dataset_test, config, image_id, use_mini_mask=False)
        molded_images = np.expand_dims(modellib.mold_image(image, config), 0)
        predicted = model.detect([image], verbose=0)[0]
        # print(predicted)
        predicted = result_to_series(predicted)
        object_gts = result_to_series({
            'rois': gt_bbox[:, :4],
            'masks': gt_mask,
            'class_ids': gt_class_ids
        })
        for matching in match_kinds:
            image_stats = calc_image_stats(
                predicted, object_gts, iou_thresh=args.iou, matching=matching)
            for class_stats in image_stats:
                class_stats['image_id'] = image_id
            dataset_stats.append(pd.DataFrame(image_stats))
    
    dataset_stats = pd.concat(dataset_stats).reset_index(drop=True)
    dataset_metrics = {
        match_kind: calc_dataset_metrics(dataset_stats, match_kind).to_dict()
        for match_kind in match_kinds
    }

    print(json.dumps( #TODO Uncomment
        dataset_metrics, sort_keys=True, indent=0, separators=(',', ':'), cls=JsonNumpyEncoder))

def main(args):
    if args.cpu:
        os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
        os.environ["CUDA_VISIBLE_DEVICES"] = ""
    with redirect_stdout(sys.stderr):
        args.dataset_test = dataset_model()
        args.dataset_test.load_coco(
            args.dataset_test_path, image_dir=args.image_dir, class_ids=args.categories)
        args.dataset_test.prepare()
    spec = importlib.util.spec_from_file_location(
        "maskrcnn_config", args.config)
    config_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(config_module)
    config = config_module.InferenceConfig()
    if args.sanity_check:
        pprint(args, file=sys.stderr)
        config.display()
        sanity_check_masks(args.dataset_test)
    test(config, args)


def get_args():
    '''Get args from the command line args'''
    parser = argparse.ArgumentParser(
        description="Statistical testing of Resnet Mask RCNN")
    parser.add_argument(
        "config", help="Use this config file (see default MaskRCNN.config.py)", default=None)
    parser.add_argument("dataset_test_path",
                        help="Path to the coco JSON for the testing set.")
    parser.add_argument("model_dir", help="Path to save and load models from.")
    parser.add_argument(
        "weights",
        help="Path to pretrained weights, or 'last' to load last model trained.",
        default=None
    )
    parser.add_argument(
        "--categories", help="Only train on images that have this group of categories", default=None)
    parser.add_argument(
        "--cpu", help="Use CPU instead of GPU", action='store_true')
    parser.add_argument(
        "--image-dir",
        help="Base dir of the images referred to relatively from the COCO JSON",
        default=None
    )
    parser.add_argument(
        "--iou", help="IoU threshold for stats.", default=0.5, type=float)
    parser.add_argument(
        "--sanity-check",
        help="Show train and validation datasets to ensure that data is valid.",
        action='store_true'
    )
    parser.add_argument(
        "--show", help="Display outputs interactively.", action='store_true')
    args = parser.parse_args()
    if args.categories != None:
        args.categories = [int(i) for i in args.categories.split(',')]
    return args


if __name__ == '__main__':
    # Put ahead to make --help faster
    ARGS = get_args()

from abyss_deep_learning.abyss_dataset import CocoDataset as dataset_model
import abyss_maskrcnn.coco as coco
import abyss_maskrcnn.model as modellib
import abyss_maskrcnn.utils as utils
import abyss_maskrcnn.visualize as visualize

if __name__ == '__main__':
    main(ARGS)
