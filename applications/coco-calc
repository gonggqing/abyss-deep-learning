#!/usr/bin/env python3
import argparse
import copy
import itertools
import json
import logging
import os
import sys
from ast import literal_eval
from contextlib import redirect_stdout
from operator import itemgetter
from typing import List

import numpy as np
from PIL import Image
from pycocotools.coco import COCO

from abyss_deep_learning.metrics import poly_intersection_area
from abyss_deep_learning.utils import poly_area, imwrite, imread, do_overlap, poly_x, poly_y

__author__ = 'Kent Hu, Vsevolod Vlaskine'

_ASSIGN_NEW_IMAGE_IDS_DESCRIPTION = """
Read in COCO file from stdin and reassigned the image ids of incoming COCO file based on the image ids from
the command line COCO. The new ids are matched by the file_name of either COCO files

Input COCO file from stdin is output to stdout.

If no COCO file is passed in, the input COCO file can have new image ids assigned based on the existing ordering or
the input COCO file can be sorted based on a field in 'images' and then have new ids assigned based on the ordering

examples:
    cat input.json | coco-calc assign-new-image-id coco coco.json --key file_name # Match by key and assign new ids to input COCO from command line COCO 
    cat input.json | coco-calc assign-new-image-id sort --key file_name # Sort the images by a key then assign new ids, if no key, assign image ids based on existing ordering
"""

_DESCRIPTION = """
Read COCO json file piped in from stdin or a list of COCO json files and apply image manipulation and 
processing. Output new COCO json file with relevant changes to the data and if output images is specified, 
output an image directory in the current working directory with all modified images.

RLE not currently supported for segmentation resizing
tile action is currently dummy action for demonstration purposes

examples:
    remap
        cat pf.json | coco-calc remap "{1:1,2:1,3:1,4:1}" --categories '{ "id": 1, "name": "PF" }'
        cat pf.json | coco-calc remap "{'PF-G':'PF','PF-L':'PF','PF-M':'PF','PF-H':'PF'}"

    resize
        cat coco.json | coco-calc resize --factor 0.3
        cat coco.json | coco-calc --verbose resize --size 480,640

    tile
        cat coco.json | coco-calc --apply-to-images tile --tiles 4,5
"""

_CROP_DESCRIPTION = """
Crop images and labels; currently supports only cropping images

example
    cat crop.json | applications/coco-calc -v crop --size 513,513 --point --apply-to-images --fit
    
"""

_INTERSECT_DESCRIPTION = """
Output intersecting polygons from stdin JSON with command line JSON in format of 
<image-id>,<first-polygon-id>,<second-polygon-id>,<first-polygon-area>,<second-polygon-area>,<intersection-area>
"""

_NMS_DESCRIPTION = """
Non Max Suppression
Remove non max overlapping bounding boxes
"""

_REMAP_DESCRIPTION = """
Remaps categories entry in a COCO json file based on its own existing
categories or a --target-categories can be given to remap existing categories
to new ones

examples
    Remap all categories in pf.json to a single category defined on the command line
    cat pf.json | coco-calc remap "{1:0, 2:0, 3:0, 4:0}" \
            --target-categories "[{'id': 0, 'name': 'PF', 'supercategory': ''}]" | sponge pf.json

    Remap category 1 to 0 and category 3 to 4 using the input COCO json as a source of categories to take from
    cat pf.json | coco-calc remap "{1:0, 3:4}" | sponge pf.json
"""

_REPATH_DESCRIPTION = """
Read coco file from stdin and re-path all images.

Output coco json contents in stdout.

examples:
    cat coco.json | coco-calc repath images
    cat coco.json | coco-calc repath /mnt/rhino/processed/industry-data/anadarko/images
"""

_RESIZE_DESCRIPTION = """
Resize images in a given coco json file. Image dimensions can be specified by [width],[height] or by a 
scaling factor to enlarge or reduce. Specify -o/--output-images with an output image directory which 
will write the new directory, if not created, in the current directory with the new images.

examples
    cat coco.json | coco-calc resize --factor 0.3
    cat coco.json | coco-calc --verbose resize --size 480,640
"""


def main(args: argparse.Namespace) -> int:
    # Setup logging of default warnings and verbose print
    logging.basicConfig(
        level=args.loglevel,
        datefmt='%Y-%m-%d %H:%M:%S',
        format='%(filename)s: %(asctime)s.%(msecs)d: %(levelname)s: %(message)s',
    )

    try:
        if args.output_fields:
            print(args.output_fields, file=sys.stdout)
            return 0
    except AttributeError:
        pass
    try:
        coco = args.func(load_coco(sys.stdin.read()), args)
    except AttributeError:
        get_args(['--help'])
    else:
        if coco.dataset is None:
            logging.warning("Output coco is empty.")
        else:
            json.dump(coco.dataset, sys.stdout, indent=args.indent)
    logging.shutdown()
    return 0


def crop(coco: COCO, args: argparse.Namespace) -> COCO:
    if not args.point:
        logging.error(
            "crop: Operation currently not supported if crop points are not annotated as 'points', "
            "please use abyss-annotation-tool to label crop points"
        )
        sys.exit(1)
    crop_width, crop_height = [int(i) for i in args.size.split(',')]
    if args.apply_to_images:
        os.makedirs(args.image_output_dir, exist_ok=True)
    imgs_out = []
    anns_out = []
    for img_entry in coco.dataset['images']:
        if os.path.isfile(img_entry['path']):
            out_path = img_entry['path']
        else:
            logging.error("crop: Image at {} not found".format(img_entry['path']))
            sys.exit(1)
        basename = os.path.basename(out_path)
        filename, _ = os.path.splitext(basename)
        stubname = os.path.join(args.image_output_dir, filename)
        anns = coco.loadAnns(coco.getAnnIds(img_entry['id']))
        if not any(ann_entry.get('annotation_type') == 'point' for ann_entry in anns):
            logging.info("crop: No cropping points for image {}".format(img_entry.get('id', -1)))
            continue
        img = imread(img_entry['path'])
        for ann_entry in anns:
            # Find crops from points defined in 'annotations'
            if ann_entry.get('annotation_type') != 'point':
                continue  # TODO: point selection quick and dirty for now; implement better usage semantics

            offset_x = int(ann_entry['bbox'][0]) - int(crop_width / 2)
            offset_y = int(ann_entry['bbox'][1]) - int(crop_height / 2)
            max_offset_x = img_entry['width'] - crop_width
            max_offset_y = img_entry['height'] - crop_height
            if args.fit:
                # Align image to border if crop goes out of image width or height
                offset_x = min(max(offset_x, 0), max_offset_x)
                offset_y = min(max(offset_y, 0), max_offset_y)
            elif offset_x < 0 or offset_y < 0 or offset_x >= max_offset_x or offset_y >= max_offset_y:
                logging.warning(
                    "crop: Discarded annotation with crop beyond image height and width "
                    "(or please use --fit to align the crop to image height and width): "
                    "annotation id: {} image: {}".format(ann_entry['id'], img_entry['path'])
                )
                continue
            cropped = img[offset_y: offset_y + crop_height, offset_x: offset_x + crop_width]
            out_path = stubname + '.' + str(ann_entry['id']) + '.png'
            cropped_entry = {
                'file_name': os.path.basename(out_path),
                'path': out_path,
                'id': len(imgs_out),
                'height': crop_height,
                'width': crop_width,
            }
            imgs_out.append(cropped_entry)
            for ann_entry in anns:
                if ann_entry.get('annotation_type') == 'point':
                    continue  # TODO: better semantics
                cropped_ann = copy.deepcopy(ann_entry)
                x, y, width, height = ann_entry['bbox']
                x -= offset_x
                y -= offset_y
                if not do_overlap((x, y, x + width, y + height), (0, 0, crop_width, crop_height)):
                    continue

                cropped_bbox = crop_bbox(ann_entry, crop_height, crop_width, (x, y, width, height), args.keep_partial)
                cropped_ann['bbox'] = cropped_bbox
                cropped_poly = None
                if isinstance(ann_entry['segmentation'], list):
                    cropped_poly = crop_poly(ann_entry, crop_height, crop_width, offset_x, offset_y, args.keep_partial)
                    cropped_ann['segmentation'] = [cropped_poly]
                elif isinstance(ann_entry['segmentation'], dict):
                    logging.warning('crop: TODO RLE annotations, currently discards these annotations')
                    continue
                cropped_ann['id'] = len(anns_out)
                cropped_ann['image_id'] = cropped_entry['id']
                if cropped_bbox is None or cropped_poly is None:
                    continue
                cropped_ann['area'] = poly_area(np.array(cropped_poly[::2]), np.array(cropped_poly[1::2]))
                anns_out.append(cropped_ann)
            if args.apply_to_images:
                imwrite(cropped, out_path)
    coco.dataset['images'] = imgs_out
    coco.dataset['annotations'] = anns_out
    return coco


def crop_bbox(ann_entry, crop_height, crop_width, bbox, keep_partial):
    x, y, width, height = bbox
    if not keep_partial and (x < 0 or y < 0 or x + width >= crop_width or y + height >= crop_height):
        logging.warning("Skipping bbox {}, specify --keep-partial to keep partial cropped bbox".format(ann_entry['id']))
        return None
    if x < 0:
        width += x
        x = 0
    if y < 0:
        height += y
        y = 0
    width = min(crop_width - x, width)
    height = min(crop_height - y, height)
    return x, y, width, height


def crop_poly(ann_entry, crop_height, crop_width, offset_x, offset_y, keep_partial):
    cropped_polygon = []
    polygon = ann_entry.get('segmentation', [[]])[0]
    for x, y in grouper(polygon, 2):
        x -= offset_x
        y -= offset_y
        if not keep_partial and (x < 0 or y < 0 or x >= crop_width or y >= crop_height):
            logging.warning(
                """Skipping segmentation {}, 
                specify --keep-partial to keep partial cropped segmentation""".format(ann_entry.get('id', -1))
            )
            return None
        x = min(max(0, x), crop_width)
        y = min(max(0, y), crop_height)
        cropped_polygon += [x, y]
    return cropped_polygon


def remap(coco: COCO, args: argparse.Namespace) -> COCO:
    # literal_eval allows usage of either single quote (') or double quote(") to interpret a json string
    if os.path.isfile(args.mapping):
        with open(args.mapping) as f:
            mapping = {category['name']: category['id'] for category in json.load(f)['categories']}
    else:
        mapping = literal_eval(args.mapping)

    source_categories = coco.loadCats(ids=coco.getCatIds())
    if not source_categories:
        return coco
    for category in source_categories:
        if not (category['id'] in mapping or category['name'] in mapping):
            mapping[category['name']] = category['name']

    output_categories = copy.deepcopy(coco.loadCats(ids=coco.getCatIds()))
    for category in output_categories:
        if category['name'] in mapping.keys():
            category_id = mapping[category['name']]
            if isinstance(category_id, int):
                category['id'] = category_id

    target_categories = source_categories
    if args.target_categories:
        args.target_categories = literal_eval(args.target_categories)
        if args.keep_source_categories:
            source_category_ids = set([category['id'] for category in output_categories])
            target_category_ids = set([category['id'] for category in args.target_categories])
            for idx in target_category_ids:
                if idx in source_category_ids:
                    logging.error("Duplicate id {} found between source and target categories".format(idx))
                    logging.error("Taken ids are {}".format(", ".join((str(i) for i in source_category_ids))))
                    sys.exit(1)
        target_categories = args.target_categories

    new_name_2_id = {category['name']: category['id'] for category in target_categories}
    source_category_names = [category['name'] for category in source_categories]
    target_category_names = [category['name'] for category in target_categories]
    annotations = []
    if len(coco.dataset['annotations']) > 0:
        added_annotation_ids = set()

        for old, new in mapping.items():
            if isinstance(old, str) and old not in source_category_names:
                logging.error("Cannot find source key {} in category names {}".format(old, source_category_names))
                sys.exit(1)

            if isinstance(new, str) and new not in target_category_names:
                logging.error("cannot find target key {} in category names {}".format(new, target_category_names))
                sys.exit(1)

            elif isinstance(old, int) and isinstance(new, int):
                for ann in coco.loadAnns(ids=coco.getAnnIds(catIds=old)):
                    ann_copy = copy.deepcopy(ann)
                    ann_copy['category_id'] = new
                    annotations.append(ann_copy)
                    added_annotation_ids.add(ann_copy['id'])
                category = coco.loadCats(ids=coco.getCatIds(catIds=old)).pop()
                category['id'] = new

            elif isinstance(old, int) and isinstance(new, str):
                if new in new_name_2_id.keys():
                    for ann in coco.loadAnns(ids=coco.getAnnIds(catIds=old)):
                        ann_copy = copy.deepcopy(ann)
                        ann_copy['category_id'] = new_name_2_id[new]
                        annotations.append(ann_copy)
                        added_annotation_ids.add(ann_copy['id'])

            elif isinstance(old, str) and isinstance(new, int):
                for ann in coco.loadAnns(ids=coco.getAnnIds(catIds=coco.getCatIds(catNms=old))):
                    ann_copy = copy.deepcopy(ann)
                    ann_copy['category_id'] = new
                    annotations.append(ann_copy)
                    added_annotation_ids.add(ann_copy['id'])
                category = coco.loadCats(ids=coco.getCatIds(catNms=old)).pop()
                category['id'] = new

            elif isinstance(old, str) and isinstance(new, str):
                if new in new_name_2_id.keys():
                    for ann in coco.loadAnns(ids=coco.getAnnIds(catIds=coco.getCatIds(catNms=old))):
                        ann_copy = copy.deepcopy(ann)
                        ann_copy['category_id'] = new_name_2_id[new]
                        annotations.append(ann_copy)
                        added_annotation_ids.add(ann_copy['id'])

        to_add_annotation_ids = set(coco.getAnnIds()) - added_annotation_ids
        annotations.extend(coco.loadAnns(ids=to_add_annotation_ids))

    coco.dataset['annotations'] = annotations

    categories = target_categories
    if args.keep_source_categories:
        categories.extend(source_categories)

    coco.dataset['categories'] = sorted(drop_duplicates(categories), key=itemgetter('id'))
    category_ids = coco.getCatIds()
    if len(set(category_ids)) != len(category_ids):
        logging.warning('There are duplicate category ids in the coco dataset.')

    return coco


def resize(coco: COCO, args: argparse.Namespace) -> COCO:
    if args.apply_to_images:
        os.makedirs(os.path.join(os.getcwd(), args.image_output_dir), exist_ok=True)

    for img_entry in coco.dataset['images']:
        img_height = img_entry.get('height')
        img_width = img_entry.get('width')

        if img_height is None or img_width is None:
            logging.warning("Cannot find 'height' or 'width' fields in COCO JSON. Looking for image")
            try:
                img_width, img_height = Image.open(img_entry.get('path')).size
            except AttributeError:
                logging.warning("Cannot find image {}, skipping".format(img_entry.get('id')))

        if args.factor is None:
            dims = args.size.split(',')
            h_scale = float(dims[0]) / img_width
            v_scale = float(dims[1]) / img_height
        else:
            h_scale = v_scale = args.factor

        img_entry['height'] = round(img_height * v_scale, None)
        img_entry['width'] = round(img_width * h_scale, None)

        if args.apply_to_images:
            if os.path.isfile(img_entry['path']):
                new_path = os.path.join(os.getcwd(), args.image_output_dir, os.path.basename(img_entry['path']))
                resized_img = imread(img_entry['path'], size=(img_entry['width'], img_entry['height']))
                img_entry['path'] = new_path
                logging.info("Saving image to {}".format(new_path))
                imwrite(resized_img, new_path)
            else:
                logging.warning("Cannot find path to image [{}]".format(img_entry['path']))

        # Rescaling bbox and segmentation values
        # format is [x, y, width, height]
        # Rescaled area value i.e. new_width * new_height
        for ann in coco.loadAnns(coco.getAnnIds(imgIds=img_entry['id'])):
            if 'bbox' in ann:
                x = round(ann['bbox'][0] * h_scale, args.digits)
                y = round(ann['bbox'][1] * v_scale, args.digits)
                width = round(ann['bbox'][2] * h_scale, args.digits)
                height = round(ann['bbox'][3] * v_scale, args.digits)
                ann['bbox'] = [x, y, width, height]
                ann['area'] = width * height

            if 'segmentation' not in ann:
                logging.warning(
                    "Annotation with id {} does not have 'segmentation'. Skipping annotation".format(ann['id'])
                )
                continue
            tmp = ann['segmentation']
            if type(tmp) is list:
                segment = tmp[0]
                new_segment = [
                    (round(x * h_scale, args.digits), round(y * v_scale, args.digits))
                    for x, y in
                    grouper(segment, 2)
                ]
                # Flatten the list of tuples
                new_segment = list(itertools.chain(*new_segment))
                ann['segmentation'] = [new_segment]
                ann['area'] = poly_area(poly_x(new_segment), poly_y(new_segment))
            elif type(tmp) is dict:
                logging.warning("RLE is not yet supported")
            else:
                logging.warning("Unknown data type [{}]".format(type(tmp)))

    return coco


def repath(coco: COCO, args: argparse.Namespace) -> COCO:
    for img_entry in coco.dataset['images']:
        try:
            img_entry['path'] = os.path.join(args.path, os.path.basename(img_entry['path']))
        except KeyError:
            logging.warning("Unable to find 'path' key for image {}".format(img_entry))
            try:
                img_entry['path'] = os.path.join(args.path, os.path.basename(img_entry['file_name']))
            except KeyError:
                logging.warning("Unable to find 'file_name' key for image {}".format(img_entry))
    return coco


def drop_duplicates(list_: list) -> list:
    def to_tuple(list_entry: list):
        return tuple(to_tuple(i) if isinstance(i, list) else i for i in list_entry)
    return [dict(i) for i in set(to_tuple([list(i) for i in sorted(i.items())]) for i in list_)]


def load_coco(json_str: str) -> COCO:
    json_str = json_str.strip()
    if not json_str:
        # Empty file check
        logging.error("Expecting input from stdin: received empty characters <{}>".format(repr(json_str)))
        sys.exit(1)
    with redirect_stdout(Verbose):
        coco = COCO()
        coco.dataset = json.loads(json_str)
        coco.createIndex()
    return coco


def grouper(iterable, size: int, fillvalue=None):
    args = [iter(iterable)] * size
    return itertools.zip_longest(*args, fillvalue=fillvalue)


def assign_new_image_ids(coco: COCO, args: argparse.Namespace) -> COCO:
    """Assigning new image id methods"""
    logging.info("assign-new-image-ids operation selected")
    if args.assign_method == 'sort':
        return assign_from_sorted(coco, args)
    elif args.assign_method == 'coco':
        return assign_from_coco(coco, args)
    logging.warning("Output coco is the same as input coco")
    return coco


#  Felzenszwalb et al.
def non_max_suppression(boxes, overlap_thresh):
    # if there are no boxes, return an empty list
    if len(boxes) == 0:
        return []

    # initialize the list of picked indexes
    pick = []

    # grab the coordinates of the bounding boxes
    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 2]
    y2 = boxes[:, 3]

    # compute the area of the bounding boxes and sort the bounding
    # boxes by the bottom-right y-coordinate of the bounding box
    area = (x2 - x1 + 1) * (y2 - y1 + 1)
    idxs = np.argsort(y2)

    # keep looping while some indexes still remain in the indexes
    # list
    while len(idxs) > 0:
        # grab the last index in the indexes list, add the index
        # value to the list of picked indexes, then initialize
        # the suppression list (i.e. indexes that will be deleted)
        # using the last index
        last = len(idxs) - 1
        i = idxs[last]
        pick.append(i)
        suppress = [last]

        # loop over all indexes in the indexes list
        for pos in range(0, last):
            # grab the current index
            j = idxs[pos]

            # find the largest (x, y) coordinates for the start of
            # the bounding box and the smallest (x, y) coordinates
            # for the end of the bounding box
            xx1 = max(x1[i], x1[j])
            yy1 = max(y1[i], y1[j])
            xx2 = min(x2[i], x2[j])
            yy2 = min(y2[i], y2[j])

            # compute the width and height of the bounding box
            w = max(0, xx2 - xx1 + 1)
            h = max(0, yy2 - yy1 + 1)

            # compute the ratio of overlap between the computed
            # bounding box and the bounding box in the area list
            overlap = float(w * h) / area[j]

            # if there is sufficient overlap, suppress the
            # current bounding box
            if overlap > overlap_thresh:
                suppress.append(pos)

        # delete all indexes from the index list that are in the
        # suppression list
        idxs = np.delete(idxs, suppress)

    # return only the bounding boxes that were picked
    return boxes[pick], pick


def groupbyUnsorted(input, key=lambda x:x):
  yielded = set()
  keys = [ key(element) for element in input ]
  for i, wantedKey in enumerate(keys):
    if wantedKey not in yielded:
      yield (wantedKey,
          (input[j] for j in range(i, len(input)) if keys[j] == wantedKey))
    yielded.add(wantedKey)

def non_max_suppression(coco: COCO, args: argparse.Namespace) -> COCO:

    try:
        ann = coco.dataset.get('annotations')

        keep_ann = []

        # perform nms per image per category
        group_on = lambda x: str(x['image_id']) + '-' + str(x['category_id'])

        # if it ever makes sense to ignore category
        #group_on = lambda x: x['image_id']

        for key, group in groupbyUnsorted(ann, group_on):
            g = list(group)
            boxes = np.empty((len(g),4))
            for i,image_annotation in enumerate(g):
                # "bbox" : [x,y,width,height]
                bbox = image_annotation['bbox']
                boxes[i,:] = [bbox[0],  bbox[1],
                              bbox[0] + bbox[2],
                              bbox[1] + bbox[3]]

            boxes, keep_i = non_max_suppression(boxes, args.overlap_threshold)

            for i in keep_i:
                keep_ann.append(g[i])

        coco.dataset['annotations'] = keep_ann

        return coco
    except Exception as e:
        print("Error!", e)
        print("Error!", sys.exc_info()[0], "occured.")
        raise


def assign_from_coco(stdin_coco: COCO, args: argparse.Namespace) -> COCO:
    """

    Args:
        stdin_coco: COCO file read from stdin
        args: arguments passed from argparse

    Returns: COCO file with image ids that have been reassigned based on the image ids from a command line COCO file

    """
    old_id_2_key = {img_entry['id']: img_entry[args.key] for img_entry in stdin_coco.dataset['images']}
    with open(args.coco) as f:
        cl_coco = json.load(f)
    key_2_new_id = {img_entry[args.key]: img_entry['id'] for img_entry in cl_coco['images']}
    all_ids = set(range(len(stdin_coco.dataset['images']) + len(cl_coco['images'])))
    new_ids = {new_id for new_id in key_2_new_id.values()}
    available_ids = all_ids - new_ids
    old_id_2_new_id = {}
    if not args.keep_mismatch:
        kept_img_ids = set()
        kept_ann_ids = set()
    for old_id, key in old_id_2_key.items():
        if key not in key_2_new_id.keys():
            old_id_2_new_id[old_id] = available_ids.pop()
    for i, image_entry in enumerate(stdin_coco.dataset['images']):
        try:
            image_entry['id'] = key_2_new_id[old_id_2_key[image_entry['id']]]
            if not args.keep_mismatch:
                kept_img_ids.add(id(image_entry))
        except KeyError:
            if args.keep_mismatch:
                # current image entry key does not exist in the command line COCO file
                logging.warning(
                    "Image entry with id {} and key: value -> {}: {} cannot be found on command line COCO file".format(
                        image_entry['id'], args.key, image_entry[args.key]))
                logging.warning(
                    "ID {} will be assigned to image entry with id {}".format(old_id_2_new_id[image_entry['id']],
                                                                              image_entry['id']))
                image_entry['id'] = old_id_2_new_id[image_entry['id']]
            else:
                continue

    for i, ann_entry in enumerate(stdin_coco.dataset['annotations']):
        try:
            ann_entry['image_id'] = key_2_new_id[old_id_2_key[ann_entry['image_id']]]
            if not args.keep_mismatch:
                kept_ann_ids.add(id(ann_entry))
        except KeyError:
            if args.keep_mismatch:
                logging.warning("This annotation has an image that could not be matched")
                ann_entry['image_id'] = old_id_2_new_id[ann_entry['image_id']]
            else:
                continue

    if not args.keep_mismatch:
        stdin_coco.dataset['images'] = [img for img in stdin_coco.dataset['images'] if id(img) in kept_img_ids]
        stdin_coco.dataset['annotations'] = [ann for ann in stdin_coco.dataset['annotations'] if
                                             id(ann) in kept_ann_ids]
    return stdin_coco


def assign_from_sorted(coco: COCO, args: argparse.Namespace) -> COCO:
    """

    Args:
        coco: COCO file read from stdin
        args: arguments pass from argparse

    Returns: COCO file with image ids that have been reassigned based on the sorted order of the images from args.key

    """
    old_id_2_path = {image['id']: image['path'] for image in coco.dataset['images']}
    from operator import itemgetter
    coco.dataset['images'].sort(key=itemgetter(args.key))
    for i, image_entry in enumerate(coco.dataset['images']):
        image_entry['id'] = i
    path_2_new_id = {image_entry['path']: image_entry['id'] for image_entry in coco.dataset['images']}
    for annotation in coco.dataset.get('annotations'):
        annotation['image_id'] = path_2_new_id[old_id_2_path[annotation['image_id']]]
    return coco


def intersection(stdin_coco: COCO, args: argparse.Namespace):
    with open(args.file) as f:
        cl_coco = load_coco(f.read().strip())

    for stdin_img_entry in stdin_coco.dataset['images']:
        try:
            cl_img_entry = cl_coco.loadImgs(ids=stdin_img_entry['id']).pop()
        except KeyError as e:
            logging.warning(
                "Cannot find matching image {} from stdin in JSON file {},"
                "try matching image ids using coco-calc assign-new-image-ids".format(stdin_img_entry['id'], args.file)
            )
            raise e
        stdin_anns = stdin_coco.loadAnns(stdin_coco.getAnnIds(imgIds=stdin_img_entry['id']))
        stdin_polys = [
            np.reshape(np.array(anns['segmentation'][0]), (len(anns['segmentation'][0]) // 2, 2)) for
            anns in stdin_anns
        ]
        cl_anns = cl_coco.loadAnns(cl_coco.getAnnIds(imgIds=cl_img_entry['id']))
        cl_polys = [
            np.reshape(np.array(anns['segmentation'][0]), (len(anns['segmentation'][0]) // 2, 2)) for
            anns in cl_anns
        ]
        stdin_areas, cl_areas, intersection_areas = poly_intersection_area(stdin_polys, cl_polys)
        if intersection_areas.size == 0:
            logging.info("Skipping image {} as no annotations exist".format(stdin_img_entry['id']))
            continue
        stdin_areas = np.array(stdin_areas, dtype=np.uint)
        cl_areas = np.array(cl_areas, dtype=np.uint)
        if args.output_non_intersecting == '-':
            first_idxs = np.where(~intersection_areas.any(axis=1))[0]
            for i in first_idxs.tolist():
                print(",".join(str(j) for j in (
                    stdin_img_entry['path'],
                    stdin_img_entry['id'],
                    stdin_anns[i]['id'],
                    stdin_anns[i]['category_id'],
                    stdin_areas[i],
                )))
        elif args.output_non_intersecting == 'cl':
            second_idxs = np.where(~intersection_areas.any(axis=0))[0]
            for i in second_idxs.tolist():
                print(",".join(str(j) for j in (
                    stdin_img_entry['path'],
                    stdin_img_entry['id'],
                    cl_anns[i]['id'],
                    cl_anns[i]['category_id'],
                    cl_areas[i],
                )))
        else:
            first_idxs, second_idxs = np.where(intersection_areas != 0)
            for i, j in zip(first_idxs.tolist(), second_idxs.tolist()):
                print(",".join(str(k) for k in (
                    stdin_img_entry['path'],
                    stdin_img_entry['id'],
                    stdin_anns[i]['id'],
                    stdin_anns[i]['category_id'],
                    stdin_areas[i],
                    cl_anns[j]['id'],
                    cl_anns[j]['category_id'],
                    cl_areas[j],
                    intersection_areas[i, j],
                )))
    sys.exit(0)


def get_args(flags: List[str] = None) -> argparse.Namespace:
    verbose = MyParser(add_help=False)
    verbose.add_argument(
        '--verbose',
        action='store_const',
        const=logging.INFO,
        dest='loglevel',
        help="Verbose output to stderr",
    )
    debug = MyParser(add_help=False)
    debug.add_argument(
        '--debug',
        action='store_const',
        const=logging.DEBUG,
        dest='loglevel',
        help='Debug output to stderr',
    )
    min_ = MyParser(add_help=False)
    min_.add_argument(
        '--minified',
        action='store_const',
        const=None,
        default=4,
        dest='indent',
        help="Disable JSON pretty print",
    )
    apply_to_images = MyParser(add_help=False)
    apply_to_images.add_argument(
        '--apply-to-images',
        action='store_true',
        help='Apply operation to images, output to directory specified by --image-output-dir',
    )
    image_output_dir = MyParser(add_help=False)
    image_output_dir.add_argument(
        '-o', '--image-output-dir',
        default='images',
        help='Image output directory. Default is %(default)s',
    )
    parents = [verbose, debug, min_]
    image_operations = [apply_to_images, image_output_dir]

    parser = MyParser(
        description=_DESCRIPTION,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        parents=parents,
    )
    subparsers = parser.add_subparsers()

    parser_crop = subparsers.add_parser(
        'crop',
        description=_CROP_DESCRIPTION,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        parents=parents + image_operations,
        help="Crop images and annotations. Annotations can be partially cropped if --keep-partial is specified",
    )

    parser_crop.add_argument(
        '--fit',
        action='store_true',
        help="If centre of cropped area is too close to image dimension, shift cropped area to fit inside image",
    )
    parser_crop.add_argument(
        '--keep-partial',
        action='store_true',
        help="If crop window cuts the annotation, only partially crop it, otherwise discard",
    )
    parser_crop.add_argument(
        '--point',
        action='store_true',
        help="Centre of crop area is identified by annotation_type 'point'",
    )
    parser_crop.add_argument(
        '-s', '--size',
        help="<width>,<height> crop size"
    )

    parser_resize = subparsers.add_parser(
        'resize',
        description=_RESIZE_DESCRIPTION,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        parents=parents + image_operations,
        help="Resize all images and their respective annotations by a scaling factor or by specified width and height",
    )

    parser_resize.add_argument(
        '-d', '--digits',
        type=int,
        help="Number of decimal digits in bbox and segmentation coordinates; default: %(default)s",
    )
    parser_resize_mx = parser_resize.add_mutually_exclusive_group(required=True)
    parser_resize_mx.add_argument(
        '-f', '--factor',
        type=float,
        help="Scale images by a percentage",
    )
    parser_resize_mx.add_argument(
        '-s', '--size',
        help="<width>,<height> size",
    )

    parser_remap = subparsers.add_parser(
        'remap',
        description=_REMAP_DESCRIPTION,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        parents=parents,
        help="Remap categories and/or category id in COCO JSON",
    )
    parser_remap.add_argument(
        'mapping',
        help="Dict style string for remapping of either category id/category name to category id/category name",
    )
    parser_remap.add_argument(
        '--keep-source-categories',
        help="If target categories is specified, append target to input categories",
        action='store_true'
    )
    parser_remap.add_argument(
        '--target-categories',
        help="Target categories to be used for re-mapping. "
             "Same format as default COCO categories list. Default categories is taken from input COCO JSON file",
    )

    parser_repath = subparsers.add_parser(
        'repath',
        description=_REPATH_DESCRIPTION,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        parents=parents,
        help="Re-path every image in COCO JSON.",
    )
    parser_repath.add_argument(
        'path',
        help="New path to prepend to each image in data set",
    )

    parser_intersection = subparsers.add_parser(
        'intersection',
        description=_INTERSECT_DESCRIPTION,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        parents=parents,
        help='Output intersecting polygons along with their polygon areas and intersection area in CSV format',
    )
    parser_intersection.add_argument(
        '--output-non-intersecting',
        choices=['-', 'cl'],
        help="Output non-intersecting polygons from either stdin or command line JSON",
    )
    parser_intersection.add_argument(
        '--output-fields',
        action='store_const',
        const="image/path,image/id,"
              "first/id,first/category_id,first/area,"
              "second/id,second/category_id,second/area,"
              "intersection/area",
        help="Print output csv fields to stdout and exit",
    )
    parser_intersection.add_argument(
        '--file',
        help="JSON file to match intersecting polygons with",
    )

    parser_non_max_suppression = subparsers.add_parser(
        'nms',
        description=_NMS_DESCRIPTION,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        parents=parents,
        help='Non Max Suppression - Remove overlapping bounding boxes',
    )
    parser_non_max_suppression.add_argument(
        '--overlap-threshold',
        default=0.5,
        help="Remove where overlap > overlap threshold default: %(default)s.",
    )

    parser_new_img_ids = subparsers.add_parser(
        'assign-new-image-ids',
        description=_ASSIGN_NEW_IMAGE_IDS_DESCRIPTION,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        parents=parents,
        help="Assign new ids to COCO file from stdin based on ids from COCO file passed as command line argument.",
    )
    parser_new_img_ids.add_argument(
        '--keep-mismatch',
        action='store_true',
        help="Keep image if the key to match by does not exist from the COCO file passed from command line, "
             "otherwise it is dropped from the output along with its annotations",
    )

    subparser_new_ids = parser_new_img_ids.add_subparsers(dest='assign_method')
    parser_sort = subparser_new_ids.add_parser(
        'sort',
        parents=parents,
        help="Sort images by a given key and assign new ids based on ordering",
    )
    parser_sort.add_argument(
        '-k', '--key',
        help="Key to sort by before assigning imade ids. "
             "If no key is given, assigned new image ids based on existing ordering",
    )

    parser_coco = subparser_new_ids.add_parser(
        'coco',
        parents=parents,
        help="Match images from stdin COCO with command line COCO by key and assign image ids from command line COCO.",
    )
    parser_coco.add_argument(
        'coco',
        help="COCO file to assign image ids from.",
    )
    parser_coco.add_argument(
        '-k', '--key',
        default='path',
        help="Key to match by. Default is %(default)s.",
    )

    parser_crop.set_defaults(func=crop)
    parser_resize.set_defaults(func=resize)
    parser_remap.set_defaults(func=remap)
    parser_repath.set_defaults(func=repath)
    parser_new_img_ids.set_defaults(func=assign_new_image_ids)
    parser_intersection.set_defaults(func=intersection)
    parser_non_max_suppression.set_defaults(func=non_max_suppression)
    return parser.parse_args(flags)


class MyParser(argparse.ArgumentParser):
    def error(self, msg):
        self.print_help(sys.stderr)
        logging.critical(msg)
        sys.exit(1)


class Verbose:
    @staticmethod
    def write(line):
        line = line.strip()
        if line:
            logging.info(line)


if __name__ == '__main__':
    sys.exit(main(get_args()))
