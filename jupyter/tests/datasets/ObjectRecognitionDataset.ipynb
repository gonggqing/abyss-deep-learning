{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Recognition Dataset Demo\n",
    "\n",
    "This notebook is an example of how to load a dataset for use with Object Recognition. This dataset contains bounding boxes of all the classes.\n",
    "\n",
    "This demo will load the dataset using the Abyss Deep Learning libraries, and display an example image with the bounding boxes overlayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "from keras.backend import clear_session\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from abyss_deep_learning.datasets.coco import ImageClassificationDataset\n",
    "from abyss_deep_learning.datasets.translators import CocoCaptionTranslator\n",
    "from abyss_deep_learning.keras.classification import caption_map_gen, onehot_gen, hamming_loss\n",
    "from abyss_deep_learning.keras.utils import lambda_gen, batching_gen\n",
    "from abyss_deep_learning.keras.models import ImageClassifier\n",
    "#from abyss_deep_learning.utils import balanced_set\n",
    "\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Go Into deep-learning/abyss_deep_learning/datasets/coco.py\n",
    "\n",
    "The classes in the cell below should go into deep-learning/abyss_deep_learning/datasets/coco.py once they have been reviewed. They are the standard interface to an Object Recognition dataset.\n",
    "\n",
    "The imports can be skipped.\n",
    "\n",
    "! Remove once it has been added !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "from contextlib import redirect_stdout\n",
    "from sys import stderr\n",
    "import concurrent.futures\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "# These imports can be skipped\n",
    "from abyss_deep_learning.base.datasets import DatasetTaskBase, DatasetTypeBase\n",
    "from abyss_deep_learning.datasets.coco import CocoInterface, CocoDataset, ImageDatatype\n",
    "from abyss_deep_learning.datasets.translators import AnnotationTranslator\n",
    "\n",
    "from abyss_deep_learning.datasets.coco import _noop\n",
    "\n",
    "class ObjectRecognitionTask(CocoInterface, DatasetTaskBase):\n",
    "    def __init__(self, coco, translator=None, num_classes=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Segmentation arguments:\n",
    "            coco (pycocotools.COCO): The COCO object to read the targes from\n",
    "            translator (AnnotationTranslator, optional): An instance of an abyss_deep_learning.datasets.translators.AnnotationTranslator\n",
    "            num_classes (int, optional): The number of classes to generate data for; if None then infer from coco.cats\n",
    "            cached (bool, optional): Whether to cache the entire dataset into memory.\n",
    "        \"\"\"\n",
    "        CocoInterface.__init__(self, coco, **kwargs)\n",
    "        assert isinstance(translator, (AnnotationTranslator, type(None)))\n",
    "        self.translator = translator or AnnotationTranslator()\n",
    "        self.num_classes = num_classes if num_classes else len(self.coco.cats) + 1\n",
    "        self.stats = dict()\n",
    "        self._targets = dict()\n",
    "\n",
    "        self._preprocess_targets = kwargs.get('preprocess_targets', _noop)\n",
    "\n",
    "        if kwargs.get('cached', False):\n",
    "            with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "                for data_id, targets in zip(\n",
    "                        self.data_ids, executor.map(self.load_targets, self.data_ids)):\n",
    "                    self._targets[data_id] = targets\n",
    "        # self._calc_class_stats()\n",
    "\n",
    "    def load_targets(self, data_id, **kwargs):\n",
    "        # assert np.issubdtype(type(data_id), np.integer), \"Must pass exactly one ID\"\n",
    "        if data_id in self._targets:\n",
    "            return self._targets[data_id]\n",
    "        img = self.coco.loadImgs(ids=[data_id])[0]\n",
    "        anns = [self.translator.translate(ann) for ann in self.coco.loadAnns(\n",
    "            self.coco.getAnnIds([data_id])) if self.translator.filter(ann)]\n",
    "        if anns:\n",
    "            boxes = np.array([ann['bbox'] for ann in anns])\n",
    "            class_ids = np.array([ann['category_id'] for ann in anns])\n",
    "            return self._preprocess_targets(class_ids, boxes)\n",
    "        return None  # TODO check\n",
    "\n",
    "    def _calc_class_stats(self):\n",
    "        if not self.stats:\n",
    "            self.stats = dict()\n",
    "            class_count = dict()\n",
    "            for data_id in self.data_ids:\n",
    "                target = self.load_targets(data_id)[0].argmax(-1)  # [0] is the category_id\n",
    "                for key, val in Counter(target.ravel().tolist()).items():\n",
    "                    class_count[key] = class_count.get(key, 0) + val\n",
    "\n",
    "            self.stats['class_weights'] = np.array(\n",
    "                [class_count.get(key, 0) for key in range(self.num_classes)], dtype=np.float64)\n",
    "            self.stats['class_weights'] **= -1.0\n",
    "            self.stats['class_weights'] /= self.stats['class_weights'].min()\n",
    "\n",
    "    @property\n",
    "    def class_weights(self):\n",
    "        '''Returns the class weights that will balance the backprop update over the class distribution.'''\n",
    "        return self.stats['class_weights']\n",
    "\n",
    "    def print_class_stats(self):\n",
    "        '''Prints statistics about the class/image distribution.'''\n",
    "        self._calc_class_stats()\n",
    "        print(\"{:s} class stats {:s}\".format('=' * 8, '=' * 8))\n",
    "        print(\"class weights:\")\n",
    "        print(\" \", self.class_weights)\n",
    "\n",
    "\n",
    "class ImageObjectRecognitionDataset(CocoDataset, ImageDatatype, ObjectRecognitionTask):\n",
    "    # TODO:\n",
    "    #   *  Class statistics readout\n",
    "    #   *  Support for computing class weights given current dataset config\n",
    "    #   *  Support for forcing class balance by selecting IDs evenly\n",
    "    #   *  Generator data order optimization\n",
    "    #   *  Support for visualising data sample or prediction with same format\n",
    "    def __init__(self, json_path, **kwargs):\n",
    "        CocoDataset.__init__(self, json_path, **kwargs)\n",
    "        ImageDatatype.__init__(self, self.coco, **kwargs)\n",
    "        ObjectRecognitionTask.__init__(self, self.coco, **kwargs)\n",
    "\n",
    "    def sample(self, image_id=None, **kwargs):\n",
    "        if not image_id:\n",
    "            image_id = random.choice(self.data_ids)\n",
    "        return (self.load_data(image_id, **kwargs), self.load_targets(image_id, **kwargs))\n",
    "\n",
    "    def generator(self, data_ids=None, shuffle_ids=False, endless=False, **kwargs):\n",
    "        if not data_ids:\n",
    "            data_ids = list(self.data_ids)\n",
    "        if shuffle_ids:\n",
    "            random.shuffle(data_ids)\n",
    "        iterator = itertools.cycle if endless else iter\n",
    "        for data_id in iterator(data_ids):\n",
    "            yield self.load_data(data_id, **kwargs), self.load_targets(data_id, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To go into deep-learning/abyss_deep_learning/datasets/translators.py\n",
    "\n",
    "The classes in the cell below should be added to deep-learning/abyss_deep_learning/datasets/translators.py as they perform functions necessary for an Object Recognition dataset.\n",
    "\n",
    "NEED TO REVIEW - what translator to use - needs to be matched with the ObjectRecognitionTask in coco.py\n",
    "\n",
    "! Remove once it has been added !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abyss_deep_learning.datasets.translators import AnnotationTranslator\n",
    "\n",
    "class CocoCategoryTranslator(AnnotationTranslator):\n",
    "    def filter(self, annotation):\n",
    "        '''Filter out non-caption annotations'''\n",
    "        return True\n",
    "\n",
    "    def translate(self, annotation):\n",
    "        '''Return a list of strings'''\n",
    "        return [annotation['category_id']]\n",
    "\n",
    "class CocoObjectTranslator(AnnotationTranslator):\n",
    "    def filter(self, annotation):\n",
    "        '''Filter out non-caption annotations'''\n",
    "        return True\n",
    "\n",
    "    def translate(self, annotation):\n",
    "        '''Return annotation and bounding box'''\n",
    "        return [annotation['category_id'], annotation['bbox']]\n",
    "\n",
    "\n",
    "class CocoAllTranslator(AnnotationTranslator):\n",
    "    def filter(self, annotation):\n",
    "        '''Filter out non-caption annotations'''\n",
    "        return True\n",
    "\n",
    "    def translate(self, annotation):\n",
    "        '''Returns the entire coco annotation dictionary for the specified annId'''\n",
    "        return annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "Enter the dataset you wish to use here.\n",
    "\n",
    "The complete dataset used for this example is created by:\n",
    "```python\n",
    "os.path.join(DATA_DIR, TRAIN_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/mnt/ssd_x/simbuoy/datasets/\"\n",
    "TRAIN_JSON = \"train1/train-sim.json\"\n",
    "VAL_JSON = \"val1/val-sim.json\"\n",
    "\n",
    "train_ds = ImageObjectRecognitionDataset(os.path.join(DATA_DIR, TRAIN_JSON),image_dir=DATA_DIR,cached=False,translator=CocoAllTranslator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the Class Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== class stats ========\n",
      "class weights:\n",
      "  [ 1.          6.16666667  3.36363636  4.625       9.25        7.4\n",
      "         inf 37.                 inf 12.33333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:71: RuntimeWarning: divide by zero encountered in reciprocal\n"
     ]
    }
   ],
   "source": [
    "catIds = train_ds.coco.getCatIds()\n",
    "train_ds.print_class_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from the Dataset\n",
    "\n",
    "The following cell samples from the dataset, and grabs a single image and its annotations.\n",
    "\n",
    "The annotations (categories_boxes variable) are a tuple, with (categories, boxes). Each of these are a numpy array, with a length equivalent to the number of annotations present in the image. The categories have a width of 1, whereas the boxes have a width of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, categories_boxes = train_ds.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the image and its annotations\n",
    "\n",
    "The following cell plots the image and its annotations, to confirm the dataset is loading correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "\n",
    "# Create a caption map\n",
    "cats = train_ds.coco.loadCats(train_ds.coco.getCatIds())\n",
    "caption_map = {}\n",
    "for cat in cats:\n",
    "    if cat['id'] not in caption_map:\n",
    "        caption_map[cat['id']] = cat['name']\n",
    "\n",
    "ax.imshow(image)\n",
    "cap_list = []\n",
    "for n in range(len(categories_boxes[0])):\n",
    "    box = categories_boxes[1][n]\n",
    "    cat = categories_boxes[0][n]\n",
    "    width = int(box[2])\n",
    "    height = int(box[3])\n",
    "    xy = (int(box[0]), int(box[1]))\n",
    "    caption = caption_map[cat]\n",
    "    cap_list.append(str(caption))\n",
    "    rect = patches.Rectangle(xy, width, height, angle=0.0, alpha=0.5, label=caption)\n",
    "    ax.add_patch(rect)\n",
    "plt.title('Categories: {}'.format(' '.join(cap_list)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
