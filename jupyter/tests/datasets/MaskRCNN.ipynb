{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import concurrent.futures\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from skimage.color import label2rgb\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "\n",
    "from mrcnn.model import MaskRCNN\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "DATA_DIR = \"/home/docker/src/abyss/deep-learning/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_args():\n",
    "    from keras.applications.resnet50 import preprocess_input\n",
    "    from bidict import bidict\n",
    "    from imgaug import augmenters as iaa\n",
    "    from imgaug.parameters import Normal, Discretize\n",
    "    from skimage.transform import resize\n",
    "    \n",
    "    def load_config(path):\n",
    "        spec = importlib.util.spec_from_file_location(\n",
    "            \"maskrcnn_config\", path)\n",
    "        config_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(config_module)\n",
    "        return config_module.Config()\n",
    "\n",
    "#     def preprocess_data(image):\n",
    "#         '''Transform the image before (possibly caching) and input to the network.'''\n",
    "#        # This is done automatically by MRCNN\n",
    "\n",
    "    def postprocess_data(image):\n",
    "        '''Inverse transform of preprocess_data, used when trying to visualize images out of the dataset.'''\n",
    "        return (image + 127.5).astype(np.uint8)\n",
    "\n",
    "    def pipeline(gen, aug_config=None):\n",
    "        '''The pipeline to run the dataset generator through.'''\n",
    "        from abyss_deep_learning.keras.classification import onehot_gen, augmentation_gen\n",
    "\n",
    "        return gen \n",
    "#                 (\n",
    "#             augmentation_gen(\n",
    "#                 onehot_gen(gen, num_classes=args['num_classes'])\n",
    "#             , aug_config, enable=(aug_config is not None))\n",
    "#         )\n",
    "\n",
    "    augmentation_config = iaa.Sequential([ \n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.Affine(\n",
    "            scale=(0.8, 1.2),\n",
    "            translate_percent=(-0.2, 0.2), \n",
    "            rotate=(-22.5, 22.5),\n",
    "            mode='constant', cval=0, order=0\n",
    "        ),\n",
    "        iaa.Sequential([ # Colour aug\n",
    "            iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "            iaa.WithChannels(0, iaa.Add(Discretize(Normal(0, 256 / 6)))),\n",
    "            iaa.WithChannels(1, iaa.Add(Discretize(Normal(0, 256 / 6)))),\n",
    "            iaa.WithChannels(2, iaa.Add(Discretize(Normal(0, 256 / 6)))),\n",
    "            iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\")\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "    args = {\n",
    "        'augmentation': None,#augmentation_config,    # Training augmentation\n",
    "#         'caption_map': caption_map,             # Captio\n",
    "        'data': {\n",
    "            'base_dir': DATA_DIR,\n",
    "            'name': \".\",\n",
    "            'sets': ['coco-segmentation']\n",
    "        },\n",
    "        'config': load_config(os.path.join(DATA_DIR, '../configs/MaskRCNN_default_config.py')),\n",
    "        'image_dims': (1024, 1024, 3),    # What to resize images to before CNN\n",
    "        'image_dir': DATA_DIR,          # Directory to use if relative image paths given\n",
    "        'nn_dtype': np.float32,         # Pretrained networks are in float32\n",
    "        'num_classes': None,            # Calculate later\n",
    "#         'use_balanced_set': False,      # Force the use of the largest class-balanced dataset\n",
    "#         'use_cached': False,            # Cache the dataset in memory\n",
    "#         'use_class_weights': True,      # Use class population to weight in the training loss\n",
    "#         'use_parallel': False,          # Use multiple GPUs\n",
    "#         'preprocess_data': preprocess_data,\n",
    "        'postprocess_data': postprocess_data,\n",
    "        'pipeline': pipeline\n",
    "    }\n",
    "    args['config'].NUM_CLASSES = 7\n",
    "    args['num_classes'] = args['config'].NUM_CLASSES\n",
    "    \n",
    "    return args\n",
    "ARGS = setup_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_datasets(args):\n",
    "    from abyss_deep_learning.datasets.coco import MaskRcnnInstSegDataset\n",
    "    \n",
    "    dataset = dict()\n",
    "    for set_name in args['data']['sets']:\n",
    "        path = os.path.join(args['data']['base_dir'], \"{:s}/{:s}.json\".format(args['data']['name'], set_name))\n",
    "        dataset[set_name] = MaskRcnnInstSegDataset(\n",
    "            path,\n",
    "            ARGS['config'],\n",
    "            image_dir=ARGS['image_dir'])\n",
    "        print(\"\\n\", set_name)\n",
    "\n",
    "    print(\"\\nNumber of classes:\", args['num_classes'])\n",
    "    cats = dataset['coco-segmentation'].coco.loadCats(dataset['coco-segmentation'].coco.getCatIds())\n",
    "    class_names = [\"BG\"] + [\n",
    "        cat['name'] for cat in sorted(cats, key=lambda x: x['id'])]\n",
    "    print(class_names)\n",
    "    return dataset, class_names\n",
    "\n",
    "DATASET, ARGS['class_names'] = setup_datasets(ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_from_inputs(inputs, **kwargs):\n",
    "    from mrcnn.visualize import display_instances\n",
    "    from mrcnn.utils import unmold_mask\n",
    "    print(inputs[4].shape)\n",
    "    N = np.argwhere(inputs[4][0] == 0)[0][0]\n",
    "    image, image_meta = inputs[0][0], inputs[1][0]\n",
    "    rpn_match, rpn_bbox = inputs[2][0], inputs[3][0]\n",
    "    gt_class_ids, gt_boxes, gt_masks = inputs[4][0, :N], inputs[5][0, :N], inputs[6][0, ..., :N]\n",
    "\n",
    "    masks = np.array([\n",
    "        unmold_mask(gt_masks[..., idx], gt_boxes[idx], image.shape)\n",
    "        for idx in range(N)]).transpose([1, 2, 0])\n",
    "\n",
    "    display_instances(\n",
    "        ARGS['postprocess_data'](image), gt_boxes, masks, gt_class_ids, ARGS['class_names'], **kwargs)\n",
    "        \n",
    "def view_dataset_samples(num_rows=2, num_cols=2):\n",
    "    plt.figure()\n",
    "    print(\"Column-wise left to right, bottom row:\")\n",
    "    for i, (name, ds) in enumerate(DATASET.items()):\n",
    "        print(name, end=' ')\n",
    "        for j, (inputs, targets) in enumerate(ARGS['pipeline'](ds.mrcnn_generator(shuffle=True))):\n",
    "            ax = plt.subplot(num_rows, num_cols, num_cols * j + i + 1)\n",
    "            display_from_inputs(inputs, ax=ax)\n",
    "#             plt.title(', '.join([ARGS['caption_map'].inv[int(cap_id)] for cap_id in np.argwhere(label)]))\n",
    "            plt.axis('off')\n",
    "            if j + 1 == num_rows:\n",
    "                break\n",
    "\n",
    "view_dataset_samples(num_rows=1, num_cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
