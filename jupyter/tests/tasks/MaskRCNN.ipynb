{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import concurrent.futures\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from skimage.color import label2rgb\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "\n",
    "from mrcnn.model import MaskRCNN\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_args():\n",
    "    from keras.applications.resnet50 import preprocess_input\n",
    "    from bidict import bidict\n",
    "    from imgaug import augmenters as iaa\n",
    "    from imgaug.parameters import Normal, Discretize\n",
    "    from skimage.transform import resize\n",
    "    \n",
    "    def load_config(path):\n",
    "        spec = importlib.util.spec_from_file_location(\n",
    "            \"maskrcnn_config\", path)\n",
    "        config_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(config_module)\n",
    "        return config_module.Config()\n",
    "\n",
    "#     def preprocess_data(image):\n",
    "#         '''Transform the image before (possibly caching) and input to the network.'''\n",
    "#        # This is done automatically by MRCNN\n",
    "\n",
    "    def postprocess_data(image):\n",
    "        '''Inverse transform of preprocess_data, used when trying to visualize images out of the dataset.'''\n",
    "        return (image + 127.5).astype(np.uint8)\n",
    "\n",
    "    def pipeline(gen, aug_config=None):\n",
    "        '''The pipeline to run the dataset generator through.'''\n",
    "        from abyss_deep_learning.keras.classification import multihot_gen, augmentation_gen\n",
    "\n",
    "        return gen \n",
    "#                 (\n",
    "#             augmentation_gen(\n",
    "#                 multihot_gen(gen, num_classes=args['num_classes'])\n",
    "#             , aug_config, enable=(aug_config is not None))\n",
    "#         )\n",
    "\n",
    "    augmentation_config = iaa.Sequential([ \n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.Affine(\n",
    "            scale=(0.8, 1.2),\n",
    "            translate_percent=(-0.2, 0.2), \n",
    "            rotate=(-22.5, 22.5),\n",
    "            mode='constant', cval=0, order=0\n",
    "        ),\n",
    "        iaa.Sequential([ # Colour aug\n",
    "            iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "            iaa.WithChannels(0, iaa.Add(Discretize(Normal(0, 256 / 6)))),\n",
    "            iaa.WithChannels(1, iaa.Add(Discretize(Normal(0, 256 / 6)))),\n",
    "            iaa.WithChannels(2, iaa.Add(Discretize(Normal(0, 256 / 6)))),\n",
    "            iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\")\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "    args = {\n",
    "        'augmentation': None,#augmentation_config,    # Training augmentation\n",
    "#         'caption_map': caption_map,             # Captio\n",
    "        'data': {\n",
    "            'base_dir': \"/data/acfr/collated/2017-summer-lettuce\",\n",
    "            'name': \"merged\",\n",
    "            'sets': ('train', 'val')\n",
    "        },\n",
    "        'config': load_config('/data/acfr/collated/2017-summer-lettuce/mrcnn_config.py'),\n",
    "        'image_dims': (1024, 1024, 3),    # What to resize images to before CNN\n",
    "        'nn_dtype': np.float32,         # Pretrained networks are in float32\n",
    "        'num_classes': None,            # Calculate later\n",
    "#         'use_balanced_set': False,      # Force the use of the largest class-balanced dataset\n",
    "#         'use_cached': False,            # Cache the dataset in memory\n",
    "#         'use_class_weights': True,      # Use class population to weight in the training loss\n",
    "#         'use_parallel': False,          # Use multiple GPUs\n",
    "#         'preprocess_data': preprocess_data,\n",
    "        'postprocess_data': postprocess_data,\n",
    "        'pipeline': pipeline\n",
    "    }\n",
    "    args['num_classes'] = args['config'].NUM_CLASSES\n",
    "    \n",
    "    return args\n",
    "ARGS = setup_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_datasets(args):\n",
    "    from abyss_deep_learning.datasets.coco import MaskRcnnInstSegDataset\n",
    "    \n",
    "    dataset = dict()\n",
    "    for set_name in args['data']['sets']:\n",
    "        path = os.path.join(args['data']['base_dir'], \"{:s}/{:s}.json\".format(args['data']['name'], set_name))\n",
    "        dataset[set_name] = MaskRcnnInstSegDataset(\n",
    "            path, ARGS['config'])\n",
    "        print(\"\\n\", set_name)\n",
    "#         dataset[set_name].print_class_stats()\n",
    "\n",
    "    print(\"\\nNumber of classes:\", args['num_classes'])\n",
    "    cats = dataset['train'].coco.loadCats(dataset['train'].coco.getCatIds())\n",
    "    class_names = [\"BG\"] + [\n",
    "        cat['name'] for cat in sorted(cats, key=lambda x: x['id'])]\n",
    "    print(class_names)\n",
    "    return dataset, class_names\n",
    "\n",
    "DATASET, ARGS['class_names'] = setup_datasets(ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_from_inputs(inputs, **kwargs):\n",
    "    from mrcnn.visualize import display_instances\n",
    "    from mrcnn.utils import unmold_mask\n",
    "    print(inputs[4].shape)\n",
    "    N = np.argwhere(inputs[4][0] == 0)[0][0]\n",
    "    image, image_meta = inputs[0][0], inputs[1][0]\n",
    "    rpn_match, rpn_bbox = inputs[2][0], inputs[3][0]\n",
    "    gt_class_ids, gt_boxes, gt_masks = inputs[4][0, :N], inputs[5][0, :N], inputs[6][0, ..., :N]\n",
    "\n",
    "    masks = np.array([\n",
    "        unmold_mask(gt_masks[..., idx], gt_boxes[idx], image.shape)\n",
    "        for idx in range(N)]).transpose([1, 2, 0])\n",
    "\n",
    "    display_instances(\n",
    "        ARGS['postprocess_data'](image), gt_boxes, masks, gt_class_ids, ARGS['class_names'], **kwargs)\n",
    "        \n",
    "def view_dataset_samples(num_rows=2):\n",
    "    plt.figure()\n",
    "    print(\"Column-wise left to right, bottom row:\")\n",
    "    for i, (name, ds) in enumerate(DATASET.items()):\n",
    "        print(name, end=' ')\n",
    "        for j, (inputs, targets) in enumerate(ARGS['pipeline'](ds.mrcnn_generator(shuffle=True))):\n",
    "            ax = plt.subplot(num_rows, 3, 3 * j + i + 1)\n",
    "            display_from_inputs(inputs, ax=ax)\n",
    "#             plt.title(', '.join([ARGS['caption_map'].inv[int(cap_id)] for cap_id in np.argwhere(label)]))\n",
    "            plt.axis('off')\n",
    "            if j + 1 == num_rows:\n",
    "                break\n",
    "\n",
    "view_dataset_samples(num_rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(object):\n",
    "    def __init__(self, config, model_dir):\n",
    "        self.epoch = 0\n",
    "        self.model = None\n",
    "        self.config = config\n",
    "        self.model_dir = model_dir\n",
    "        self.compiled = False\n",
    "    \n",
    "    def create(self, model_path=None, train=False, fresh_heads=False, gpu_count=1):\n",
    "        if not model_path:\n",
    "            model_path = '/data/models/mask_rcnn_coco.h5'\n",
    "            \n",
    "        if not train:\n",
    "            self.config.IMAGES_PER_GPU = 1\n",
    "            self.config.BATCH_SIZE = 1\n",
    "        self.model = None\n",
    "        K.clear_session()\n",
    "        self.config.GPU_COUNT = gpu_count\n",
    "        self.model = MaskRCNN(\n",
    "            mode=(\"training\" if train else \"inference\"),\n",
    "            config=self.config, model_dir=self.model_dir)\n",
    "        if model_path: \n",
    "            exclude = [\n",
    "                \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                \"mrcnn_bbox\", \"mrcnn_mask\"] if fresh_heads else []\n",
    "            self.model.load_weights(model_path, by_name=True, exclude=exclude)\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Inference MRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_rois(rois, scale, max_height, max_width):\n",
    "    h = rois[:,2] - rois[:,0]\n",
    "    w = rois[:,3] - rois[:,1]\n",
    "    rois += + np.round(np.vstack([-scale * h, -scale * w, scale * h, scale * w]).T).astype(np.int32)\n",
    "    rois = np.maximum(0, rois)\n",
    "    rois[:, 2] = np.minimum(max_height, rois[:, 2])\n",
    "    rois[:, 3] = np.minimum(max_width, rois[:, 3])\n",
    "    return rois\n",
    "\n",
    "def save_result(path, image, r, threshold):\n",
    "    '''note global OUTPUT_DIR'''\n",
    "    basename = '.'.join(os.path.basename(path).split('.')[:-1])\n",
    "#     image = imread(path)\n",
    "    rois = scale_rois(r['rois'].copy(), 0.25, *image.shape[0:2])\n",
    "\n",
    "    assert len(rois) == r['masks'].shape[-1] == len(r['class_ids']) == len(r['scores']), \"shape mismatch\"\n",
    "    for plant_idx, (roi, mask, class_id, score) in enumerate(\n",
    "            zip(rois, r['masks'].transpose([2, 0, 1]), r['class_ids'], r['scores'])):\n",
    "        if score > threshold:\n",
    "            output_path = os.path.join(OUTPUT_DIR, \"{:s}_{:d}.png\".format(basename, plant_idx))\n",
    "            image_roi = image[roi[0]:roi[2], roi[1]:roi[3]]\n",
    "            imsave(output_path, image_roi)\n",
    "            output_path = os.path.join(OUTPUT_DIR, \"{:s}_{:d}_mask.png\".format(basename, plant_idx))\n",
    "            image_roi = 255 * mask[roi[0]:roi[2], roi[1]:roi[3]]\n",
    "            imsave(output_path, image_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/data/acfr/collated/thesis/cauliflower-broccoli\"\n",
    "OUTPUT_DIR = output_dir\n",
    "\n",
    "!mkdir -p $output_dir\n",
    "# model_weights = \"/data/log/maskrcnn/weeks2to6/final2.h5\"\n",
    "model_weights = \"/data/log/maskrcnn/broccoli-allages/merged/final.h5\"\n",
    "exp = None\n",
    "ARGS['config'].USE_MINI_MASK = False\n",
    "ARGS['config'].IMAGES_PER_GPU = 1\n",
    "exp = Experiment(ARGS['config'], output_dir + \"/log\")\n",
    "model = exp.create(model_path=model_weights, train=False, fresh_heads=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "paths = [path \n",
    "    for date in ['201710', '201711', '201712']\n",
    "    for path in glob(\"/data/acfr/ladybird/{:s}*/auto0/grasshopper3/img/left/*.png\".format(date))\n",
    "]\n",
    "\n",
    "train_filenames = [img['file_name'] for img in DATASET['train'].coco.loadImgs(DATASET['train'].coco.getImgIds())]\n",
    "paths = [path for path in paths if os.path.basename(path) not in train_filenames]\n",
    "print(\"processing \", len(paths))\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for img_idx, path in enumerate(paths):\n",
    "    image = imread(path)[np.newaxis, ...]\n",
    "    basename = '.'.join(os.path.basename(path).split('.')[:-1])\n",
    "    r = exp.model.detect(image)[0]\n",
    "    num_dets = r['scores'].size\n",
    "    if not num_dets:\n",
    "        continue\n",
    "    save_result(path, image[0], r, threshold=0.95)\n",
    "    r['filename'] = [basename] * num_dets\n",
    "    r['roi/y1'] = r['rois'][:, 0]\n",
    "    r['roi/x1'] = r['rois'][:, 1]\n",
    "    r['roi/y2'] = r['rois'][:, 2]\n",
    "    r['roi/x2'] = r['rois'][:, 3]\n",
    "    del r['rois'], r['masks']\n",
    "    columns = [a for a in r.keys()]\n",
    "#     print([a for a in r.values()])\n",
    "    data = np.vstack([a for a in r.values()]).T\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    results.append(df)\n",
    "#     plt.figure()\n",
    "#     display_instances(\n",
    "#         image[0],\n",
    "#         r['rois'],\n",
    "#         r['masks'],\n",
    "#         r['class_ids'],\n",
    "#         ARGS['class_names'], ax=plt.gca())\n",
    "\n",
    "# def save_results(paths, results, threshold=0.975):\n",
    "#     import concurrent.futures\n",
    "# #     for path, result in zip(paths, results):\n",
    "# #         save_result(path, result, threshold)\n",
    "#     with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#         executor.map(save_result, paths, results, [threshold] * len(results))\n",
    "\n",
    "# save_results(paths, results, threshold=0.5)\n",
    "results = pd.concat(results).reset_index()\n",
    "results.to_csv(os.path.join(OUTPUT_DIR, 'stats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = results[results['scores'].apply(float) >= 0.99]\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.utils import expand_mask\n",
    "from mrcnn.visualize import display_images, display_instances\n",
    "# from abyss_deep_learning.keras.segmentation import jaccard_index\n",
    "\n",
    "def plot_test(gen, model, num_images=1, show=False):\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    ious_list = []\n",
    "    i = 0\n",
    "    for ((images, image_meta, rpn_match, rpn_bbox, gt_class_ids, gt_boxes, gt_masks), targets) in gen:\n",
    "        image = images[0]\n",
    "        valid = np.all(gt_boxes[0], axis=1)\n",
    "        class_ids = gt_class_ids[0, valid]\n",
    "        masks = gt_masks[0, ..., valid].transpose((1, 2, 0))\n",
    "        boxes = gt_boxes[0, valid, ...]\n",
    "        \n",
    "        labels = expand_mask(boxes, masks, image.shape).astype(np.uint8)\n",
    "        r = model.detect([image], verbose=True)[0]\n",
    "        num_pred = len(r['class_ids'])\n",
    "        num_gt = len(class_ids)\n",
    "        print(\"GTs = {:d}, Pred = {:d}\".format(num_gt, num_pred))\n",
    "        \n",
    "        ious = np.array([[\n",
    "            1 #jaccard_index(r['masks'][..., i] , labels[..., j]) \n",
    "                for j in range(labels.shape[-1])] \n",
    "                for i in range(r['masks'].shape[-1])])\n",
    "        pred_idx, gt_idx = linear_sum_assignment(1-ious)\n",
    "        r['ious'] = np.array([ious[pred_idx[i], gt_idx[i]] \n",
    "                              if (i in pred_idx and i in gt_idx) else 0.0 for i in range(num_pred)])\n",
    "        print(\"IoUs\", r['ious'])\n",
    "        print(\"Scores\", r['scores'])\n",
    "        ious_list.append(ious)\n",
    "        class_names = ['BG'] + [cat['name'] for cat in DATASET['train'].coco.cats.values()]\n",
    "        if show:\n",
    "            plt.figure()\n",
    "            ax = plt.subplot(1, 2, 1)\n",
    "            display_instances(\n",
    "                image + ARGS['config'].MEAN_PIXEL,\n",
    "                boxes,\n",
    "                masks,\n",
    "                class_ids,\n",
    "                class_names, ax=ax)\n",
    "            ax = plt.subplot(1, 2, 2, sharex=ax, sharey=ax)\n",
    "            display_instances(\n",
    "                image + ARGS['config'].MEAN_PIXEL,\n",
    "                r['rois'],\n",
    "                r['masks'],\n",
    "                r['class_ids'],\n",
    "                class_names, ax=ax)\n",
    "            \n",
    "#         imsave(\"/tmp/maskrcnn/image.png\", (image + config.MEAN_PIXEL).astype(np.uint8))\n",
    "        i += 1    \n",
    "        if i >= num_images:\n",
    "                break\n",
    "    return ious_list\n",
    "\n",
    "ious = plot_test(\n",
    "    DATASET['val'].mrcnn_generator(shuffle=True),\n",
    "    exp.model, num_images=1, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcnn.visualize as viz\n",
    "# evaluate_coco(model, dataset_val, coco_val, eval_type=\"segm\", limit=0, image_ids=None)\n",
    "viz.display_weight_stats(exp.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = DATASET['val']\n",
    "image = coco.load_image(1)\n",
    "exp\n",
    "# Get activations of a few sample layers\n",
    "activations = exp.model.run_graph([image], [\n",
    "#     (\"input_image\",        exp.model.keras_model.get_layer(\"input_image\").output),\n",
    "    (\"res2c_out\",          exp.model.keras_model.get_layer(\"res2c_out\").output),\n",
    "    (\"res3c_out\",          exp.model.keras_model.get_layer(\"res3c_out\").output),\n",
    "    (\"res4c_out\",          exp.model.keras_model.get_layer(\"res4c_out\").output),\n",
    "    (\"res5c_out\",          exp.model.keras_model.get_layer(\"res5c_out\").output),\n",
    "    (\"rpn_bbox\",           exp.model.keras_model.get_layer(\"rpn_bbox\").output),\n",
    "    (\"roi\",                exp.model.keras_model.get_layer(\"ROI\").output),\n",
    "])\n",
    "\n",
    "plt.figure()\n",
    "layer_names = [\"res2c_out\", \"res3c_out\", \"res4c_out\", \"res5c_out\"]\n",
    "ax = None\n",
    "for i, layer in enumerate(layer_names):\n",
    "    ax = plt.subplot(len(layer_names) // 2, 2, i + 1)\n",
    "    plt.imshow(activations[layer].sum(axis=3)[0])\n",
    "    plt.title(layer)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Backbone feature map\n",
    "# display_images(np.transpose(activations[\"res2c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n",
    "# display_images(np.transpose(activations[\"res3c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n",
    "# display_images(np.transpose(activations[\"res4c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n",
    "# display_images(np.transpose(activations[\"res5c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "from herbicide.utils import vis_square\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = [299, 299]\n",
    "THUMB_SIZE = [50, 50]\n",
    "IMAGES = None\n",
    "FEATURES = None\n",
    "MASKS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = \"/data/acfr/collated/thesis/lettuce\"\n",
    "def read_log_stats(logdir):\n",
    "    size = pd.read_csv(\n",
    "        os.path.join(logdir, \"stats.csv\"))\n",
    "    size['width'] = size['roi/x2'] - size['roi/x1']\n",
    "    size['height'] = size['roi/y2'] - size['roi/y1']\n",
    "    size['ratio'] = size['height'] / size['width']\n",
    "    size['area'] = size['height'] * size['width']\n",
    "    size['ts'] = size['filename'].apply(pd.to_datetime)\n",
    "\n",
    "    def between_times(ser, t1, t2):\n",
    "        return np.logical_and(\n",
    "            ser >= pd.to_datetime(t1), ser < pd.to_datetime(t2))\n",
    "    # class0 = between_times(size['ts'], '20170329T020104.972891', '20170329T021056.206941')\n",
    "    # class0 |= between_times(size['ts'], '20170329T021911.8', '20170329T023046.677172')\n",
    "    class1 = between_times(size['ts'], '20170329T021056.206941', '20170329T021911.8')\n",
    "    class1 |= between_times(size['ts'], '20170329T023046.677172', '20170329T023847.0')\n",
    "    size['class_ids'] = np.ones_like(class1, dtype=np.uint8) + class1.astype(np.uint8)\n",
    "    # size.rename()\n",
    "    # size.index.name = 'index'\n",
    "    size = size.drop(columns=['Unnamed: 0'])\n",
    "    return size\n",
    "\n",
    "def select_quantiles(df, quantiles, mask=None, exclude=[]):\n",
    "    c = np.ones(len(df), dtype=np.bool)\n",
    "    mask = mask if mask is not None else c.copy()\n",
    "    for name in df.columns:\n",
    "        if name not in exclude:\n",
    "            c &= np.logical_and(\n",
    "                df[name] > df[name][mask].quantile(quantiles[0]),\n",
    "                df[name] < df[name][mask].quantile(quantiles[1]))\n",
    "    return c\n",
    "\n",
    "def drop_outliers(size):\n",
    "    mask = (size['class_ids'] <= 1) #| (size['class_ids'] == 1)\n",
    "    mask &= size['week_no'] == 0\n",
    "    used = select_quantiles(size[['area', 'ratio']], [0.1, 0.9], mask=mask)\n",
    "    used &= select_quantiles(size[['scores']], [0.2, 1.0], mask=mask)\n",
    "    used &= mask\n",
    "    # size.to_csv(os.path.join(LOG_DIR, 'stats.csv'))\n",
    "\n",
    "    print(np.count_nonzero(used))\n",
    "    plt.figure()\n",
    "    plt.scatter(size['height'][~used], size['width'][~used], c=(0, 0.5, 0.5), alpha=0.1)\n",
    "    plt.scatter(size['height'][used], size['width'][used], c=(0, 1, 0), alpha=0.3)\n",
    "    plt.axis('equal')\n",
    "    print(size['ts'][used].dt.week.value_counts())\n",
    "    return size[used]\n",
    "\n",
    "def sample_on(df, column):\n",
    "    # Create views of 'pos' and 'neg' text.\n",
    "    unique_labels = df[column].unique()\n",
    "    num = STATS.groupby(column).size().min()\n",
    "    \n",
    "    # Equally sample 'pos' and 'neg' with replacement and concatenate into a dataframe.\n",
    "    result = pd.concat([\n",
    "        df[df[column] == label].sample(num)\n",
    "        for label in unique_labels], axis=0)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "STATS = read_log_stats(LOG_DIR)\n",
    "STATS = STATS.rename({'index': 'idxz'}, axis=1)\n",
    "STATS['week_no'] = STATS['ts'].dt.week.as_matrix()\n",
    "STATS['week_no'] = STATS['week_no'] - STATS['week_no'].min()\n",
    "STATS['class_ids'] = STATS['class_ids'] - 1\n",
    "STATS = drop_outliers(STATS).reset_index(drop=True)\n",
    "\n",
    "print(3*len(STATS) * (np.ones(IMG_SIZE + [4]).size + np.ones(THUMB_SIZE + [3]).size) / 1024 ** 3, \"GB\")\n",
    "\n",
    "N_CLUSTERS = np.unique(STATS['class_ids']).size\n",
    "print(N_CLUSTERS)\n",
    "STATS['name'] = [\n",
    "    \"{:s}_{:d}.png\".format(name, index)\n",
    "    for name, index in zip(STATS['filename'], STATS['idxz'])]\n",
    "print(len(STATS), STATS.index.max())\n",
    "\n",
    "STATS.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_str(*args, **kwargs):\n",
    "    return '-'.join(\n",
    "        [item[1] for item in sorted(kwargs.items(), key=lambda x: x[0])]\n",
    "    )\n",
    "dataset_str(scale='stretch', mask='none', features='cnn-plantclef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import label2rgb\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import remove_small_holes\n",
    "\n",
    "def resize_image(image, shape, scale_mode='stretch', order=1):\n",
    "    \"\"\"mode can be 'stretch', 'square' or 'keep-scale'\"\"\"\n",
    "    image_dtype = image.dtype\n",
    "    if scale_mode == 'stretch':\n",
    "        return resize(image, shape[0:2], mode='constant', cval=0, preserve_range=True, order=order).astype(image_dtype)\n",
    "    if scale_mode == 'square':\n",
    "        # resize largest side and pad smallest\n",
    "        img_shape = image.shape\n",
    "        scale = np.max(shape[:2]) / np.max(img_shape[:2])\n",
    "        out_dims = np.array([img_shape[0] * scale, img_shape[1] * scale]).round().astype(int)\n",
    "        image = resize(image, out_dims, mode='constant', cval=0, preserve_range=True, order=order).astype(image_dtype)\n",
    "        \n",
    "        img_shape = image.shape\n",
    "        pad_y = (shape[0] - img_shape[0]) / 2\n",
    "        pad_x = (shape[1] - img_shape[1]) / 2\n",
    "        pad_y = [int(np.floor(pad_y)), int(np.ceil(pad_y))]\n",
    "        pad_x = [int(np.floor(pad_x)), int(np.ceil(pad_x))]\n",
    "        if any([i > 0 for i in pad_x + pad_y]):\n",
    "            image = np.pad(\n",
    "                image, [pad_y, pad_x, [0, 0]],\n",
    "                mode='constant', constant_values=[[0], [0], [0]])\n",
    "        return image\n",
    "        \n",
    "    if scale_mode == 'keep-scale':\n",
    "        img_shape = image.shape\n",
    "        diff_y = (shape[0] - img_shape[0]) / 2\n",
    "        diff_x = (shape[1] - img_shape[1]) / 2\n",
    "        diff_y = [int(np.floor(diff_y)), int(np.ceil(diff_y))]\n",
    "        diff_x = [int(np.floor(diff_x)), int(np.ceil(diff_x))]\n",
    "\n",
    "        # Crop\n",
    "        crop_y = [\n",
    "            abs(diff_y[0]) if diff_y[0] <= 0 else 0, \n",
    "            img_shape[0] - abs(diff_y[1]) if diff_y[1] <= 0 else img_shape[0]\n",
    "        ]\n",
    "        crop_x = [\n",
    "            abs(diff_x[0]) if diff_x[0] <= 0 else 0, \n",
    "            img_shape[1] - abs(diff_x[1]) if diff_x[1] <= 0 else img_shape[1]\n",
    "        ]\n",
    "        image = image[crop_y[0]:crop_y[1], crop_x[0]:crop_x[1], ...]\n",
    "\n",
    "        img_shape = image.shape\n",
    "        pad_y = (shape[0] - img_shape[0]) / 2\n",
    "        pad_x = (shape[1] - img_shape[1]) / 2\n",
    "        pad_y = [int(np.floor(pad_y)), int(np.ceil(pad_y))]\n",
    "        pad_x = [int(np.floor(pad_x)), int(np.ceil(pad_x))]\n",
    "        if any([i > 0 for i in pad_x + pad_y]):\n",
    "            image = np.pad(\n",
    "                image, [pad_y, pad_x, [0, 0]],\n",
    "                mode='constant', constant_values=[[0], [0], [0]])\n",
    "        return image\n",
    "    raise ValueError(\"prepare_image.resize_image bad scale_mode: \" + str(scale_mode))\n",
    "    \n",
    "def prepare_image(name, modes):\n",
    "    image_full = imread(os.path.join(LOG_DIR, name))\n",
    "    image = dict()\n",
    "    for mode in modes:\n",
    "        if mode == 'thumb':\n",
    "            image['thumb'] = resize(\n",
    "                image_full, THUMB_SIZE, preserve_range=True, mode='constant', cval=0)\n",
    "        else:\n",
    "            image[mode] = resize_image(image_full, IMG_SIZE, scale_mode=mode, order=1)\n",
    "    return image\n",
    "\n",
    "def prepare_mask(name, images, idx, mask_modes, scale_modes):\n",
    "    \"\"\"Returns dict {tuple: image} where the tuple is (mask_mode, scale_mode)\"\"\"\n",
    "    masks = dict()\n",
    "    for key in itertools.product(mask_modes, scale_modes):\n",
    "        mask_mode, scale_mode = key\n",
    "        if scale_mode == 'thumb':\n",
    "            continue\n",
    "        if mask_mode == 'none':\n",
    "            masks[key] = np.ones(IMG_SIZE + [1], dtype=np.uint8)\n",
    "        elif mask_mode == 'mrcnn':\n",
    "            mask_name = '.'.join(name.split('.')[:-1]) + \"_mask.\" + name.split('.')[-1]\n",
    "            image_full = imread(os.path.join(LOG_DIR, mask_name))\n",
    "            if image_full.ndim == 2:\n",
    "                image_full = image_full[..., np.newaxis]\n",
    "\n",
    "            masks[key] = resize_image(image_full, IMG_SIZE, scale_mode=scale_mode, order=0)\n",
    "        elif mask_mode == 'exgr':\n",
    "            masks[key] = resize_image(\n",
    "                exgr_mask(\n",
    "                    images[scale_mode][idx]),\n",
    "                IMG_SIZE, scale_mode=scale_mode, order=0)[..., np.newaxis]\n",
    "        else:\n",
    "            raise ValueError(\"prepare_mask unknown mask_mode '{}'\".format(mask_mode))\n",
    "    return masks\n",
    "\n",
    "def load_images(mask_modes, scale_modes, load_batch_size=12, parallel=False):\n",
    "    paths = STATS['name'].as_matrix().tolist()\n",
    "    images = {\n",
    "        mode: np.ones([len(paths), *IMG_SIZE, 3], dtype=np.uint8)\n",
    "        for mode in scale_modes if mode != 'thumb'\n",
    "    }\n",
    "    masks = {\n",
    "        (mask_mode, scale_mode): np.ones([len(paths), *IMG_SIZE, 1], dtype=np.uint8)\n",
    "        for mask_mode, scale_mode in itertools.product(mask_modes, scale_modes)\n",
    "        if scale_mode != 'thumb'\n",
    "    }\n",
    "    images['thumb'] = np.ones([len(paths), *THUMB_SIZE, 3], dtype=np.uint8)\n",
    "    \n",
    "    if parallel:\n",
    "        raise NotImplementedError(\"Bug here no parallel\")\n",
    "        for b in range(0, len(paths), load_batch_size):\n",
    "            e = b + np.minimum(load_batch_size, len(paths) - b)\n",
    "            with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "                for idx, ims in zip(range(b, e), executor.map(\n",
    "                        prepare_image, paths[b:e], [scale_modes] * load_batch_size)):\n",
    "                    for mode, image in ims.items():\n",
    "                        images[mode][idx, ...] = image\n",
    "    else:\n",
    "        for idx, path in enumerate(paths):\n",
    "            for scale_mode, image in prepare_image(path, scale_modes).items():\n",
    "                images[scale_mode][idx, ...] = image\n",
    "            for key, mask in prepare_mask(path, images, idx, mask_modes, scale_modes).items():\n",
    "                masks[key][idx, ...] = mask\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "def exgr_mask(image):\n",
    "    image = image.astype(np.float64)\n",
    "    image /= np.maximum(0, np.max(image, (0, 1)))\n",
    "    image /= np.maximum(1, np.sum(image, 2)[..., np.newaxis])\n",
    "    mask = (2 * image[..., 1] - image[..., 2] - image[..., 0]) > 0\n",
    "    label_img = label(mask, background=0)\n",
    "    idx = np.bincount(label_img.ravel())[1:].argmax() + 1 # choose the biggest blob\n",
    "    mask = label_img == idx\n",
    "    mask = remove_small_holes(mask).astype(np.uint8)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATS = STATS.sample(100).reset_index(drop=True)\n",
    "SCALE_MODES = ['stretch', 'square', 'keep-scale']\n",
    "MASK_MODES = ['none', 'mrcnn', 'exgr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES, MASKS = load_images(\n",
    "    MASK_MODES, SCALE_MODES + ['thumb'],\n",
    "    load_batch_size=24, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask_type, scale_type in MASKS.keys():\n",
    "    plt.figure()\n",
    "#     plt.imshow(label2rgb(MASKS[(mask_type, scale_type)][0, ..., 0], IMAGES[scale_type][0]))\n",
    "    plt.imshow((MASKS[(mask_type, scale_type)][0, ...] > 0) * IMAGES[scale_type][0])\n",
    "    plt.title(\"{} {}\".format(mask_type, scale_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_LIST = {\n",
    "    \"area\": (\"$\\sqrt{area}$\", lambda x: x ** 0.5, 'px'),\n",
    "#     \"bbox\": (\"bbox\", lambda x: x, 'px'),\n",
    "#     \"bbox_area\": (\"$\\sqrt{bbox\\ area}$\", lambda x: x ** 0.5, 'px'),\n",
    "    \"centroid\": (\"centroid\", lambda x: x, 'px'),\n",
    "    \"convex_area\": (\"$\\sqrt{convex\\ area}$\", lambda x: x ** 2, 'px'),\n",
    "#     \"convex_image\": (\"convex image\", lambda x: x, 'px'),\n",
    "#     \"coords\": (\"coords\", lambda x: x, 'px'),\n",
    "    \"eccentricity\": (\"eccentricity\", lambda x: x, None),\n",
    "    \"equivalent_diameter\": (\"equivalent diameter\", lambda x: x, 'px'),\n",
    "#     \"euler_number\": (\"euler number\", lambda x: x, None),\n",
    "#     \"extent\": (\"extent\", lambda x: x, None),\n",
    "    \"filled_area\": (\"$\\sqrt{filled\\ area}$\", lambda x: x ** 0.5, 'px'),\n",
    "#     \"filled_image\": (\"filled image\", lambda x: x, 'px'),\n",
    "#     \"image\": (\"image\", lambda x: x, 'px'),\n",
    "#     \"inertia_tensor\": (\"inertia tensor\", lambda x: x ** 0.5, '$px^2$'),\n",
    "    \"inertia_tensor_eigvals\": (\"inertia tensor eigvals\", lambda x: x ** 0.5, '$px^2$'),\n",
    "#     \"intensity_image\": (\"intensity image\", lambda x: x, None),\n",
    "#     \"label\": (\"label\", lambda x: x, 'class number'),\n",
    "    \"local_centroid\": (\"local centroid\", lambda x: x, 'px'),\n",
    "    \"major_axis_length\": (\"major axis length\", lambda x: x, 'px'),\n",
    "    \"max_intensity\": (\"max intensity\", lambda x: x, 'DN'),\n",
    "    \"mean_intensity\": (\"mean intensity\", lambda x: x, 'DN'),\n",
    "    \"min_intensity\": (\"min intensity\", lambda x: x, 'DN'),\n",
    "    \"minor_axis_length\": (\"minor axis length\", lambda x: x, 'px'),\n",
    "    \"moments\": (\"moments\", lambda x: x ** 0.25, '$px^4$'),\n",
    "#     \"moments_central\": (\"moments central\", lambda x: x ** 0.5, '$DN\\ \\dot px^2$'),\n",
    "#     \"moments_hu\": (\"moments hu\", lambda x: x, None),\n",
    "#     \"moments_normalized\": (\"moments normalized\", lambda x: x, None),\n",
    "    \"orientation\": (\"orientation\", lambda x: x, 'rad'),\n",
    "    \"perimeter\": (\"perimeter\", lambda x: x, 'px'),\n",
    "    \"solidity\": (\"solidity\", lambda x: x, None),\n",
    "    \"weighted_centroid\": (\"weighted centroid\", lambda x: x ** 0.5, '$DN\\ \\dot px^2$'),\n",
    "    \"weighted_local_centroid\": (\"weighted local centroid\", lambda x: x, '$DN\\ \\dot px$'),\n",
    "    \"weighted_moments\": (\"weighted moments\", lambda x: x ** 0.5, '$DN\\ \\dot px^2$'),\n",
    "#     \"weighted_moments_central\": (\"$\\sqrt{weighted\\ moments\\ central}$\", lambda x: x ** 0.5, '$\\sqrt{DN}\\ \\dot px$'),\n",
    "#     \"weighted_moments_hu\": (\"weighted moments hu\", lambda x: x, '$DN$'),\n",
    "#     \"weighted_moments_normalized\": (\"weighted moments normalized\", lambda x: x, '$DN$')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __extract_features_hcf(image, mask=None):\n",
    "#         plt.figure()\n",
    "#         plt.imshow(label2rgb(mask[..., 0] if mask.ndim == 3 else mask, image, bg_label=0))\n",
    "        rp = regionprops(mask, image[..., 1])\n",
    "        feats =  {\n",
    "            feature_name: func(np.array(rp[0][feature_name])).ravel() \\\n",
    "            for feature_name, (_, func, _) in FEATURE_LIST.items()}\n",
    "        feat_keys = np.hstack([\n",
    "            [\"{:s}/{:d}\".format(key, i) for i, _ in enumerate(value)]\n",
    "            for key, value in feats.items()])\n",
    "        return np.hstack([feat for feat in feats.values()]), feat_keys\n",
    "\n",
    "    \n",
    "def extract_features(feature_mode, mask_mode, scale_mode):\n",
    "    def extract_features_hcf(images, masks):\n",
    "        import concurrent.futures\n",
    "        assert masks is not None, 'hcf requires a valid mask'\n",
    "        \n",
    "        feats, feat_keys = __extract_features_hcf(images[0], masks[0])\n",
    "        feats = np.ones([len(images), len(feats)])\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            for idx, feat in zip(range(len(feats)), executor.map(__extract_features_hcf, images, masks)):\n",
    "                feats[idx, :] = feat[0]\n",
    "        return feats, feat_keys\n",
    "\n",
    "    def extract_features_convnet(images, masks, weights):\n",
    "        from keras.applications.xception import Xception, preprocess_input\n",
    "        from keras.models import model_from_json, Model\n",
    "        from keras.layers import GlobalAveragePooling2D\n",
    "#         from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "        K.clear_session()\n",
    "        if weights == 'imagenet':\n",
    "#             model = InceptionResNetV2(include_top=False, weights='imagenet', pooling='avg')\n",
    "            model = Xception(include_top=False, weights='imagenet', pooling='avg')\n",
    "        elif weights == 'plantclef':\n",
    "            with open(\"/data/log/cnn/plantclef/xception/130epoch/model_def.json\", \"r\") as file:\n",
    "                model = model_from_json(file.read())\n",
    "            model.load_weights(\n",
    "                \"/data/log/cnn/plantclef/xception/130epoch/model_weights.h5\",\n",
    "                by_name=False)\n",
    "            model = Model(\n",
    "                model.layers[1].inputs[0],\n",
    "                GlobalAveragePooling2D()(model.layers[1].outputs[0])\n",
    "                )\n",
    "        features = np.array([\n",
    "            model.predict(\n",
    "                preprocess_input(image[np.newaxis, ...]) * (mask > 0)\n",
    "            )[0]\n",
    "            for image, mask in zip(images, masks)])\n",
    "        return features, [str(i) for i in range(features.shape[1])]\n",
    "    \n",
    "    data = IMAGES[scale_mode]\n",
    "    masks = MASKS[(mask_mode, scale_mode)]\n",
    "    \n",
    "    if feature_mode == 'hcf':\n",
    "        X_gt_, feats_name = extract_features_hcf(data, masks)\n",
    "    elif feature_mode == \"cnn-plantclef\":\n",
    "        X_gt_, feats_name = extract_features_convnet(data, masks, weights='plantclef')\n",
    "    elif feature_mode == \"cnn-imagenet\":\n",
    "        X_gt_, feats_name = extract_features_convnet(data, masks, weights='imagenet')\n",
    "    else:\n",
    "        raise ValueError(\"extract_features: invalid f_type\")\n",
    "    return pd.DataFrame(X_gt_, columns=feats_name, index=STATS.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test convnet features with various masks\n",
    "def test_conv_masks(scale_name='stretch'):\n",
    "    from keras.applications.xception import Xception, preprocess_input\n",
    "    from keras.models import model_from_json, Model\n",
    "    from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "    with open(\"/data/log/cnn/plantclef/xception/130epoch/model_def.json\", \"r\") as file:\n",
    "            model = model_from_json(file.read())\n",
    "    model.load_weights(\n",
    "        \"/data/log/cnn/plantclef/xception/130epoch/model_weights.h5\",\n",
    "        by_name=False)\n",
    "    model = Model(\n",
    "        model.layers[1].inputs[0],\n",
    "        GlobalAveragePooling2D()(model.layers[1].outputs[0])\n",
    "        )\n",
    "    features = dict()\n",
    "    image = IMAGES[scale_name][0]\n",
    "    for mask_name in ['exgr', 'mrcnn', 'none']:\n",
    "        mask = MASKS[(mask_name, scale_name)][0]\n",
    "        masked_image = image * (mask > 0)\n",
    "        print(image.shape, mask.shape, masked_image.shape)\n",
    "        plt.figure()\n",
    "        plt.imshow(masked_image)\n",
    "        features[(mask_name, scale_name)] = model.predict(\n",
    "            preprocess_input(masked_image[np.newaxis, ...]))[0]\n",
    "    return features\n",
    "    \n",
    "feat_comp = test_conv_masks()\n",
    "plt.figure()\n",
    "plt.hist(\n",
    "    [feat_comp[('none', 'stretch')].ravel(),\n",
    "     feat_comp[('exgr', 'stretch')].ravel(),\n",
    "     feat_comp[('mrcnn', 'stretch')].ravel()],\n",
    "    bins=30, log=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_MODES =  ['hcf', 'cnn-plantclef', 'cnn-imagenet']\n",
    "FEATURES = dict()\n",
    "\n",
    "for comb in itertools.product(\n",
    "        FEATURE_MODES,\n",
    "        MASK_MODES,\n",
    "        SCALE_MODES):\n",
    "    if comb[0] == 'hcf' and comb[1] == 'none':\n",
    "        continue\n",
    "    print(comb)\n",
    "    FEATURES[comb] = extract_features(*comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load Images/Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"lettuce-type\"\n",
    "prefix = \"/data/acfr/collated/thesis/lettuce/pickle/{:s}_\".format(save_name)\n",
    "# # IMAGES, MASKS, FEATURES = None, None, None\n",
    "\n",
    "if IMAGES:\n",
    "    with open(prefix + \"IMAGES.pkz\", \"wb\") as file:\n",
    "        pickle.dump(IMAGES, file)\n",
    "else:\n",
    "    with open(prefix + \"IMAGES.pkz\", \"rb\") as file:\n",
    "        IMAGES = pickle.load(file)\n",
    "\n",
    "if MASKS:\n",
    "    with open(prefix + \"MASKS.pkz\", \"wb\") as file:\n",
    "        pickle.dump(MASKS, file)\n",
    "else:\n",
    "    with open(prefix + \"MASKS.pkz\", \"rb\") as file:\n",
    "        MASKS = pickle.load(file)\n",
    "        \n",
    "if FEATURES:\n",
    "    with open(prefix + \"FEATURES.pkz\", \"wb\") as file:\n",
    "        pickle.dump(FEATURES, file)\n",
    "else:\n",
    "    with open(prefix + \"FEATURES.pkz\", \"rb\") as file:\n",
    "        FEATURES = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.base import (BaseEstimator, ClassifierMixin, ClusterMixin,\n",
    "                          TransformerMixin)\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             precision_score)\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.model_selection import (GridSearchCV, StratifiedKFold,\n",
    "                                     train_test_split)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "\n",
    "# Setup data\n",
    "stats = sample_on(STATS, 'class_ids')\n",
    "features = FEATURES[('cnn-imagenet', 'exgr', 'stretch')]\n",
    "features = features.loc[stats.index & features.index]\n",
    "\n",
    "class_key = 'class_ids'\n",
    "X_gt = features\n",
    "y_gt = stats[class_key]#[subset]\n",
    "print(\"shapes:\", X_gt.shape, y_gt.shape)\n",
    "print(\"types:\", type(X_gt), type(y_gt))\n",
    "print(\"classes:\", np.unique(y_gt))\n",
    "\n",
    "# Data examples\n",
    "def test(stats, y_gt, class_key):\n",
    "    unique_y = np.unique(y_gt)\n",
    "    plt.figure()\n",
    "    for i, label in enumerate (unique_y):\n",
    "        plt.subplot(1, unique_y.size, 1 + i)\n",
    "        idx = stats[stats[class_key] == label].sample().index\n",
    "        plt.imshow(IMAGES['stretch'][idx[0].astype(int), ...])\n",
    "test(stats, y_gt, class_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Plot\n",
    "def plot_labels(X, y_true, y_pred, pca=True):\n",
    "    markers = np.array(['C'+str(i) + '.+v^<>s8p*xD'[j] for i, j in zip(y_true, y_pred)])\n",
    "    pca_feats = PCA(n_components=3).fit_transform(\n",
    "        StandardScaler(with_mean=True, with_std=True).fit_transform(X))\n",
    "    X = pca_feats if pca else X\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for marker in np.unique(markers):\n",
    "        pos = X[markers == marker]\n",
    "        ax.plot3D(pos[:, 0], pos[:, 1], pos[:, 2], marker, alpha=0.5)\n",
    "#     ax.scatter(pca_feats[:, 0], pca_feats[:, 1], pca_feats[:, 2], c=c)\n",
    "    print(sorted(Counter(markers).items(), key=lambda x: x[0]))\n",
    "    \n",
    "    \n",
    "plot_labels(X_gt, y_gt, y_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for label in np.unique(y_gt):\n",
    "    X_class = X_gt[y_gt == label]\n",
    "    summary = X_class.mean(axis=0)\n",
    "    print(X_class.shape, summary.shape)\n",
    "    plt.plot(summary, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "for split_no, (train_index, test_index) in enumerate(skf.split(X_gt, y_gt)):\n",
    "    X_train, X_test = X_gt.iloc[train_index], X_gt.iloc[test_index]\n",
    "    y_train, y_test = y_gt.iloc[train_index], y_gt.iloc[test_index]\n",
    "    class_weight = compute_class_weight('balanced', sorted(np.unique(y_train)), y_train)\n",
    "    class_weight = {label: weight for label, weight in zip(sorted(np.unique(y_train)), class_weight)}\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    estimator = SVC(C=1.0, class_weight=class_weight, probability=True)\n",
    "    \n",
    "    estimator.fit(scaler.fit_transform(X_train), y_train)\n",
    "    y_pred = estimator.predict_proba(scaler.transform(X_test))\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, y_pred.argmax(-1))\n",
    "    average_precision = sklearn.metrics.average_precision_score(y_test, y_pred.argmax(-1), average='micro')\n",
    "    print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "    print('Accuracy score: {0:0.2f}'.format(accuracy))\n",
    "    \n",
    "precision, recall, _ = sklearn.metrics.precision_recall_curve(\n",
    "    y_test, y_pred[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "plot_labels(X_test, y_test, y_pred.argmax(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Clustering\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "for split_no, (train_index, test_index) in enumerate(skf.split(X_gt, y_gt)):\n",
    "    X_train, X_test = X_gt.iloc[train_index], X_gt.iloc[test_index]\n",
    "    y_train, y_test = y_gt.iloc[train_index], y_gt.iloc[test_index]\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.hist(X_train.mean(axis=-1))\n",
    "#     print(X_train[0].shape)\n",
    "    \n",
    "    scaler = StandardScaler(with_mean=False, with_std=False)\n",
    "    transformer = StandardScaler(with_mean=False, with_std=False)\n",
    "#     transformer = KernelPCA(n_components=3, kernel='rbf', gamma=1e-2)\n",
    "    transformer = PCA(n_components=3)\n",
    "#     transformer = BernoulliRBM(n_components=3, learning_rate=1e-4, n_iter=10)\n",
    "    \n",
    "#     estimator = BayesianGaussianMixture(\n",
    "#         n_components=10,\n",
    "#         weight_concentration_prior_type=\"dirichlet_process\",\n",
    "#         weight_concentration_prior=1e1)\n",
    "    estimator = KMeans(n_clusters=2)\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_train, X_test = minmax_scale(X_train), minmax_scale(X_test)\n",
    "    \n",
    "    X_train = transformer.fit_transform(X_train)\n",
    "    X_test = transformer.transform(X_test)\n",
    "\n",
    "    estimator.fit(X_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    \n",
    "    print(sklearn.metrics.normalized_mutual_info_score(y_test, y_pred))\n",
    "#     print(estimator.weights_)\n",
    "    print(np.unique(y_pred))\n",
    "    \n",
    "plot_labels(X_test, y_test, y_pred, pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "\n",
    "def display_table(table):\n",
    "    \"\"\"Display values in a table format.\n",
    "    table: an iterable of rows, and each row is an iterable of values.\n",
    "    \"\"\"\n",
    "    html = \"\"\n",
    "    for row in table:\n",
    "        row_html = \"\"\n",
    "        for col in row:\n",
    "            row_html += \"<td>{:40}</td>\".format(str(col))\n",
    "        html += \"<tr>\" + row_html + \"</tr>\"\n",
    "    html = \"<table>\" + html + \"</table>\"\n",
    "    IPython.display.display(IPython.display.HTML(html))\n",
    "\n",
    "\n",
    "def display_weight_stats(model):\n",
    "    \"\"\"Scans all the weights in the model and returns a list of tuples\n",
    "    that contain stats about each weight.\n",
    "    \"\"\"\n",
    "    layers = model.layers\n",
    "    table = [[\"WEIGHT NAME\", \"TRAIN\", \"SHAPE\", \"MIN\", \"MAX\", \"STD\"]]\n",
    "    for l in layers:\n",
    "        weight_values = l.get_weights()  # list of Numpy arrays\n",
    "        weight_tensors = l.weights  # list of TF tensors\n",
    "        for i, w in enumerate(weight_values):\n",
    "            weight_name = weight_tensors[i].name\n",
    "            # Detect problematic layers. Exclude biases of conv layers.\n",
    "            alert = \"\"\n",
    "            if w.min() == w.max() and not (l.__class__.__name__ == \"Conv2D\" and i == 1):\n",
    "                alert += \"<span style='color:red'>*** dead?</span>\"\n",
    "            if np.abs(w.min()) > 1000 or np.abs(w.max()) > 1000:\n",
    "                alert += \"<span style='color:red'>*** Overflow?</span>\"\n",
    "            # Add row\n",
    "            table.append([\n",
    "                weight_name + alert,\n",
    "                str(weight_tensors[i].trainable),\n",
    "                str(w.shape),\n",
    "                \"{:+9.4f}\".format(w.min()),\n",
    "                \"{:+10.4f}\".format(w.max()),\n",
    "                \"{:+9.4f}\".format(w.std()),\n",
    "            ])\n",
    "    display_table(table)\n",
    "\n",
    "import keras.models\n",
    "\n",
    "model = None\n",
    "K.clear_session()\n",
    "with open(\"/data/log/cnn/plantclef/xception/130epoch/model_def.json\", \"r\") as file:\n",
    "    model = keras.models.model_from_json(file.read())\n",
    "model.load_weights(\n",
    "    \"/data/log/cnn/plantclef/xception/130epoch/model_weights.h5\",\n",
    "    by_name=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "display_weight_stats(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglom Clustering\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "for split_no, (train_index, test_index) in enumerate(skf.split(X_gt, y_gt)):\n",
    "    X_train, X_test = X_gt.iloc[train_index], X_gt.iloc[test_index]\n",
    "    y_train, y_test = y_gt.iloc[train_index], y_gt.iloc[test_index]\n",
    "    knn_graph = kneighbors_graph(X_test, 30, include_self=False)\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    transformer = StandardScaler(with_mean=False, with_std=False)\n",
    "    transformer = PCA(n_components=3)\n",
    "    \n",
    "    estimator = AgglomerativeClustering(\n",
    "        linkage='ward',\n",
    "        connectivity=knn_graph,\n",
    "        n_clusters=2)\n",
    "    estimator.fit(transformer.fit_transform(scaler.fit_transform(X_test)))\n",
    "    y_pred = estimator.labels_\n",
    "    \n",
    "    print(sklearn.metrics.normalized_mutual_info_score(y_test, y_pred))\n",
    "#     print(estimator.weights_)\n",
    "    print(np.unique(y_pred))\n",
    "plot_labels(X_test, y_test, y_pred, pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_w = np.linalg.norm(pipeline.named_steps.feat_sel.components_, axis=0)\n",
    "# pca = pd.DataFrame(\n",
    "#     data=pipeline.named_steps.feat_sel.explained_variance_ratio_,  \n",
    "#     index=pd.Series([feats_name[i] for i in pca_w.argsort()[::-1]], name='Feature'),\n",
    "#     columns=['Var Ratio'])\n",
    "# print(pca.sum())\n",
    "# pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test Classifier\n",
    "\n",
    "\n",
    "# def test_classifier(feature_set, weeks):\n",
    "#     subset = STATS['week_no'].apply(lambda x: x in weeks).as_matrix()\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         FEATURES[feature_set][0][subset],\n",
    "#         STATS['week_no'][subset],\n",
    "#         test_size=0.2)\n",
    "#     class_weight = compute_class_weight('balanced', sorted(np.unique(y_train)), y_train)\n",
    "#     class_weight = {label: weight for label, weight in zip(sorted(np.unique(y_train)), class_weight)}\n",
    "#     estimator = Pipeline([\n",
    "#         ('scaler', StandardScaler()),\n",
    "# #         ('transformer', PCA(n_components=30)),\n",
    "#         ('estimator', SVC(kernel='rbf', C=1, class_weight=class_weight))\n",
    "#     ])\n",
    "\n",
    "#     estimator.fit(X_train, y_train)\n",
    "#     return estimator.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# # import statsmodels.api as sm\n",
    "# # df = pd.DataFrame(results)\n",
    "# # plt.figure()\n",
    "# # for i, (supervision, group) in enumerate(df.groupby('supervision')):\n",
    "# #     ax = plt.subplot(1, 2, 1 + i)\n",
    "# #     vals = group.sort_values(by='k_features')\n",
    "# #     vals.plot(x='k_features', y='precision', style='.', ax=ax)\n",
    "# #     regression = sm.formula.ols(formula='precision ~ k_features', data=vals)\n",
    "# #     res = regression.fit()\n",
    "# #     vals.assign(fit=res.fittedvalues).plot(x='k_features', y='fit', ax=ax)\n",
    "# # plt.suptitle('HCF Features')\n",
    "# # plt.gcf().axes[0].set_ylabel('precision')\n",
    "# # # df[['precision', 'supervision']].boxplot( by='supervision')\n",
    "\n",
    "# results = []\n",
    "# _weeks = [(0, 1), (0, 1, 2), (0, 1, 2, 3), (0, 1, 2, 3, 4)]\n",
    "# for features, image_mode in FEATURES.keys():\n",
    "#     print(features, image_mode)\n",
    "#     for weeks in _weeks:\n",
    "#         score = test_classifier((features, image_mode, mask_mode), weeks)\n",
    "#         results.append({\n",
    "#             'features': features + \"-\" + mask_mode if features == \"hcf\" else features,\n",
    "#             'image scaling': image_mode,\n",
    "#             'weeks': weeks[-1],\n",
    "#             'test score': score\n",
    "#         })\n",
    "# results = pd.DataFrame(results)\n",
    "# results.groupby(['features', 'image scaling', 'weeks']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,6), dpi=150)\n",
    "# _, axes = plt.subplots(1, 2)\n",
    "# for i, (key, group) in enumerate(results.groupby(\"features\")):\n",
    "#     ax = 0 if key == 'cnn' else 1\n",
    "#     for scale_type, subgroup in group.groupby('image scaling'):\n",
    "#         subgroup.sort_values('weeks').plot(\n",
    "#             x='weeks', y='test score',\n",
    "#             label=str( key + \" \" + scale_type), ax=axes[ax])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = STATS[['height', 'width', 'filename']][STATS['week_no'] == 4].sample()['filename']\n",
    "# print(IMAGES['keep-scale'][sample.index].shape)\n",
    "# plt.figure()\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.imshow(IMAGES['keep-scale'][sample.index][0])\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.imshow(exgr_mask(IMAGES['keep-scale'][sample.index][0]))\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.imshow(MASKS['keep-scale'][sample.index][0][..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    #data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "            + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data\n",
    "\n",
    "def save_embeddings(LOG_DIR, features, labels, sprite=None, sprite_shape=None):\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.contrib.tensorboard.plugins import projector\n",
    "    \n",
    "    !rm -R \"$LOG_DIR\"\n",
    "    !mkdir -p \"$LOG_DIR\"\n",
    "\n",
    "    metadata = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "    features = tf.Variable(features, name='features')\n",
    "\n",
    "    with open(metadata, 'w') as metadata_file:\n",
    "        for row in labels:\n",
    "            metadata_file.write('%d\\n' % row)\n",
    "            \n",
    "    if sprite is not None:\n",
    "        imsave(os.path.join(LOG_DIR, 'sprite.png'), sprite)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver([features])\n",
    "\n",
    "        sess.run(features.initializer)\n",
    "        saver.save(sess, os.path.join(LOG_DIR, 'features.ckpt'))\n",
    "\n",
    "        config = projector.ProjectorConfig()\n",
    "        # One can add multiple embeddings.\n",
    "        embedding = config.embeddings.add()\n",
    "        embedding.tensor_name = features.name\n",
    "        # Link this tensor to its metadata file (e.g. labels).\n",
    "        embedding.metadata_path = metadata\n",
    "        if sprite is not None:\n",
    "            embedding.sprite.image_path = os.path.join(LOG_DIR, 'sprite.png')\n",
    "            embedding.sprite.single_image_dim.extend(sprite_shape)\n",
    "        # Saves a config file that TensorBoard will read during startup.\n",
    "        projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save_embeddings(\n",
    "#     \"/data/log/embeddings/lettuce-w2to6-HCFcrop_SS_PCA_RBF_GMM\",\n",
    "#     StandardScaler().fit_transform(X_gt_),\n",
    "#     y_gt_,\n",
    "#     sprite=images_to_sprite(thumbs), sprite_shape=THUMB_SIZE)\n",
    "## d = pd.DataFrame(X_gt_, columns=feats_name)\n",
    "## d.to_csv(\"/data/acfr/collated/thesis/hcf-crop.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noop(BaseEstimator, TransformerMixin):\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        return X\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        pass\n",
    "    def transform(self, X, **kwargs):\n",
    "        return X\n",
    "    def set_params(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "class ClassificationExperiment(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "\n",
    "        scaling_type: one of the following:\n",
    "            'stretch': Stretch the image across image_size, does not keep ratio.\n",
    "            'square': Stretch the largest dimension, pad the smallest to keep h/w ratio.\n",
    "            'keep-scale': Pad or crop both dimensions to keep the x/y ratio.\n",
    "            \n",
    "        image_size: [N, M] shape to resize images to #TODO\n",
    "        \n",
    "        features: one of the following:\n",
    "            'hcf-exgr': Use selected hand crafted features (ExGR mask)\n",
    "            'hcf-mrcnn': Use selected hand crafted features (MRCNN masks)\n",
    "            'cnn-imagenet': Use CNN features trained from imagenet\n",
    "            'cnn-plantclef': Use CNN features trained from plantCLEF\n",
    "        \n",
    "        cnn_pooling: either 'avg' or 'max'\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, features='cnn-plantclef', mask_mode='exgr', scaling_type='stretch'):\n",
    "        self.scaling_type = scaling_type\n",
    "        self.features = features\n",
    "        self.mask_mode = mask_mode\n",
    "#         self.image_size = image_size\n",
    "#         self.cnn_pooling = cnn_pooling\n",
    "        self._reload_data()\n",
    "        \n",
    "    def _reload_data(self):\n",
    "        key = (self.features, self.mask_mode, self.scaling_type)\n",
    "        if key not in FEATURES:\n",
    "            raise ValueError(\"Not a valid combination of scaling_type and features \" + str(key))\n",
    "        self.X_gt_ = FEATURES[key]\n",
    "#         self.X_gt_ = self.X_gt_\n",
    "        self.y_gt_ = STATS['class_ids'].as_matrix()\n",
    "        \n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        \"\"\"x is indices of features and labels\"\"\"\n",
    "        return self.X_gt_.iloc[X]\n",
    "    \n",
    "#     def transform_label(self, y, **kwargs):\n",
    "#         \"\"\"x is indices of features and labels\"\"\"\n",
    "#         return self.y_gt_.iloc[y]\n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        return 0.0\n",
    "    \n",
    "    def fit_transform(self, X, y=None, **kwargs):\n",
    "        \"\"\"x is indices of features and labels\"\"\"\n",
    "        return self.transform(X, y)\n",
    "    \n",
    "    def stats(self, test_size=0.1):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X_gt_, self.y_gt_, test_size=test_size)\n",
    "        print(\"trivial accuracy\")\n",
    "        print([np.count_nonzero(l == y_test) / y_test.size for l in sorted(np.unique(y_test))])\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        reload_data = False\n",
    "        if 'features' in params:\n",
    "            self.features = params.pop('features')\n",
    "            reload_data = True\n",
    "        if 'scaling_type' in params:\n",
    "            self.scaling_type = params.pop('scaling_type')\n",
    "            reload_data = True\n",
    "        if reload_data:\n",
    "            self._reload_data()\n",
    "        super().set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ClassificationExperiment(\n",
    "    scaling_type='stretch', mask_mode='none', features='cnn-plantclef')\n",
    "exp.stats()\n",
    "exp.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_CLUSTERS = 2\n",
    "from sklearn import metrics\n",
    "def encode_onehot(x, num_classes):\n",
    "    y = np.zeros((len(x), num_classes))\n",
    "    y[np.arange(len(x)), x] = 1\n",
    "    return y\n",
    "\n",
    "def micro_average_precision_score(x, y):\n",
    "    return metrics.average_precision_score(\n",
    "        encode_onehot(x, N_CLUSTERS),\n",
    "        encode_onehot(y, N_CLUSTERS),\n",
    "        average='micro')\n",
    "\n",
    "y_train = STATS['class_ids'].as_matrix()\n",
    "class_weight = compute_class_weight('balanced', sorted(np.unique(y_train)), y_train)\n",
    "class_weight = {label: weight for label, weight in zip(sorted(np.unique(y_train)), class_weight)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(experiment_type):\n",
    "    feature_modes =  ['hcf']#'cnn-plantclef', 'cnn-imagenet']\n",
    "    mask_modes = ['exgr', 'mrcnn']\n",
    "    if experiment_type == 'classification':\n",
    "        parameters = [ # CLASSIFICATION\n",
    "            {\n",
    "                'source__features': feature_modes,\n",
    "                'source__scaling_type': SCALE_MODES,\n",
    "                'source__mask_mode': mask_modes,\n",
    "                'transformer': [None],\n",
    "                'estimator': [LinearSVC(penalty='l1', dual=False, class_weight=class_weight)],\n",
    "                'estimator__C': 2.0 ** np.arange(-4, 2),\n",
    "            },\n",
    "            {\n",
    "                'source__features': feature_modes,\n",
    "                'source__scaling_type': SCALE_MODES,\n",
    "                'source__mask_mode': mask_modes,\n",
    "                'transformer': [None],\n",
    "                'estimator': [SVC(kernel='rbf', class_weight=class_weight)],\n",
    "                'estimator__C': 2.0 ** np.arange(-1, 5),\n",
    "            },\n",
    "            {\n",
    "                'source__features': feature_modes,\n",
    "                'source__scaling_type': SCALE_MODES,\n",
    "                'source__mask_mode': mask_modes,\n",
    "                'transformer': [None],\n",
    "                'estimator': [RandomForestClassifier(n_estimators=250, class_weight=class_weight)],\n",
    "            },\n",
    "        ]\n",
    "        scoring = {\n",
    "            'precision': metrics.make_scorer(micro_average_precision_score),\n",
    "            'accuracy': metrics.make_scorer(metrics.accuracy_score)\n",
    "        }\n",
    "        estimator = SVC()\n",
    "        refit = 'precision'\n",
    "    elif experiment_type == 'cluster':\n",
    "        parameters = [ #CLUSTERING\n",
    "            {\n",
    "                'source__features': FEATURE_MODES,\n",
    "                'source__scaling_type': SCALE_MODES,\n",
    "                'transformer': [None, PCA(n_components=55)],\n",
    "                'estimator': [KMeans()],\n",
    "                'estimator__n_clusters': [2],\n",
    "            },\n",
    "        ]\n",
    "        scoring = {\n",
    "            'NMI': metrics.make_scorer(metrics.adjusted_mutual_info_score),\n",
    "        }\n",
    "        estimator = KMeans()\n",
    "        refit = 'NMI'\n",
    "\n",
    "    estimator = Pipeline([\n",
    "        ('source', ClassificationExperiment()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('transformer', PCA()),\n",
    "        ('estimator', estimator)\n",
    "    ])\n",
    "\n",
    "    subset = STATS['class_ids'].apply(lambda x: True).as_matrix()\n",
    "#     subset[::100] = True\n",
    "    grid = GridSearchCV(\n",
    "        estimator, parameters,\n",
    "        cv=StratifiedKFold(n_splits=3, shuffle=True),\n",
    "        scoring=scoring, refit=refit,\n",
    "        n_jobs=12, return_train_score=True)\n",
    "    grid.fit(\n",
    "        np.arange(len(STATS))[subset],\n",
    "        STATS['class_ids'].as_matrix()[subset])\n",
    "    return pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "results = experiment('classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['PCA'] = results['param_transformer'].apply(lambda x: 0 if x is None else x.n_components)\n",
    "results['model'] = results['param_estimator'].apply(lambda x: repr(x).split(\"(\")[0])\n",
    "results['param_estimator__C'] = results['param_estimator__C'].apply(lambda x: 0 if np.isnan(x) else x)\n",
    "results[results['param_source__scaling_type'] == 'stretch'].sort_values('mean_test_accuracy', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.to_csv(\"/data/acfr/collated/thesis/results.csv\")\n",
    "results2 = results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', 3):\n",
    "#     print(results.groupby(\n",
    "#         ['param_source__scaling_type', 'param_source__features',\n",
    "#          'PCA', 'model', 'param_estimator__C']).mean()[['mean_test_accuracy']])\n",
    "\n",
    "group = ['param_source__scaling_type', 'param_source__features', 'param_source__mask_mode', 'model']\n",
    "idx = results.sort_values(by='mean_test_accuracy', ascending=False).index\n",
    "results.loc[idx]#\n",
    "# results.groupby(group)['mean_test_accuracy'].max()[24:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in results.groupby(group[:-1], sort=True):\n",
    "    idx_max_acc = val['mean_test_accuracy'].idxmax()\n",
    "    idx_max_precision = val['mean_test_precision'].idxmax()\n",
    "#     print(idx_max_acc == idx_max_precision)\n",
    "    best = results.loc[idx_max_precision]\n",
    "#     print(*idx, sep=\"\\t\", end='\\t')\n",
    "    print(\n",
    "#         round(best['mean_test_accuracy'], 3),\n",
    "#         round(best['mean_test_precision'], 3),\n",
    "#         best['model'],\n",
    "        best['param_estimator__C'], sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(prefix + \"results_type.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = ['param_source__scaling_type', 'param_source__features']\n",
    "idx = results.groupby(group, sort=False)['mean_test_score'].idxmax()\n",
    "results.loc[idx].sort_values(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([results, results2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"/data/acfr/collated/thesis/lettuce/pickle/lettuce-type_results_type.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
