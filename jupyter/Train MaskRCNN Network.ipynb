{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import concurrent.futures\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from skimage.color import label2rgb\n",
    "from keras import Model\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from pycocotools.coco import COCO\n",
    "from collections import Counter\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "# from abyss_deep_learning.keras.detection import MaskRcnnDataset\n",
    "from mrcnn.model import MaskRCNN, data_generator\n",
    "from mrcnn.utils import Dataset as MrcnnDatasetBase\n",
    "\n",
    "from skimage.morphology import remove_small_holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path):\n",
    "    spec = importlib.util.spec_from_file_location(\n",
    "        \"maskrcnn_config\", path)\n",
    "    config_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(config_module)\n",
    "    config = config_module.Config()\n",
    "    input_shape = config.IMAGE_SHAPE\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionTask(CocoInterface, DatasetTaskBase):\n",
    "    def __init__(self, coco, translator=None, **kwargs):\n",
    "        '''Assumes that the data can be anything, but each data has 0 or more targets.\n",
    "\n",
    "        kwargs:\n",
    "          * cached: (Boolean)\n",
    "              Cache the targets in memory instead of loading it every time\n",
    "          * force_balance: (Boolean) #TODO\n",
    "              Sample ids such that all classes are balanced to the smallest class.\n",
    "          * translator: (Callable)\n",
    "              After loading the data target run it through this translator function.\n",
    "              Must be an instance of a subclass of abyss.datasets.translators.AnnotationTranslator.\n",
    "              Should be used for example remapping captions.\n",
    "        '''\n",
    "        CocoInterface.__init__(self, coco, **kwargs)\n",
    "        assert isinstance(translator, (AnnotationTranslator, type(None)))\n",
    "        self.translator = translator or AnnotationTranslator()\n",
    "        self.captions = set(sorted([\n",
    "            caption\n",
    "            for annotation in self.coco.loadAnns(self.coco.getAnnIds(imgIds=[]))\n",
    "            for caption in self.translator.translate(annotation)\n",
    "            if self.translator.filter(annotation)]))\n",
    "        self.num_classes = len(self.captions)\n",
    "        self.stats = dict()\n",
    "        self._targets = dict()\n",
    "\n",
    "        self._preprocess_targets = kwargs.get('preprocess_targets', _noop)\n",
    "\n",
    "        if kwargs.get('cached', False):\n",
    "            with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "                for data_id, targets in zip(\n",
    "                        self.data_ids, executor.map(self.load_targets, self.data_ids)):\n",
    "                    self._targets[data_id] = targets\n",
    "\n",
    "        self._calc_class_stats()\n",
    "\n",
    "    def load_targets(self, data_id, **kwargs):\n",
    "        if data_id in self._targets:\n",
    "            return self._targets[data_id]\n",
    "        \n",
    "        image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                load_image_gt(dataset, config, image_id, augment=augment,\n",
    "                              augmentation=None,\n",
    "                              use_mini_mask=config.USE_MINI_MASK)\n",
    "            \n",
    "        batch_images = mold_image(image.astype(np.float32), config)\n",
    "        \n",
    "        batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox,\n",
    "                          batch_gt_class_ids, batch_gt_boxes, batch_gt_masks\n",
    "\n",
    "    def _calc_class_stats(self):\n",
    "        if not self.stats:\n",
    "            targets = [self.load_targets(data_id) for data_id in self.data_ids]\n",
    "            unlabeled = sum([1 for target in targets if not target])\n",
    "            self.stats['unlabeled'] = unlabeled / len(self.data_ids)\n",
    "            targets = [caption \n",
    "                for captions in targets\n",
    "                for caption in captions]\n",
    "            self.stats['images_per_class'] = dict(sorted(Counter(targets).items(), key=lambda x: x[0]))\n",
    "            class_weights = compute_class_weight('balanced', list(self.captions), targets)\n",
    "            class_weights = {i: float(np.round(v, 3)) for i, v in enumerate(class_weights)}\n",
    "            self.stats['class_weights'] = class_weights\n",
    "            a = np.array(list(class_weights.values()))\n",
    "            self.stats['trivial_accuracy'] = np.mean(a / np.max(a))\n",
    "\n",
    "    @property\n",
    "    def class_weights(self):\n",
    "        '''Returns the class weights that will balance the backprop update over the class distribution.'''\n",
    "        return self.stats['class_weights']\n",
    "\n",
    "    def print_class_stats(self):\n",
    "        '''Prints statistics about the class/image distribution.'''\n",
    "        self._calc_class_stats()\n",
    "        print(\"{:s} class stats {:s}\".format('=' * 8, '=' * 8))\n",
    "        print(\"data count per class:\")\n",
    "        print(\" \", self.stats['images_per_class'])\n",
    "        print(\"class weights:\")\n",
    "        print(\" \", self.class_weights)\n",
    "        print(\"trivial result accuracy:\\n  {:.2f} or {:.2f}\".format(\n",
    "            self.stats['trivial_accuracy'], 1 - self.stats['trivial_accuracy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MrcnnCocoDataset(CocoDataset, ImageDatatype, DetectionTask):\n",
    "    # TODO: \n",
    "    #   *  Class statistics readout\n",
    "    #   *  Support for computing class weights given current dataset config\n",
    "    #   *  Support for forcing class balance by selecting IDs evenly\n",
    "    #   *  Generator data order optimization\n",
    "    #   *  Support for visualising data sample or prediction with same format\n",
    "    def __init__(self, json_path, **kwargs):\n",
    "        CocoDataset.__init__(self, json_path, **kwargs)\n",
    "        ImageDatatype.__init__(self, self.coco, **kwargs)\n",
    "        ClassificationTask.__init__(self, self.coco, **kwargs)\n",
    "        \n",
    "    def sample(self, image_id=None, **kwargs):\n",
    "        if not image_id:\n",
    "            image_id = random.choice(self.data_ids)\n",
    "        return (self.load_data(image_id, **kwargs), self.load_targets(image_id, **kwargs))\n",
    "            \n",
    "    def generator(self, data_ids=None, shuffle_ids=False, endless=False, **kwargs):\n",
    "        if not data_ids:\n",
    "            data_ids = list(self.data_ids)\n",
    "        if shuffle_ids:\n",
    "            random.shuffle(data_ids)\n",
    "        iterator = itertools.cycle if endless else iter\n",
    "        for data_id in iterator(data_ids):\n",
    "            yield self.load_data(data_id, **kwargs), self.load_targets(data_id, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = None\n",
    "categories = None\n",
    "num_classes = 2\n",
    "use_balanced_set = False\n",
    "use_class_weights = True\n",
    "config_file = \"/home/docker/src/abyss/deep-learning/configs/MaskRCNN_default_config.py\"\n",
    "aug_config = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Sometimes(0.9, iaa.Multiply((0.8, 1.2))),\n",
    "    iaa.Affine(\n",
    "        scale=(0.85, 1.15),\n",
    "        translate_percent={\"x\": (-0.15, 0.15), \"y\": (-0.15, 0.15)},\n",
    "        rotate=(-45, 45),\n",
    "        shear=0.0,\n",
    "        order=1,\n",
    "        cval=0,\n",
    "        mode='constant',\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dir = \"/data/acfr/collated/2017-summer-lettuce\"\n",
    "dataset_name = \"weeks2to6\"\n",
    "\n",
    "########## Don't modify below\n",
    "dataset_files = {\n",
    "    'train': os.path.join(database_dir, \"{:s}/train.json\".format(dataset_name)),\n",
    "    'val': os.path.join(database_dir, \"{:s}/val.json\".format(dataset_name)),\n",
    "    'test': os.path.join(database_dir, \"{:s}/val.json\".format(dataset_name))\n",
    "}\n",
    "dataset = {\n",
    "    'names': list(dataset_files.keys()),\n",
    "    'classes': [], # MUST FILL IN\n",
    "    'class_weights': {name: None for name in dataset_files.keys()},\n",
    "    'ids' : {},\n",
    "    'gens': {},\n",
    "    'data': {},\n",
    "    'coco': {},\n",
    "    'config': load_config(config_file)\n",
    "}\n",
    "\n",
    "for name, path in dataset_files.items():\n",
    "    coco = MaskRcnnDataset(path)\n",
    "    ids = coco.image_ids\n",
    "    gen = data_generator(coco, dataset['config'], shuffle=True, augmentation=aug_config, detection_targets=False)\n",
    "    print(\"{:s}: {:d} images\".format(name, len(ids)))\n",
    "    dataset['coco'][name] = coco\n",
    "    dataset['ids'][name] = ids\n",
    "    dataset['gens'][name] = gen\n",
    "\n",
    "dataset['name'] = dataset_name.replace(\"/\", \"-\")\n",
    "dataset['classes'] = sorted([cat['id'] for cat in dataset['coco']['train'].coco.cats.values()])    \n",
    "dataset['config'].NAME = dataset['name']    \n",
    "dataset['config'].STEPS_PER_EPOCH = len(dataset['ids']['train']) // dataset['config'].BATCH_SIZE\n",
    "dataset['config'].NUM_CLASSES = len(dataset['classes'])\n",
    "dataset['config'].display()\n",
    "\n",
    "num_classes = dataset['config'].NUM_CLASSES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n5 -r1\n",
    "image, target = dataset['coco']['train'].sample()\n",
    "print(image.shape, target[0].shape, target[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in dataset['gens']['train']:\n",
    "    images, image_meta, rpn_match, rpn_bbox, gt_class_ids, gt_boxes, gt_masks = inputs\n",
    "    print(\"images.shape\", images.shape)\n",
    "    print(\"image_meta.shape\", image_meta.shape)\n",
    "    print(\"rpn_match.shape\", rpn_match.shape)\n",
    "    print(\"rpn_bbox.shape\", rpn_bbox.shape)\n",
    "    print(\"gt_class_ids.shape\", gt_class_ids.shape)\n",
    "    print(\"gt_boxes.shape\", gt_boxes.shape)\n",
    "    print(\"gt_masks.shape\", gt_masks.shape)\n",
    "    print(\"images min/max\", np.min(images), np.max(images))\n",
    "    break\n",
    "    \n",
    "plt.figure()\n",
    "num_rows = 2\n",
    "print(\"Left to right: ground truth samples from \", end='')\n",
    "for j in range(num_rows):\n",
    "    for i, name in enumerate(dataset['names']):\n",
    "        plt.subplot(num_rows, 3, 3 * j + i + 1)\n",
    "    #     print(data[0].shape, data[1], (np.min(data[0]), np.max(data[0])))\n",
    "        image, targets = dataset['coco'][name].sample()\n",
    "        if name == 'train':\n",
    "            image = aug_config.augment_image(image)\n",
    "        print(image.dtype, image.shape)\n",
    "        plt.imshow((image))\n",
    "#         plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(label)]))\n",
    "        print(name, end=', ')\n",
    "        plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coco = dataset['coco']['train'].coco\n",
    "# for ann_id, ann in coco.anns.items():\n",
    "#     try:\n",
    "#         mask = coco.annToMask(ann)\n",
    "#     except:\n",
    "#         print(\"masking failed on\", ann_id)\n",
    "#     if ann.get('annotation_type', None) == 'magnetic_lasso':\n",
    "#         print(\"mag\", ann_id)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_class_weights:\n",
    "    for name, ds in dataset['coco'].items():\n",
    "        print(\"{:s} {:s} class stats {:s}\".format('=' * 8, name, '=' * 8))\n",
    "        y = [ann['category_id'] for ann in ds.coco.anns.values() if 'segmentation' in ann]\n",
    "        count = np.array(list(dict(sorted(Counter(y).items(), key=lambda x: x[0])).values()))\n",
    "        spread = {i: float(v.round(2)) for i, v in enumerate(count / np.sum(count))}\n",
    "        class_weights = compute_class_weight('balanced', dataset['classes'], y)\n",
    "        class_weights = {i: float(np.round(v, 3)) for i, v in enumerate(class_weights)}\n",
    "        dataset['class_weights'][name] = class_weights\n",
    "        a = np.array(list(dataset['class_weights'][name].values()))\n",
    "        \n",
    "        print(\"class weights:\".format(name))\n",
    "        print(\" \", class_weights)\n",
    "        print(\"class cover fractions:\\n  \", spread )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(object):\n",
    "    def __init__(self, config, model_dir):\n",
    "        self.epoch = 0\n",
    "        self.model = None\n",
    "        self.config = config\n",
    "        self.model_dir = model_dir\n",
    "        self.compiled = False\n",
    "    \n",
    "    def create(self, model_path=None, train=False, fresh_heads=False, gpu_count=1):\n",
    "        if not model_path:\n",
    "            model_path = '/data/models/mask_rcnn_coco.h5'\n",
    "            \n",
    "        if not train:\n",
    "            self.config.IMAGES_PER_GPU = 1\n",
    "            self.config.BATCH_SIZE = 1\n",
    "        self.model = None\n",
    "        K.clear_session()\n",
    "        self.config.GPU_COUNT = gpu_count\n",
    "        self.model = MaskRCNN(\n",
    "            mode=(\"training\" if train else \"inference\"),\n",
    "            config=self.config, model_dir=self.model_dir)\n",
    "        if model_path: \n",
    "            exclude = [\n",
    "                \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                \"mrcnn_bbox\", \"mrcnn_mask\"] if fresh_heads else []\n",
    "            self.model.load_weights(model_path, by_name=True, exclude=exclude)\n",
    "    \n",
    "    def train(self, learning_rate, epochs, layers, **kwargs):\n",
    "        return self.model.train(\n",
    "            dataset['coco']['train'], dataset['coco']['val'], \n",
    "            learning_rate, epochs, layers,\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train MRCNN heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = None # None for COCO pretrained weights\n",
    "logdir = os.path.join(\"/data/log/maskrcnn/{:s}\".format(dataset['name']))\n",
    "!mkdir -p \"$logdir\"\n",
    "best_path = os.path.join(logdir, \"models/best.{epoch:03d}-{val_loss:.4f}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dataset['config']\n",
    "config.USE_MINI_MASK = True\n",
    "config.WEIGHT_DECAY = 1e-4\n",
    "config.VALIDATION_STEPS = len(dataset['ids']['val']) // config.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = None\n",
    "exp = Experiment(dataset['config'], logdir)\n",
    "model = exp.create(model_path=model_path, train=True, fresh_heads=True, gpu_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.train(\n",
    "    2.5e-3, 50, 'heads',\n",
    "    custom_callbacks=[EarlyStopping(patience=2, min_delta=0.05, verbose=1)],\n",
    "    augmentation=aug_config,\n",
    "    no_augmentation_sources=None)\n",
    "exp.model.keras_model.save_weights(os.path.join(logdir, 'heads.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = os.path.join(logdir, 'heads.h5')\n",
    "\n",
    "exp = None\n",
    "exp = Experiment(dataset['config'], logdir)\n",
    "model = exp.create(model_path=saved_model_path, train=True, fresh_heads=False)\n",
    "\n",
    "if exp.model.epoch == 0:\n",
    "    exp.model.epoch = 12\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=3, cooldown=10, verbose=1),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0.0, patience=20, verbose=1, mode='auto')\n",
    "]\n",
    "try:\n",
    "    lr = K.get_value(exp.model.keras_model.optimizer.lr)\n",
    "except AttributeError:\n",
    "    lr = 1e-4\n",
    "\n",
    "\n",
    "exp.train(\n",
    "    lr, 200, 'all',\n",
    "    augmentation=aug_config,\n",
    "    custom_callbacks=callbacks,\n",
    "    no_augmentation_sources=None)\n",
    "exp.model.keras_model.save_weights(os.path.join(logdir, 'final.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = None\n",
    "config.USE_MINI_MASK = False\n",
    "config.IMAGES_PER_GPU = 1\n",
    "exp = Experiment(dataset['config'], logdir)\n",
    "model = exp.create(model_path=os.path.join(logdir, 'final2.h5'), train=False, fresh_heads=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.utils import expand_mask\n",
    "from mrcnn.visualize import display_images, display_instances\n",
    "from abyss_deep_learning.keras.segmentation import jaccard_index\n",
    "\n",
    "def plot_test(gen, model, num_images=1, show=False):\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    ious_list = []\n",
    "    i = 0\n",
    "    for ((images, image_meta, rpn_match, rpn_bbox, gt_class_ids, gt_boxes, gt_masks), targets) in gen:\n",
    "        image = images[0]\n",
    "        valid = np.all(gt_boxes[0], axis=1)\n",
    "        class_ids = gt_class_ids[0, valid]\n",
    "        masks = gt_masks[0, ..., valid].transpose((1, 2, 0))\n",
    "        boxes = gt_boxes[0, valid, ...]\n",
    "        \n",
    "        labels = expand_mask(boxes, masks, image.shape).astype(np.uint8)\n",
    "        r = model.detect([image], verbose=True)[0]\n",
    "        num_pred = len(r['class_ids'])\n",
    "        num_gt = len(class_ids)\n",
    "        print(\"GTs = {:d}, Pred = {:d}\".format(num_gt, num_pred))\n",
    "        \n",
    "        ious = np.array([[\n",
    "            jaccard_index(r['masks'][..., i] , labels[..., j]) \n",
    "                for j in range(labels.shape[-1])] \n",
    "                for i in range(r['masks'].shape[-1])])\n",
    "        pred_idx, gt_idx = linear_sum_assignment(1-ious)\n",
    "        r['ious'] = np.array([ious[pred_idx[i], gt_idx[i]] \n",
    "                              if (i in pred_idx and i in gt_idx) else 0.0 for i in range(num_pred)])\n",
    "        print(\"IoUs\", r['ious'])\n",
    "        print(\"Scores\", r['scores'])\n",
    "        ious_list.append(ious)\n",
    "        class_names = ['BG'] + [cat['name'] for cat in dataset['coco']['train'].coco.cats.values()]\n",
    "        if show:\n",
    "            plt.figure()\n",
    "            ax = plt.subplot(1, 2, 1)\n",
    "            display_instances(\n",
    "                image + dataset['config'].MEAN_PIXEL,\n",
    "                boxes,\n",
    "                masks,\n",
    "                class_ids,\n",
    "                class_names, ax=ax)\n",
    "            ax = plt.subplot(1, 2, 2, sharex=ax, sharey=ax)\n",
    "            display_instances(\n",
    "                image + dataset['config'].MEAN_PIXEL,\n",
    "                r['rois'],\n",
    "                r['masks'],\n",
    "                r['class_ids'],\n",
    "                class_names, ax=ax)\n",
    "            \n",
    "#         imsave(\"/tmp/maskrcnn/image.png\", (image + config.MEAN_PIXEL).astype(np.uint8))\n",
    "        i += 1    \n",
    "        if i >= num_images:\n",
    "                break\n",
    "    return ious_list\n",
    "\n",
    "ious = plot_test(dataset['gens']['test'], exp.model, num_images=1, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcnn.visualize as viz\n",
    "# evaluate_coco(model, dataset_val, coco_val, eval_type=\"segm\", limit=0, image_ids=None)\n",
    "viz.display_weight_stats(exp.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = dataset['coco']['val']\n",
    "image = coco.load_image(1)\n",
    "exp\n",
    "# Get activations of a few sample layers\n",
    "activations = exp.model.run_graph([image], [\n",
    "#     (\"input_image\",        exp.model.keras_model.get_layer(\"input_image\").output),\n",
    "    (\"res2c_out\",          exp.model.keras_model.get_layer(\"res2c_out\").output),\n",
    "    (\"res3c_out\",          exp.model.keras_model.get_layer(\"res3c_out\").output),\n",
    "    (\"res4c_out\",          exp.model.keras_model.get_layer(\"res4c_out\").output),\n",
    "    (\"res5c_out\",          exp.model.keras_model.get_layer(\"res5c_out\").output),\n",
    "    (\"rpn_bbox\",           exp.model.keras_model.get_layer(\"rpn_bbox\").output),\n",
    "    (\"roi\",                exp.model.keras_model.get_layer(\"ROI\").output),\n",
    "])\n",
    "\n",
    "plt.figure()\n",
    "layer_names = [\"res2c_out\", \"res3c_out\", \"res4c_out\", \"res5c_out\"]\n",
    "ax = None\n",
    "for i, layer in enumerate(layer_names):\n",
    "    ax = plt.subplot(len(layer_names) // 2, 2, i + 1)\n",
    "    plt.imshow(activations[layer].sum(axis=3)[0])\n",
    "    plt.title(layer)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Backbone feature map\n",
    "# display_images(np.transpose(activations[\"res2c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n",
    "# display_images(np.transpose(activations[\"res3c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n",
    "# display_images(np.transpose(activations[\"res4c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n",
    "# display_images(np.transpose(activations[\"res5c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
