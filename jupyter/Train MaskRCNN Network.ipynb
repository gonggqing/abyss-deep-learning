{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import concurrent.futures\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from skimage.color import label2rgb\n",
    "from keras import Model\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from pycocotools.coco import COCO\n",
    "from collections import Counter\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from abyss_deep_learning.keras.detection import MaskRcnnDataset\n",
    "from abyss_deep_learning.utils import ann_to_mask\n",
    "from mrcnn.model import MaskRCNN, data_generator\n",
    "from mrcnn.utils import Dataset as DatasetBase\n",
    "\n",
    "\n",
    "from skimage.morphology import remove_small_holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path, num_classes):\n",
    "    assert num_classes or dataset_train\n",
    "    spec = importlib.util.spec_from_file_location(\n",
    "        \"maskrcnn_config\", path)\n",
    "    config_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(config_module)\n",
    "    config = config_module.Config()\n",
    "    config.NUM_CLASSES = num_classes\n",
    "    input_shape = config.IMAGE_SHAPE\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = None\n",
    "categories = None\n",
    "num_classes = 2\n",
    "use_balanced_set = False\n",
    "use_class_weights = True\n",
    "config_file = \"/home/docker/src/abyss/deep-learning/configs/MaskRCNN_default_config.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dir = \"/data/acfr/collated/2017-summer-lettuce\"\n",
    "dataset_name = \"20170329T000000\"\n",
    "dataset_files = {\n",
    "    'train': os.path.join(database_dir, \"{:s}/train.json\".format(dataset_name)),\n",
    "    'val': os.path.join(database_dir, \"{:s}/val.json\".format(dataset_name)),\n",
    "    'test': os.path.join(database_dir, \"{:s}/test.json\".format(dataset_name))\n",
    "}\n",
    "dataset = {\n",
    "    'names': list(dataset_files.keys()),\n",
    "    'classes': [], # MUST FILL IN\n",
    "    'class_weights': {name: None for name in dataset_files.keys()},\n",
    "    'ids' : {},\n",
    "    'gens': {},\n",
    "    'data': {},\n",
    "    'coco': {},\n",
    "    'config': load_config(config_file, num_classes=num_classes)\n",
    "}\n",
    "dataset['config'].NUM_CLASSES = num_classes\n",
    "dataset['name'] = dataset_name.replace(\"/\", \"-\")\n",
    "dataset['config'].NAME = dataset['name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(MaskRcnnDataset(dataset_files['train']).coco.cats) + 1\n",
    "\n",
    "for name, path in dataset_files.items():\n",
    "    coco = MaskRcnnDataset(path)\n",
    "    \n",
    "    ids = coco.image_ids\n",
    "    gen = data_generator(coco, dataset['config'], shuffle=True, augmentation=None, detection_targets=False)\n",
    "    print(\"{:s}: {:d} images\".format(name, len(ids)))\n",
    "    dataset['coco'][name] = coco\n",
    "    dataset['ids'][name] = ids\n",
    "    dataset['gens'][name] = gen\n",
    "    \n",
    "dataset['config'].STEPS_PER_EPOCH = len(dataset['ids']['train']) // dataset['config'].BATCH_SIZE\n",
    "dataset['classes'] = sorted([cat['id'] for cat in dataset['coco']['train'].coco.cats.values()])\n",
    "dataset['config'].display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n5 -r1\n",
    "image, target = dataset['coco']['train'].sample()\n",
    "print(image.shape, target[0].shape, target[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in dataset['gens']['train']:\n",
    "    images, image_meta, rpn_match, rpn_bbox, gt_class_ids, gt_boxes, gt_masks = inputs\n",
    "    print(\"images.shape\", images.shape)\n",
    "    print(\"image_meta.shape\", image_meta.shape)\n",
    "    print(\"rpn_match.shape\", rpn_match.shape)\n",
    "    print(\"rpn_bbox.shape\", rpn_bbox.shape)\n",
    "    print(\"gt_class_ids.shape\", gt_class_ids.shape)\n",
    "    print(\"gt_boxes.shape\", gt_boxes.shape)\n",
    "    print(\"gt_masks.shape\", gt_masks.shape)\n",
    "    print(\"images min/max\", np.min(images), np.max(images))\n",
    "    break\n",
    "    \n",
    "plt.figure()\n",
    "num_rows = 3\n",
    "print(\"Left to right: ground truth samples from \", end='')\n",
    "for j in range(num_rows):\n",
    "    for i, name in enumerate(dataset['names']):\n",
    "        plt.subplot(num_rows, 3, 3 * j + i + 1)\n",
    "    #     print(data[0].shape, data[1], (np.min(data[0]), np.max(data[0])))\n",
    "        image, targets = dataset['coco'][name].sample()\n",
    "        print(image.dtype, image.shape)\n",
    "        plt.imshow((image))\n",
    "#         plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(label)]))\n",
    "        print(name, end=', ')\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "# def display_instances(images, masks, boxes, class_ids):\n",
    "#     valid = np.all(boxes, axis=1)\n",
    "#     class_ids = class_ids[valid]\n",
    "#     masks = masks[..., valid]#.transpose((2, 0, 1))\n",
    "#     boxes = boxes[valid, ...]\n",
    "#     print(\"masks.shape\", masks.shape)\n",
    "# #     for i, class_id in enumerate(class_ids):\n",
    "# #         masks[..., i] *= class_id\n",
    "#     print(boxes.shape, masks.shape, images.shape, class_ids.shape)\n",
    "    \n",
    "#     labels = expand_mask(boxes, masks, images.shape).astype(np.uint8)\n",
    "#     labels = np.any(labels, axis=2)\n",
    "# #         labels *= np.arange(1, labels.shape[-1] + 1).astype(np.uint8)\n",
    "# #         print(labels)\n",
    "#     labels = resize(labels, images.shape[0:2], order=0)\n",
    "#     return label2rgb(labels, images.astype(np.uint8), bg_label=0)\n",
    "\n",
    "# def display_instances_gen(gen, add_mean=None):\n",
    "#     ''''batching == 1 support ONLY'''\n",
    "#     for ((images, image_meta, rpn_match, rpn_bbox, gt_class_ids, gt_boxes, gt_masks), targets) in gen:\n",
    "#         image = images[0] + add_mean if add_mean is not None else images[0]\n",
    "#         yield (display_instances(image, gt_masks[0], gt_boxes[0], gt_class_ids[0]),)\n",
    "\n",
    "# displays = [\n",
    "#     display[0] for display in \n",
    "#         head_gen(\n",
    "#             display_instances_gen(\n",
    "#                 data_generator(dataset_train, config)\n",
    "#             , add_mean=config.MEAN_PIXEL),\n",
    "#         first=4)]\n",
    "# plt.figure()\n",
    "# vis_square(np.array(displays))\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_class_weights:\n",
    "    for name, ds in dataset['coco'].items():\n",
    "        print(\"{:s} {:s} class stats {:s}\".format('=' * 8, name, '=' * 8))\n",
    "        y = [ann['category_id'] for ann in ds.coco.anns.values() if 'segmentation' in ann]\n",
    "        count = np.array(list(dict(sorted(Counter(y).items(), key=lambda x: x[0])).values()))\n",
    "        spread = {i: float(v.round(2)) for i, v in enumerate(count / np.sum(count))}\n",
    "        class_weights = compute_class_weight('balanced', dataset['classes'], y)\n",
    "        class_weights = {i: float(np.round(v, 3)) for i, v in enumerate(class_weights)}\n",
    "        dataset['class_weights'][name] = class_weights\n",
    "        a = np.array(list(dataset['class_weights'][name].values()))\n",
    "        \n",
    "        print(\"class weights:\".format(name))\n",
    "        print(\" \", class_weights)\n",
    "        print(\"class cover fractions:\\n  \", spread )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(object):\n",
    "    def __init__(self, config, model_dir):\n",
    "        self.epoch = 0\n",
    "        self.model = None\n",
    "        self.config = config\n",
    "        self.model_dir = model_dir\n",
    "        self.compiled = False\n",
    "    \n",
    "    def create(self, model_path=None, train=False, fresh_heads=False):\n",
    "        if not model_path:\n",
    "            model_path = '/data/models/mask_rcnn_coco.h5'\n",
    "            \n",
    "        if not train:\n",
    "            self.config.IMAGES_PER_GPU = 1\n",
    "            self.config.BATCH_SIZE = 1\n",
    "        self.model = None\n",
    "        K.clear_session()\n",
    "        \n",
    "        self.model = MaskRCNN(\n",
    "            mode=(\"training\" if train else \"inference\"),\n",
    "            config=self.config, model_dir=self.model_dir)\n",
    "        if model_path: \n",
    "            exclude = [\n",
    "                \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                \"mrcnn_bbox\", \"mrcnn_mask\"] if fresh_heads else []\n",
    "            self.model.load_weights(model_path, by_name=True, exclude=exclude)\n",
    "    \n",
    "    def train(self, learning_rate, epochs, layers, **kwargs):\n",
    "        return self.model.train(\n",
    "            dataset['coco']['train'], dataset['coco']['val'], \n",
    "            learning_rate, epochs, layers,\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train MRCNN heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = None # None for COCO pretrained weights\n",
    "logdir = os.path.join(\"/data/log/maskrcnn/{:s}\".format(dataset['name']))\n",
    "!mkdir -p \"$logdir/models\"\n",
    "best_path = os.path.join(logdir, \"models/best.{epoch:03d}-{val_loss:.4f}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(dataset['config'], logdir)\n",
    "model = exp.create(model_path=model_path, train=True, fresh_heads=True)\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=5, verbose=1),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0.0, patience=10, verbose=1, mode='auto')\n",
    "]\n",
    "\n",
    "exp.train(\n",
    "    1e-3, 100, 'heads',\n",
    "    augmentation=None,\n",
    "    custom_callbacks=callbacks,\n",
    "    no_augmentation_sources=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = 'FILL_THIS_IN/mask_rcnn_20170329t000000_0040.h5'\n",
    "\n",
    "exp = Experiment(dataset['config'], logdir)\n",
    "model = exp.create(model_path=saved_model_path, train=True, fresh_heads=True)\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, cooldown=10, verbose=1),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0.0, patience=20, verbose=1, mode='auto')\n",
    "]\n",
    "\n",
    "exp.train(\n",
    "    1e-4, 200, '3+',\n",
    "    augmentation=None,\n",
    "    custom_callbacks=callbacks,\n",
    "    no_augmentation_sources=None)\n",
    "exp.model.keras_model.save_weights(os.path.join(logdir, 'final.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp\n",
    "exp = Experiment(dataset['config'], logdir)\n",
    "model = exp.create(model_path=os.path.join(logdir, 'final.h5'), train=False, fresh_heads=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO BELOW UNFINISHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.utils import expand_mask\n",
    "from mrcnn.visualize import display_images, display_instances\n",
    "from abyss_deep_learning.keras.segmentation import jaccard_index\n",
    "\n",
    "def plot_test(gen, model, num_images=1, show=False):\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    ious_list = []\n",
    "    i = 0\n",
    "    for ((images, image_meta, rpn_match, rpn_bbox, gt_class_ids, gt_boxes, gt_masks), targets) in gen:\n",
    "        image = images[0]\n",
    "        valid = np.all(gt_boxes[0], axis=1)\n",
    "        class_ids = gt_class_ids[0, valid]\n",
    "        masks = gt_masks[0, ..., valid].transpose((1, 2, 0))\n",
    "        boxes = gt_boxes[0, valid, ...]\n",
    "        \n",
    "        labels = expand_mask(boxes, masks, image.shape).astype(np.uint8)\n",
    "        r = model.detect([image], verbose=True)[0]\n",
    "        num_pred = len(r['class_ids'])\n",
    "        num_gt = len(class_ids)\n",
    "        print(\"GTs = {:d}, Pred = {:d}\".format(num_gt, num_pred))\n",
    "        \n",
    "        ious = np.array([[\n",
    "            jaccard_index(r['masks'][..., i] , labels[..., j]) \n",
    "                for j in range(labels.shape[-1])] \n",
    "                for i in range(r['masks'].shape[-1])])\n",
    "        pred_idx, gt_idx = linear_sum_assignment(1-ious)\n",
    "        r['ious'] = np.array([ious[pred_idx[i], gt_idx[i]] \n",
    "                              if (i in pred_idx and i in gt_idx) else 0.0 for i in range(num_pred)])\n",
    "        print(\"IoUs\", r['ious'])\n",
    "        print(\"Scores\", r['scores'])\n",
    "        ious_list.append(ious)\n",
    "        class_names = ['BG'] + [cat['name'] for cat in dataset['coco']['train'].coco.cats.values()]\n",
    "        if show:\n",
    "            plt.figure()\n",
    "            ax = plt.subplot(1, 2, 1)\n",
    "            display_instances(\n",
    "                image + dataset['config'].MEAN_PIXEL,\n",
    "                boxes,\n",
    "                masks,\n",
    "                class_ids,\n",
    "                class_names, ax=ax)\n",
    "#             display_predictions(\n",
    "#                 image + config.MEAN_PIXEL, boxes, labels, class_ids, dataset_train.class_names, ax=ax)\n",
    "#             ax = plt.subplot(1, 2, 2, sharex=ax, sharey=ax)\n",
    "#             display_predictions(\n",
    "#                 image + config.MEAN_PIXEL, r['rois'], r['masks'], r['class_ids'],\n",
    "#                 dataset_train.class_names,  r['scores'], ax=ax)\n",
    "#             plt.tight_layout()\n",
    "#         imsave(\"/tmp/maskrcnn/image.png\", (image + config.MEAN_PIXEL).astype(np.uint8))\n",
    "        i += 1    \n",
    "        if i >= num_images:\n",
    "                break\n",
    "    return ious_list\n",
    "\n",
    "ious = plot_test(dataset['gens']['test'], exp.model, num_images=1, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_coco(model, dataset_val, coco_val, eval_type=\"segm\", limit=0, image_ids=None)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
