{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from mrcnn.model import MaskRCNN\n",
    "from skimage.color import label2rgb\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "import imgaug.augmenters as iaa\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_args():\n",
    "    from keras.applications.resnet50 import preprocess_input\n",
    "    from bidict import bidict\n",
    "    from imgaug import augmenters as iaa\n",
    "    from imgaug.parameters import Normal, Discretize\n",
    "    from skimage.transform import resize\n",
    "    \n",
    "    def load_config(path):\n",
    "        spec = importlib.util.spec_from_file_location(\n",
    "            \"maskrcnn_config\", path)\n",
    "        config_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(config_module)\n",
    "        return config_module.Config()\n",
    "\n",
    "#     def preprocess_data(image):\n",
    "#         '''Transform the image before (possibly caching) and input to the network.'''\n",
    "#        # This is done automatically by MRCNN\n",
    "\n",
    "    def postprocess_data(image):\n",
    "        '''Inverse transform of preprocess_data, used when trying to visualize images out of the dataset.'''\n",
    "        return (image).astype(np.uint8)\n",
    "\n",
    "    def pipeline(gen, aug_config=None):\n",
    "        '''The pipeline to run the dataset generator through.'''\n",
    "        from abyss_deep_learning.keras.classification import onehot_gen, augmentation_gen\n",
    "\n",
    "        return gen \n",
    "#                 (\n",
    "#             augmentation_gen(\n",
    "#                 onehot_gen(gen, num_classes=args['num_classes'])\n",
    "#             , aug_config, enable=(aug_config is not None))\n",
    "#         )\n",
    "\n",
    "    augmentation_config = iaa.Sequential([ \n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.Affine(\n",
    "            scale=(0.8, 1.2),\n",
    "            translate_percent=(-0.2, 0.2), \n",
    "            rotate=(-22.5, 22.5),\n",
    "            mode='constant', cval=0, order=0\n",
    "        ),\n",
    "        \n",
    "#         iaa.Sequential([ # Colour aug\n",
    "#             iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "#             iaa.WithChannels(0, iaa.Add(Discretize(Normal(0, 256 / 10)))),\n",
    "#             iaa.WithChannels(1, iaa.Add(Discretize(Normal(0, 256 / 5)))),\n",
    "#             iaa.WithChannels(2, iaa.Add(Discretize(Normal(0, 256 / 5)))),\n",
    "#             iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\")\n",
    "#         ])\n",
    "    ])\n",
    "\n",
    "    args = {\n",
    "        'augmentation': augmentation_config,    # Training augmentation\n",
    "#         'caption_map': caption_map,             # Captio\n",
    "        'data': {\n",
    "            'base_dir': \"/data/abyss/oceaneering/annotations\",\n",
    "            'name': \"separation\",\n",
    "            'sets': ('train', 'val')\n",
    "        },\n",
    "        'config': load_config('/home/docker/src/abyss/deep-learning/configs/oceaneering2.py'),\n",
    "        'image_dims': (512, 512, 3),    # What to resize images to before CNN\n",
    "        'nn_dtype': np.float32,         # Pretrained networks are in float32\n",
    "        'num_classes': None,            # Calculate later\n",
    "#         'use_balanced_set': False,      # Force the use of the largest class-balanced dataset\n",
    "#         'use_cached': False,            # Cache the dataset in memory\n",
    "#         'use_class_weights': True,      # Use class population to weight in the training loss\n",
    "#         'use_parallel': False,          # Use multiple GPUs\n",
    "#         'preprocess_data': preprocess_data,\n",
    "        'postprocess_data': postprocess_data,\n",
    "        'pipeline': pipeline\n",
    "    }\n",
    "    args['num_classes'] = args['config'].NUM_CLASSES\n",
    "    \n",
    "    return args\n",
    "ARGS = setup_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_datasets(args):\n",
    "    from abyss_deep_learning.datasets.coco import MaskRcnnInstSegDataset\n",
    "    \n",
    "    dataset = dict()\n",
    "    for set_name in args['data']['sets']:\n",
    "        path = os.path.join(args['data']['base_dir'], \"{:s}/{:s}.json\".format(args['data']['name'], set_name))\n",
    "        dataset[set_name] = MaskRcnnInstSegDataset(\n",
    "            path, ARGS['config'])\n",
    "        print(\"\\n\", set_name)\n",
    "#         dataset[set_name].print_class_stats()\n",
    "\n",
    "    print(\"\\nNumber of classes:\", args['num_classes'])\n",
    "    cats = dataset['train'].coco.loadCats(dataset['train'].coco.getCatIds())\n",
    "    class_names = [\"BG\"] + [\n",
    "        cat['name'] for cat in sorted(cats, key=lambda x: x['id'])]\n",
    "    print(class_names)\n",
    "    return dataset, class_names\n",
    "\n",
    "DATASET, ARGS['class_names'] = setup_datasets(ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_from_inputs(inputs, **kwargs):\n",
    "    from mrcnn.visualize import display_instances\n",
    "    from mrcnn.utils import unmold_mask\n",
    "    print(inputs[4].shape)\n",
    "    N = np.argwhere(inputs[4][0] == 0)[0][0]\n",
    "    image, image_meta = inputs[0][0], inputs[1][0]\n",
    "    rpn_match, rpn_bbox = inputs[2][0], inputs[3][0]\n",
    "    gt_class_ids, gt_boxes, gt_masks = inputs[4][0, :N], inputs[5][0, :N], inputs[6][0, ..., :N]\n",
    "\n",
    "    masks = np.array([\n",
    "        unmold_mask(gt_masks[..., idx], gt_boxes[idx], image.shape)\n",
    "        for idx in range(N)]).transpose([1, 2, 0])\n",
    "\n",
    "    display_instances(\n",
    "        ARGS['postprocess_data'](image), gt_boxes, masks, gt_class_ids, ARGS['class_names'], **kwargs)\n",
    "        \n",
    "def view_dataset_samples(num_rows=2):\n",
    "    plt.figure()\n",
    "    print(\"Column-wise left to right, bottom row:\")\n",
    "    for i, (name, ds) in enumerate(DATASET.items()):\n",
    "        print(name, end=' ')\n",
    "        for j, (inputs, targets) in enumerate(ARGS['pipeline'](\n",
    "            ds.mrcnn_generator(shuffle=True, augmentation=ARGS['augmentation']))):\n",
    "            ax = plt.subplot(num_rows, 3, 3 * j + i + 1)\n",
    "            print({\n",
    "                k: (kk.dtype, kk.shape)\n",
    "                for k, kk in enumerate(inputs)\n",
    "            })\n",
    "            display_from_inputs(inputs, ax=ax)\n",
    "#             plt.title(', '.join([ARGS['caption_map'].inv[int(cap_id)] for cap_id in np.argwhere(label)]))\n",
    "            plt.axis('off')\n",
    "            if j + 1 == num_rows:\n",
    "                break\n",
    "\n",
    "view_dataset_samples(num_rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(object):\n",
    "    def __init__(self, config, model_dir):\n",
    "        self.epoch = 0\n",
    "        self.model = None\n",
    "        self.config = config\n",
    "        self.model_dir = model_dir\n",
    "        self.compiled = False\n",
    "    \n",
    "    def create(self, model_path=None, train=False, fresh_heads=False, gpu_count=1):\n",
    "        if model_path is None:\n",
    "            model_path = '/data/models/mask_rcnn_coco.h5'\n",
    "        elif model_path is False:\n",
    "            model_path = None\n",
    "#         if not train:\n",
    "        self.config.IMAGES_PER_GPU = 1\n",
    "        self.config.BATCH_SIZE = 1\n",
    "        self.model = None\n",
    "        K.clear_session()\n",
    "        self.config.GPU_COUNT = gpu_count\n",
    "        self.model = MaskRCNN(\n",
    "            mode=(\"training\" if train else \"inference\"),\n",
    "            config=self.config, model_dir=self.model_dir)\n",
    "        if model_path: \n",
    "            exclude = [\n",
    "                \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                \"mrcnn_bbox\", \"mrcnn_mask\"] if fresh_heads else []\n",
    "            self.model.load_weights(model_path, by_name=True, exclude=exclude)\n",
    "    \n",
    "    def train(self, learning_rate, epochs, layers, **kwargs):\n",
    "        return self.model.train(\n",
    "            DATASET['train'], DATASET['val'], \n",
    "            learning_rate, epochs, layers,\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train MRCNN heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = False # None for COCO pretrained weights, False for empty\n",
    "logdir = os.path.join(\"/data/log/maskrcnn/broccoli-allages/{:s}\".format(ARGS['data']['name']))\n",
    "!mkdir -p \"$logdir\"\n",
    "best_path = os.path.join(logdir, \"models/best.{epoch:03d}-{val_loss:.4f}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ARGS['config']\n",
    "# config.USE_MINI_MASK = True\n",
    "# config.BATCH_SIZE = 1\n",
    "# config.IMAGES_PER_GPU = 1\n",
    "# config.WEIGHT_DECAY = 1e-4\n",
    "# config.VALIDATION_STEPS = len(DATASET['val'].data_ids) // config.BATCH_SIZE\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = None\n",
    "exp = Experiment(ARGS['config'], logdir)\n",
    "model = exp.create(model_path=model_path, train=True, fresh_heads=True, gpu_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_layers = 'heads'\n",
    "exp.train(\n",
    "    1e-6, 50, train_layers,\n",
    "    custom_callbacks=[EarlyStopping(patience=2, min_delta=0.05, verbose=1)],\n",
    "    augmentation=None,#ARGS['augmentation'],\n",
    "    no_augmentation_sources=None)\n",
    "exp.model.keras_model.save_weights(os.path.join(logdir, 'heads.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = os.path.join(logdir, 'heads.h5')\n",
    "\n",
    "exp = None\n",
    "exp = Experiment(ARGS['config'], logdir)\n",
    "model = exp.create(model_path=saved_model_path, train=True, fresh_heads=False)\n",
    "\n",
    "if exp.model.epoch == 0:\n",
    "    exp.model.epoch = 12\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=3, cooldown=10, verbose=1),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0.0, patience=20, verbose=1, mode='auto'),\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(logdir, \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"),\n",
    "        verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "# try:\n",
    "#     lr = K.get_value(exp.model.keras_model.optimizer.lr)\n",
    "# except AttributeError:\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "exp.train(\n",
    "    lr, 200, 'all',\n",
    "    augmentation=ARGS['augmentation'],\n",
    "    custom_callbacks=callbacks,\n",
    "    no_augmentation_sources=None)\n",
    "exp.model.keras_model.save_weights(os.path.join(logdir, 'final2.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = None\n",
    "config.USE_MINI_MASK = False\n",
    "config.IMAGES_PER_GPU = 1\n",
    "exp = Experiment(ARGS['config'], logdir)\n",
    "model = exp.create(model_path=os.path.join(logdir, 'final2.h5'), train=False, fresh_heads=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.utils import expand_mask\n",
    "from mrcnn.visualize import display_images, display_instances\n",
    "# from abyss_deep_learning.keras.segmentation import jaccard_index\n",
    "\n",
    "def plot_test(gen, model, num_images=1, show=False):\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    ious_list = []\n",
    "    i = 0\n",
    "    for ((images, image_meta, rpn_match, rpn_bbox, gt_class_ids, gt_boxes, gt_masks), targets) in gen:\n",
    "        image = images[0]\n",
    "        valid = np.all(gt_boxes[0], axis=1)\n",
    "        class_ids = gt_class_ids[0, valid]\n",
    "        masks = gt_masks[0, ..., valid].transpose((1, 2, 0))\n",
    "        boxes = gt_boxes[0, valid, ...]\n",
    "        \n",
    "        labels = expand_mask(boxes, masks, image.shape).astype(np.uint8)\n",
    "        r = model.detect([image], verbose=True)[0]\n",
    "        num_pred = len(r['class_ids'])\n",
    "        \n",
    "        num_gt = len(class_ids)\n",
    "        print(\"GTs = {:d}, Pred = {:d}\".format(num_gt, num_pred))\n",
    "        ious = np.array([[\n",
    "            1 #jaccard_index(r['masks'][..., i] , labels[..., j]) \n",
    "                for j in range(labels.shape[-1])] \n",
    "                for i in range(r['masks'].shape[-1])])\n",
    "        pred_idx, gt_idx = linear_sum_assignment(1-ious)\n",
    "        r['ious'] = np.array([ious[pred_idx[i], gt_idx[i]] \n",
    "                              if (i in pred_idx and i in gt_idx) else 0.0 for i in range(num_pred)])\n",
    "        print(\"IoUs\", r['ious'])\n",
    "        print(\"Scores\", r['scores'])\n",
    "        ious_list.append(ious)\n",
    "        class_names = ['BG'] + [cat['name'] for cat in DATASET['train'].coco.cats.values()]\n",
    "        if show:\n",
    "            plt.figure()\n",
    "            ax = plt.subplot(1, 2, 1)\n",
    "            display_instances(\n",
    "                image + ARGS['config'].MEAN_PIXEL,\n",
    "                boxes,\n",
    "                masks,\n",
    "                class_ids,\n",
    "                class_names, ax=ax)\n",
    "            ax = plt.subplot(1, 2, 2, sharex=ax, sharey=ax)\n",
    "            display_instances(\n",
    "                image + ARGS['config'].MEAN_PIXEL,\n",
    "                r['rois'],\n",
    "                r['masks'],\n",
    "                r['class_ids'],\n",
    "                class_names, ax=ax)\n",
    "            \n",
    "#         imsave(\"/tmp/maskrcnn/image.png\", (image + config.MEAN_PIXEL).astype(np.uint8))\n",
    "        i += 1    \n",
    "        if i >= num_images:\n",
    "                break\n",
    "    return ious_list\n",
    "\n",
    "ious = plot_test(\n",
    "    DATASET['val'].mrcnn_generator(shuffle=True),\n",
    "    exp.model, num_images=1, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcnn.visualize as viz\n",
    "# evaluate_coco(model, dataset_val, coco_val, eval_type=\"segm\", limit=0, image_ids=None)\n",
    "viz.display_weight_stats(exp.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = DATASET['val']\n",
    "image = coco.load_image(1)\n",
    "exp\n",
    "# Get activations of a few sample layers\n",
    "activations = exp.model.run_graph([image], [\n",
    "#     (\"input_image\",        exp.model.keras_model.get_layer(\"input_image\").output),\n",
    "    (\"res2c_out\",          exp.model.keras_model.get_layer(\"res2c_out\").output),\n",
    "    (\"res3c_out\",          exp.model.keras_model.get_layer(\"res3c_out\").output),\n",
    "    (\"res4c_out\",          exp.model.keras_model.get_layer(\"res4c_out\").output),\n",
    "    (\"res5c_out\",          exp.model.keras_model.get_layer(\"res5c_out\").output),\n",
    "    (\"rpn_bbox\",           exp.model.keras_model.get_layer(\"rpn_bbox\").output),\n",
    "    (\"roi\",                exp.model.keras_model.get_layer(\"ROI\").output),\n",
    "])\n",
    "\n",
    "plt.figure()\n",
    "layer_names = [\"res2c_out\", \"res3c_out\", \"res4c_out\", \"res5c_out\"]\n",
    "ax = None\n",
    "for i, layer in enumerate(layer_names):\n",
    "    ax = plt.subplot(len(layer_names) // 2, 2, i + 1)\n",
    "    plt.imshow(activations[layer].sum(axis=3)[0])\n",
    "    plt.title(layer)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Backbone feature map\n",
    "# display_images(np.transpose(activations[\"res2c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n",
    "# display_images(np.transpose(activations[\"res3c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n",
    "# display_images(np.transpose(activations[\"res4c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n",
    "# display_images(np.transpose(activations[\"res5c_out\"][0,:,:,:4], [2, 0, 1]), cols=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
