{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from pycocotools.coco import COCO\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "from abyss_deep_learning.keras.classification import ClassificationDataset, caption_map_gen, onehot_gen, augmentation_gen\n",
    "from abyss_deep_learning.keras.utils import batching_gen, lambda_gen\n",
    "import abyss_deep_learning.abyss_dataset as dataset_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### CONFIGURE THIS ########################\n",
    "# num_classes assumed from caption_map entries\n",
    "image_dims = (299, 299, 3) # Preset for InceptionV3\n",
    "batch_size = 5\n",
    "log_dir = \"/data/log/cnn/cso\"\n",
    "\n",
    "# maps caption strings to class numbers (ensure minimal set of class numbers)\n",
    "# eg use {0, 1, 2} not {4, 7, 8}\n",
    "\n",
    "# Caption type can be either \"single\" or \"multi\".\n",
    "# This sets up various parameters in the system.\n",
    "# If conversion between single and multi is required this should be done explicitly and presented\n",
    "# in a separate json file. The internal representation of all the labels is one-hot encoding.\n",
    "caption_type = \"single\" \n",
    "caption_map = {\n",
    "    'f': 1,\n",
    "    's': 0\n",
    "}\n",
    "coco_train = ClassificationDataset(caption_map, \"/data/abyss/projectmax/cso/dataset_train.json\")\n",
    "coco_val = ClassificationDataset(caption_map, \"/data/abyss/projectmax/cso/dataset_val.json\")\n",
    "coco_test = ClassificationDataset(caption_map, \"/data/abyss/projectmax/cso/dataset_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_map_r = {val: key for key, val in caption_map.items()}\n",
    "num_classes = len(caption_map)\n",
    "steps_per_epoch = coco_train.num_images() // batch_size\n",
    "steps_per_epoch_val = coco_val.num_images() // batch_size\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Steps per epoch:\", steps_per_epoch)\n",
    "print(\"Steps per steps_per_epoch_val:\", steps_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, caption):\n",
    "    image = resize(image, image_dims, preserve_range=True)\n",
    "    return preprocess_input(image.astype(np.float32)), caption\n",
    "\n",
    "def postprocess(image):\n",
    "    return ((image + 1) * 127).astype(np.uint8)\n",
    "\n",
    "def pipeline(gen, aug_config=None):\n",
    "    return (\n",
    "        augmentation_gen(\n",
    "            onehot_gen(\n",
    "                lambda_gen(\n",
    "                    caption_map_gen(gen, caption_map)\n",
    "                , func=preprocess)\n",
    "            , num_classes=num_classes)\n",
    "        , aug_config, enable=(aug_config is not None))\n",
    "    )\n",
    "\n",
    "def augmentation_gen(gen, aug_config, enable=True):\n",
    "    '''\n",
    "    Data augmentation for classification task.\n",
    "    Target is untouched.\n",
    "    '''\n",
    "    if not enable:\n",
    "        while True:\n",
    "            yield from gen\n",
    "    aug_list = []\n",
    "    if 'flip_lr_percentage' in aug_config:\n",
    "        aug_list += [iaa.Fliplr(aug_config['flip_lr_percentage'])]\n",
    "    if 'flip_ud_percentage' in aug_config:\n",
    "        aug_list += [iaa.Flipud(aug_config['flip_ud_percentage'])]\n",
    "    if 'affine' in aug_config:\n",
    "        aug_list += [iaa.Affine(**aug_config['affine'])]\n",
    "#     if 'color' in aug_config: #  Color aug not working  yet\n",
    "#         aug_list += [iaa.Sometimes(\n",
    "#             aug_config['color']['probability'], iaa.Sequential([\n",
    "#             iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "#             iaa.WithChannels(0, iaa.Add(aug_config['color']['hue'])),\n",
    "#             iaa.WithChannels(1, iaa.Add(aug_config['color']['saturation'])),\n",
    "#             iaa.WithChannels(2, iaa.Add(aug_config['color']['value'])),\n",
    "#             iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\")\n",
    "#         ]))]\n",
    "    seq = iaa.Sequential(aug_list)\n",
    "    for image, target in gen:\n",
    "        yield seq.augment_image(image), target\n",
    "        \n",
    "aug_config = {\n",
    "    'flip_lr_percentage': 0.5,\n",
    "    'flip_ud_percentage': 0.5,\n",
    "    'affine': {\n",
    "        \"order\": 1,\n",
    "        'scale': {\n",
    "            \"x\": (0.8, 1.2),\n",
    "            \"y\": (0.8, 1.2)\n",
    "        },\n",
    "        \"rotate\": (-10, 10),\n",
    "        \"shear\": (-5, 5),\n",
    "        \"mode\": 'constant'\n",
    "    },\n",
    "#     'color': {\n",
    "#         'probability': 1.00,\n",
    "#         'hue': (0, 0),\n",
    "#         'saturation': (0, 0),\n",
    "#         'value': (0, 0)\n",
    "#     }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = pipeline(\n",
    "    coco_train.generator(shuffle_ids=True),\n",
    "    aug_config=aug_config)\n",
    "val_gen = pipeline(coco_val.generator(shuffle_ids=True))\n",
    "test_gen = pipeline(coco_test.generator(shuffle_ids=True))\n",
    "    \n",
    "for i, (train, val, test) in enumerate(zip(train_gen, val_gen, test_gen)):\n",
    "    print(train[0].shape, train[1])\n",
    "    print(val[0].shape, val[1])\n",
    "    print(test[0].shape, test[1])\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(postprocess(train[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(train[1])]))\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(postprocess(val[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(val[1])]))\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(postprocess(test[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(test[1])]))\n",
    "    \n",
    "    if i >= 0:\n",
    "        break\n",
    "print(\"Left to right: ground truth samples from train, val test\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dump_data(gen, num_images):\n",
    "    data = [[],[]]\n",
    "    for i, (image, caption) in enumerate(gen):\n",
    "        data[0].append(image)\n",
    "        data[1].append(caption)\n",
    "        if i >= num_images:\n",
    "            break\n",
    "    data = (\n",
    "        np.concatenate([i[np.newaxis, ...] for i in data[0]], axis=0),\n",
    "        np.concatenate([i[np.newaxis, ...] for i in data[1]], axis=0)\n",
    "    )\n",
    "    return data\n",
    "\n",
    "def count_labels_multi(data):\n",
    "    return Counter([int(j) for i in data[1] for j in np.argwhere(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gen_dump_data(train_gen, coco_train.num_images())\n",
    "val_data = gen_dump_data(val_gen, coco_val.num_images())\n",
    "test_data = gen_dump_data(test_gen, coco_test.num_images())\n",
    "\n",
    "for label, data in zip(\n",
    "        [\"train\", \"val\", \"test\"],\n",
    "        [train_data, val_data, test_data]):\n",
    "    counter = count_labels_multi(data)\n",
    "    print(label, counter)\n",
    "    \n",
    "train_counts = count_labels_multi(train_data)\n",
    "class_weights =  1 / np.array([j for i, j in sorted(train_counts.items(), key=lambda x: x[0])], dtype=np.float32)\n",
    "class_weights /= np.linalg.norm(class_weights)\n",
    "class_weights = dict(zip(sorted(train_counts.keys()), class_weights.tolist()))\n",
    "print(\"class_weights:\")\n",
    "print(class_weights)\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_head(base_model, num_classes, caption_type, train_features=False, opt_params={}):\n",
    "    '''make sure base_model has include_top=False'''\n",
    "    from keras.layers import Dense, MaxPooling2D, Dropout, Flatten\n",
    "    from keras.models import Model\n",
    "    \n",
    "    if not opt_params:\n",
    "        opt_params = {\"optimizer\": \"Nadam\"}\n",
    "    opt_params['loss'] = \"categorical_crossentropy\" if caption_type == \"single\" else \"binary_crossentropy\"\n",
    "    activation = \"softmax\" if caption_type == \"single\" else \"sigmoid\"\n",
    "    \n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation=activation, name='class_logits')(x)\n",
    "\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = train_features\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(**opt_params, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note:\n",
    "###    When single-label training a 'softmax' activation and 'categorical_crossentropy' loss is used\n",
    "###    When multi-label training a 'sigmoid' activation and 'binary_crossentropy' loss is used\n",
    "\n",
    "K.clear_session()\n",
    "model = create_new_head(\n",
    "    InceptionV3(\n",
    "        include_top=False, weights='imagenet', input_shape=image_dims),\n",
    "    num_classes, caption_type, train_features=False,\n",
    "    opt_params={'optimizer': \"Nadam\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load model weights if needed\n",
    "# model.load_weights(\"/data/log/cnn/cso-sigmoid/models/best.058-0.0681.h5\")\n",
    "# model.load_weights(\"/data/log/cnn/cso/models/best.036-0.1494.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path = os.path.join(log_dir, \"models/best.{epoch:03d}-{val_loss:.4f}.h5\")\n",
    "\n",
    "callbacks=[\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=9, cooldown=6, verbose=1),\n",
    "        ModelCheckpoint(\n",
    "            best_path, monitor='val_loss', verbose=1,\n",
    "            save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "        TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=0,\n",
    "            batch_size=batch_size,\n",
    "            write_graph=False,\n",
    "            write_grads=False,\n",
    "            write_images=False),\n",
    "#         EarlyStopping(\n",
    "#             monitor='val_loss', min_delta=0.0, patience=40, verbose=1, mode='auto')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train with initial LR\n",
    "learning_rate = 1e-4\n",
    "K.set_value(model.optimizer.lr, learning_rate)\n",
    "train_history = model.fit_generator(\n",
    "    batching_gen(train_gen, batch_size=batch_size),\n",
    "    validation_data=tuple(val_data),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=steps_per_epoch_val,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks, \n",
    "    epochs=100,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def multi_label_decision(y_true, y_pred, thresh=0.5):\n",
    "    return (y_true > thresh) == (y_pred > thresh)\n",
    "def single_label_decision(y_true, y_pred):\n",
    "    return np.argmax(y_true, axis=-1) == np.argmax(y_pred, axis=-1)\n",
    "\n",
    "decision_function = single_label_decision if caption_type == 'single' else multi_label_decision\n",
    "thresh = 0.5 # Used for multi-label decisions\n",
    "\n",
    "Y_true = test_data[1]\n",
    "Y_pred = model.predict(test_data[0])\n",
    "TP = decision_function(Y_true, Y_pred)\n",
    "print(\"Test accuracy for {:d} samples: {:.2f}\".format(len(test_data[0]), np.count_nonzero(TP) / TP.size))\n",
    "for i, (image, true_caption, pred_caption) in enumerate(zip(test_data[0], test_data[1], Y_pred)):\n",
    "    if i % 4 == 0:\n",
    "        if i > 0:\n",
    "            plt.tight_layout()\n",
    "        if i >= 4:\n",
    "            break\n",
    "        if i < len(test_data[0]):\n",
    "            plt.figure()\n",
    "    plt.subplot(2, 2, 1 + (i % 4))\n",
    "    plt.imshow(postprocess(image))\n",
    "    plt.title(\"T: {:s}; P: {:s}\".format(\n",
    "        ', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(true_caption > thresh)]),\n",
    "        ', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(pred_caption > thresh)])\n",
    "    ))\n",
    "test_metrics = model.evaluate(test_data[0], test_data[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model (pretty important!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name, class_map_r, prediction_type,\n",
    "               model_weights_path, model_def_path, model_info_path,\n",
    "               test_metrics=None, description=\"\"):\n",
    "    def merged(a, b):\n",
    "        merged = dict(a)\n",
    "        merged.update(b)\n",
    "        return merged\n",
    "        \n",
    "    model_info = {\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"weights\": model_weights_path,\n",
    "        \"prediction_type\": caption_type,\n",
    "        \"model\": model_def_path,\n",
    "        \"classes\": class_map_r,\n",
    "        \"architecture\": {\n",
    "            \"backbone\": \"inceptionv3\",\n",
    "            \"logit_activation\": model.get_layer(\"class_logits\").activation.__name__,\n",
    "            \"input_shape\": image_dims\n",
    "        },\n",
    "        \"metrics\": {\n",
    "            \"loss_function\": train_history.model.loss,\n",
    "            \"train\": merged(\n",
    "                train_history.history,\n",
    "                {\n",
    "                    \"epoch\": train_history.epoch,\n",
    "                    \"params\": train_history.params\n",
    "                })\n",
    "        }\n",
    "    }\n",
    "    if test_metrics:\n",
    "        model_info['metrics']['test'] = test_metrics\n",
    "    \n",
    "    print(\"Writing model def to \" + model_def_path)\n",
    "    with open(model_def_path, \"w\") as file:\n",
    "        file.write(model.to_json())\n",
    "        \n",
    "    print(\"Writing model weights to \" + model_weights_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "    \n",
    "    print(\"Writing model info to \" + model_info_path)\n",
    "    with open(model_info_path, \"w\") as file:\n",
    "        file.write(json.dumps(model_info))\n",
    "    \n",
    "# Fill in the relevant params below    \n",
    "model_def_path = os.path.join(log_dir, \"model_def.json\")\n",
    "model_weights_path = os.path.join(log_dir, \"model_weights.h5\")\n",
    "model_info_path = os.path.join(log_dir, \"model.json\")\n",
    "save_model(\n",
    "    model, name=\"example-1\",\n",
    "    class_map_r=caption_map_r, prediction_type=caption_type,\n",
    "    model_weights_path=model_weights_path, model_def_path=model_def_path, model_info_path=model_info_path,\n",
    "    test_metrics=test_metrics,\n",
    "    description=\"Model for detecting whether camera is forwards or sidewards facing in a pipe.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
