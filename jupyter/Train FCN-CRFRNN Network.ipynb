{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/lib64:' + os.environ['LD_LIBRARY_PATH']\n",
    "from abyss_deep_learning.utils import config_gpu\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from skimage.color import label2rgb\n",
    "from keras import Model\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from abyss_deep_learning.datasets.base import DatasetTaskBase\n",
    "from abyss_deep_learning.keras.tensorboard import ImprovedTensorBoard\n",
    "from abyss_deep_learning.datasets.coco import CocoInterface, CocoDataset, ImageDatatype\n",
    "\n",
    "#augmentation_gen, jaccard_index\n",
    "from abyss_deep_learning.keras.utils import initialize_conv_transpose2d, lambda_gen\n",
    "\n",
    "from crfrnn.crfrnn_model import get_crfrnn_model_def\n",
    "config_gpu([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### If you don't have the imagenet weights below it will auto download them\n",
    "if not os.path.exists(\"~/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"):\n",
    "    from keras.applications.vgg16 import VGG16\n",
    "    vgg = VGG16(include_top=False)\n",
    "    del vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def _noop(*args):\n",
    "    return args if len(args) > 1 else args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pack_masks(masks, mask_classes, num_classes, dtype=np.uint8):\n",
    "    '''Pack a list of instance masks into a categorical mask.\n",
    "    Expects masks to be shape [height, width, num_instances] and mask_classes to be [num_instances].'''\n",
    "    num_shapes = len(mask_classes)\n",
    "    shape = masks.shape\n",
    "    packed = np.zeros(shape[0:2] + (num_classes,), dtype=dtype)\n",
    "    packed[..., 0] = 1\n",
    "    for i in range(num_shapes):\n",
    "        class_id = mask_classes[i]\n",
    "        mask = masks[..., i]\n",
    "        packed[..., class_id] |= mask\n",
    "        packed[..., 0] &= ~mask\n",
    "    return packed\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "def augmentation_gen(gen, common_aug, image_aug, enable=True):\n",
    "    '''\n",
    "    Data augmentation for segmentation task.\n",
    "    A common augmentation list is applied to both images and masks and should not contain colour augmentation, \n",
    "    and should ensure order=0 is used for all geometric transforms.\n",
    "    An image augmentation list is then applied to only the image, this should contain no geometric augmentations.\n",
    "    '''\n",
    "    if not enable:\n",
    "        while True:\n",
    "            yield from gen\n",
    "    common_seq = iaa.Sequential(common_aug)\n",
    "    image_seq = iaa.Sequential(image_aug)\n",
    "    for image, target in gen:\n",
    "        common_seq_det = common_seq.to_deterministic()\n",
    "        image_c = common_seq_det.augment_image(image)\n",
    "#         image_c = image_seq.augment_image(image)\n",
    "        masks_c = common_seq_det.augment_image(target)\n",
    "        yield image_c, masks_c\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abyss_deep_learning.datasets.translators import AnnotationTranslator\n",
    "import concurrent.futures\n",
    "\n",
    "class SemanticSegmentationTask(CocoInterface, DatasetTaskBase):\n",
    "    def __init__(self, coco, translator=None, **kwargs):\n",
    "        CocoInterface.__init__(self, coco, **kwargs)\n",
    "        assert isinstance(translator, (AnnotationTranslator, type(None)))\n",
    "        self.translator = translator or AnnotationTranslator()\n",
    "        self.num_classes = len(self.coco.cats) + 1\n",
    "        self.stats = dict()\n",
    "        self._targets = dict()\n",
    "\n",
    "        self._preprocess_targets = kwargs.get('preprocess_targets', _noop)\n",
    "\n",
    "        if kwargs.get('cached', False):\n",
    "            with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "                for data_id, targets in zip(\n",
    "                        self.data_ids, executor.map(self.load_targets, self.data_ids)):\n",
    "                    self._targets[data_id] = targets\n",
    "\n",
    "        self._calc_class_stats()\n",
    "\n",
    "    def load_targets(self, data_id, **kwargs):\n",
    "        assert np.issubdtype(type(data_id), np.integer), \"Must pass exactly one ID\"\n",
    "        if data_id in self._targets:\n",
    "            return self._targets[data_id]\n",
    "        img = self.coco.loadImgs(ids=[data_id])[0]\n",
    "        anns = [self.translator.translate(ann) for ann in self.coco.loadAnns(\n",
    "            self.coco.getAnnIds([data_id])) if self.translator.filter(ann)]\n",
    "        if anns:\n",
    "            masks = np.array([self.coco.annToMask(ann) for ann in anns]).transpose((1, 2, 0))\n",
    "            class_ids = np.array([ann['category_id'] for ann in anns])\n",
    "            return self._preprocess_targets(\n",
    "                _pack_masks(masks, class_ids, self.num_classes, dtype=self.dtype_image))\n",
    "        masks = np.zeros((img['height'], img['width'], self.num_classes), dtype=self.dtype_image)\n",
    "        masks[..., 0] = 1\n",
    "        return self._preprocess_targets(masks)\n",
    "        \n",
    "\n",
    "    def _calc_class_stats(self):\n",
    "        from collections import Counter\n",
    "        if not self.stats:\n",
    "            self.stats = dict()\n",
    "            class_count = dict()\n",
    "            for data_id in self.data_ids:\n",
    "                target = self.load_targets(data_id).argmax(-1)\n",
    "                for key, val in Counter(target.ravel().tolist()).items():\n",
    "                    class_count[key] = class_count.get(key, 0) + val\n",
    "            \n",
    "            self.stats['class_weights'] = np.array(\n",
    "                [class_count.get(key, 0) for key in range(ARGS['num_classes'])], dtype=np.float64)\n",
    "            self.stats['class_weights'] **= -1.0\n",
    "            self.stats['class_weights'] /= self.stats['class_weights'].min()\n",
    "#             a = np.array(list(class_weights.values()))\n",
    "#             self.stats['trivial_accuracy'] = np.mean(a / np.max(a))\n",
    "\n",
    "    @property\n",
    "    def class_weights(self):\n",
    "        '''Returns the class weights that will balance the backprop update over the class distribution.'''\n",
    "        return self.stats['class_weights']\n",
    "\n",
    "    def print_class_stats(self):\n",
    "        '''Prints statistics about the class/image distribution.'''\n",
    "        self._calc_class_stats()\n",
    "#         print(\"{:s} class stats {:s}\".format('=' * 8, '=' * 8))\n",
    "#         print(\"data count per class:\")\n",
    "#         print(\" \", self.stats['images_per_class'])\n",
    "        print(\"class weights:\")\n",
    "        print(\" \", self.class_weights)\n",
    "#         print(\"trivial result accuracy:\\n  {:.2f} or {:.2f}\".format(\n",
    "#             self.stats['trivial_accuracy'], 1 - self.stats['trivial_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "class ImageSemanticSegmentationDataset(CocoDataset, ImageDatatype, SemanticSegmentationTask):\n",
    "    # TODO: \n",
    "    #   *  Class statistics readout\n",
    "    #   *  Support for computing class weights given current dataset config\n",
    "    #   *  Support for forcing class balance by selecting IDs evenly\n",
    "    #   *  Generator data order optimization\n",
    "    #   *  Support for visualising data sample or prediction with same format\n",
    "    def __init__(self, json_path, **kwargs):\n",
    "        CocoDataset.__init__(self, json_path, **kwargs)\n",
    "        ImageDatatype.__init__(self, self.coco, **kwargs)\n",
    "        SemanticSegmentationTask.__init__(self, self.coco, **kwargs)\n",
    "        \n",
    "    def sample(self, image_id=None, **kwargs):\n",
    "        if not image_id:\n",
    "            image_id = random.choice(self.data_ids)\n",
    "        return (self.load_data(image_id, **kwargs), self.load_targets(image_id, **kwargs))\n",
    "            \n",
    "    def generator(self, data_ids=None, shuffle_ids=False, endless=False, **kwargs):\n",
    "        if not data_ids:\n",
    "            data_ids = list(self.data_ids)\n",
    "        if shuffle_ids:\n",
    "            random.shuffle(data_ids)\n",
    "        iterator = itertools.cycle if endless else iter\n",
    "        for data_id in iterator(data_ids):\n",
    "            yield self.load_data(data_id, **kwargs), self.load_targets(data_id, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "def preprocess_data(image):\n",
    "    '''Transform the image before (possibly caching) and input to the network.'''\n",
    "    image = resize(image, ARGS['image_dims'], preserve_range=True, mode='constant')\n",
    "    return preprocess_input(image.astype(ARGS['nn_dtype']), mode='tf')\n",
    "\n",
    "def preprocess_targets(image):\n",
    "    '''Transform the mask before (possibly caching) and input to the network.'''\n",
    "    image = resize(image, ARGS['image_dims'][0:2], preserve_range=True, mode='constant')\n",
    "    return image.astype(ARGS['nn_dtype'])\n",
    "\n",
    "def postprocess_data(image):\n",
    "    '''Inverse transform of preprocess_data, used when trying to visualize images out of the dataset.'''\n",
    "    return ((image + 1) * 127.5).astype(np.uint8)\n",
    "\n",
    "\n",
    "from abyss_deep_learning.datasets.translators import AnnotationTranslator\n",
    "class AnnotationMapper(AnnotationTranslator):\n",
    "        '''Transform COCO JSON annotations in any way you want. This one maps source to dest classes.'''\n",
    "        def __init__(self, class_map=None):\n",
    "            self.class_map = class_map\n",
    "#             self.num_classes = len(class_map)\n",
    "\n",
    "        def filter(self, annotation):\n",
    "            return 'segmentation' in annotation and annotation['annotation_type'] in ['poly']\n",
    "\n",
    "        def translate(self, annotation):\n",
    "            output = dict(annotation)\n",
    "            if self.class_map:\n",
    "                output['category_id'] = self.class_map[annotation['category_id']]\n",
    "            return annotation\n",
    "        \n",
    "def setup_args():\n",
    "    \n",
    "    from bidict import bidict\n",
    "    from imgaug import augmenters as iaa\n",
    "    from imgaug.parameters import Normal\n",
    "    \n",
    "    \n",
    "\n",
    "    def pipeline(gen, aug_config=None):\n",
    "        '''The pipeline to run the dataset generator through.'''\n",
    "#         from abyss_deep_learning.keras.classification import augmentation_gen\n",
    "        if not aug_config:\n",
    "            aug_config = (None, None)\n",
    "        return (\n",
    "            augmentation_gen(gen, *aug_config, enable=(aug_config[0] is not None))\n",
    "        )\n",
    "\n",
    "    \n",
    "        \n",
    "    class_map = bidict({ # or give a bidict mapping source->dest category_id\n",
    "        0: 0,\n",
    "        1: 1,\n",
    "        2: 2,\n",
    "        3: 3,\n",
    "    })\n",
    "    \n",
    "    augmentation_common = iaa.Sequential([ \n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.Affine(\n",
    "            scale=(0.8, 1.2),\n",
    "            translate_percent=(-0.2, 0.2), \n",
    "            rotate=(-22.5, 22.5),\n",
    "            mode='constant', cval=0, order=0\n",
    "        ),\n",
    "        \n",
    "    ])\n",
    "    augmentation_image = iaa.Sequential([ # Colour aug\n",
    "        iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "        iaa.WithChannels(0, iaa.Add(Normal(0, 256 / 6))),\n",
    "        iaa.WithChannels(1, iaa.Add(Normal(0, 256 / 6))),\n",
    "        iaa.WithChannels(2, iaa.Add(Normal(0, 256 / 6))),\n",
    "        iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\")\n",
    "    ])\n",
    "\n",
    "    args = {\n",
    "        'annotation_translator': AnnotationMapper(class_map),\n",
    "        'augmentation': (augmentation_common, augmentation_image),    # Training augmentation\n",
    "        'class_map': class_map,             # class_map\n",
    "        'caption_type': ['single', 'multi'][1], # Caption type can be either \"single\" or \"multi\".\n",
    "                                                # This sets up various other parameters in the system.\n",
    "        'data': {\n",
    "            'base_dir': \"/data/abyss/anadarko/label-sets\",\n",
    "            'name': \"first\",\n",
    "            'sets': ('train', 'val', 'test')\n",
    "        },\n",
    "        'image_dims': (500, 500, 3),    # What to resize images to before CNN\n",
    "        'nn_dtype': np.float32,         # Pretrained networks are in float32\n",
    "        'num_classes': len(class_map),\n",
    "        'use_balanced_set': False,      # Force the use of the largest class-balanced dataset\n",
    "        'use_cached': True,            # Cache the dataset in memory\n",
    "        'use_class_weights': True,      # Use class population to weight in the training loss\n",
    "        'use_parallel': False,          # Use multiple GPUs\n",
    "        'preprocess_data': preprocess_data,\n",
    "        'preprocess_targets': preprocess_targets,\n",
    "        'postprocess_data': postprocess_data,\n",
    "        'pipeline': pipeline\n",
    "    }\n",
    "    \n",
    "    return args\n",
    "ARGS = setup_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_datasets(args):\n",
    "    from abyss_deep_learning.datasets.coco import ImageClassificationDataset\n",
    "    \n",
    "    dataset = dict()\n",
    "    for set_name in args['data']['sets']:\n",
    "        path = os.path.join(args['data']['base_dir'], \"{:s}/{:s}.json\".format(args['data']['name'], set_name))\n",
    "        dataset[set_name] = ImageSemanticSegmentationDataset(\n",
    "            path,\n",
    "            translator=args['annotation_translator'],\n",
    "            cached=args['use_cached'],\n",
    "            preprocess_data=args['preprocess_data'],\n",
    "            preprocess_targets=args['preprocess_targets'])\n",
    "        print(\"\\n\", set_name)\n",
    "        dataset[set_name].print_class_stats()\n",
    "\n",
    "\n",
    "    print(\"\\nNumber of classes:\", args['num_classes'])\n",
    "    print(\"captions:\")\n",
    "    print(args['class_map'])\n",
    "    return dataset\n",
    "DATASET = setup_datasets(ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_dataset_samples(num_rows=2):\n",
    "    plt.figure()\n",
    "    print(\"Column-wise left to right, bottom row:\")\n",
    "    for i, (name, ds) in enumerate(DATASET.items()):\n",
    "        print(name, end=' ')\n",
    "        for j, (image, label) in enumerate(ARGS['pipeline'](ds.generator(shuffle_ids=True))):\n",
    "            plt.subplot(num_rows, 3, 3 * j + i + 1)\n",
    "            plt.imshow(\n",
    "                label2rgb(label.argmax(-1), ARGS['postprocess_data'](image), bg_label=0))\n",
    "#             plt.title(', '.join([str(ARGS['class_map'].inv[int(cap_id)]) for cap_id in np.argwhere(label)]))\n",
    "            plt.axis('off')\n",
    "            if j + 1 == num_rows:\n",
    "                break\n",
    "        print('shape: {}, label: {}, min: {:.1f}, mean: {:.1f}, max: {:.1f}'.format(\n",
    "            image.shape, label.shape, image.min(), image.mean(), image.max()))\n",
    "\n",
    "view_dataset_samples(num_rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(object):\n",
    "    def __init__(self):\n",
    "        self.batch_size = 1\n",
    "        self.model_parallel = None\n",
    "        self.has_crf = False\n",
    "    \n",
    "    def get_train_model(self):\n",
    "        return self.model_parallel or self.model\n",
    "        \n",
    "    def plot_test(self, output_fn=np.argmax):\n",
    "        gen = DATASET['test'].generator(shuffle_ids=True)\n",
    "        for i, (rgb, target) in enumerate(gen):\n",
    "            print(\"rgb.shape\", rgb.shape)\n",
    "            print(\"rgb min/max\", np.min(rgb), np.max(rgb))\n",
    "            print(\"target.shape\", target.shape)\n",
    "            print(\"target min/max\", np.min(target), np.max(target))\n",
    "\n",
    "            rgb8 = ((rgb + 1) / 2 * 255).astype(np.uint8)\n",
    "            Y_pred = self.model.predict(rgb[np.newaxis, ...])\n",
    "            plt.figure()\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(rgb8)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(label2rgb(target.argmax(-1), rgb8, bg_label=0))\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.imshow(label2rgb(Y_pred[0].argmax(-1), rgb8, bg_label=0))\n",
    "#             plt.title(\"CRF IoU={:.2f}\".format(\n",
    "#                 jaccard_index(output_fn(target, axis=-1), np.argmax(Y_pred[0], axis=-1))))\n",
    "            plt.tight_layout()\n",
    "            break\n",
    "\n",
    "    def init_crf(self):\n",
    "        crf_params = ['crfrnn/spatial_ker_weights:0',\n",
    "                  'crfrnn/bilateral_ker_weights:0',\n",
    "                  'crfrnn/compatibility_matrix:0']\n",
    "        self.model.get_layer(name='crfrnn').set_weights([\n",
    "            np.eye(2), np.eye(2), 1 - np.eye(2)\n",
    "        ])\n",
    "        \n",
    "    def create_model(self, num_classes, image_dims, upsample='new', num_iterations=0):\n",
    "        '''\n",
    "        crf can be one of 'new', 'load', 'train' or 'none'\n",
    "        upsample can be one of 'new', 'load' or 'train\n",
    "        '''\n",
    "        self.has_crf = num_iterations > 0\n",
    "        self.model = None\n",
    "        self.model_parallel = None\n",
    "        K.clear_session()\n",
    "        print(\"Making model with {:d} classes and {} input shape\".format(num_classes, str(image_dims)))\n",
    "        self.model = get_crfrnn_model_def(\n",
    "            num_classes=num_classes, input_shape=image_dims,\n",
    "            num_iterations=num_iterations, with_crf=self.has_crf)\n",
    "        if upsample in ['bilinear', 'train']:\n",
    "            initialize_conv_transpose2d(\n",
    "                self.model,\n",
    "                ['score2', 'score4', 'upsample'],\n",
    "                trainable=True)\n",
    "        if self.has_crf:\n",
    "            self.init_crf()\n",
    "            \n",
    "    def load_model(self, model_path):\n",
    "        if model_path: \n",
    "            self.model.load_weights(model_path, by_name=True)\n",
    "        if self.has_crf:\n",
    "            self.init_crf()\n",
    "\n",
    "    def compile_model(self, train_layers=None, parallel=False):\n",
    "        from abyss_deep_learning.keras.metrics import mpca_factory, auc_factory\n",
    "        weights = np.ones((1, 1, 1, 1))\n",
    "        \n",
    "        if train_layers:\n",
    "            for layer in self.model.layers:\n",
    "                layer.trainable = layer.name in train_layers\n",
    "        if parallel:\n",
    "            from keras.utils import multi_gpu_model\n",
    "            self.model_parallel = multi_gpu_model(self.model, gpus=2)#, cpu_merge=True, cpu_relocation=False)\n",
    "        self.get_train_model().compile(\n",
    "            optimizer='nadam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[\n",
    "                'accuracy',\n",
    "#                  auc_factory(\"PR\", weights),\n",
    "#                  auc_factory(\"ROC\", weights)\n",
    "            ])\n",
    "\n",
    "    def train(self, epochs, initial_epoch=0, val_data=None):\n",
    "        from abyss_deep_learning.keras.utils import batching_gen\n",
    "        \n",
    "        steps_per_epoch = len(DATASET['train'].data_ids) // self.batch_size\n",
    "        steps_per_epoch_val = VAL_DATA[0].shape[0] // self.batch_size \n",
    "        print(\"Steps per epoch:\", steps_per_epoch)\n",
    "        print(\"Steps per steps_per_epoch_val:\", steps_per_epoch_val)\n",
    "\n",
    "        train_gen = ARGS['pipeline'](DATASET['train'].generator(\n",
    "            shuffle_ids=True, endless=True), aug_config=ARGS['augmentation'])\n",
    "        common = {\n",
    "            \"class_weight\": DATASET['train'].class_weights,\n",
    "            \"callbacks\": self.callbacks,\n",
    "            \"epochs\": epochs,\n",
    "            \"verbose\": 1,\n",
    "            \"initial_epoch\": initial_epoch,\n",
    "        }\n",
    "\n",
    "        self.history = self.get_train_model().fit_generator(\n",
    "            batching_gen(train_gen, batch_size=self.batch_size),\n",
    "#             validation_data=batching_gen(\n",
    "#                 data_source('val'), batch_size=exp.batch_size),\n",
    "            validation_data=VAL_DATA,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_steps=steps_per_epoch_val,\n",
    "            workers=10,\n",
    "            **common)\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dataset(dataset, num_data, aug_config=None):\n",
    "    data = np.empty((num_data,) + tuple(ARGS['image_dims']), dtype=ARGS['nn_dtype'])\n",
    "    targets = np.empty((num_data,) + tuple(ARGS['image_dims'][0:2] + (ARGS['num_classes'],)), dtype=ARGS['nn_dtype'])\n",
    "    for i, (datum, target) in enumerate(ARGS['pipeline'](dataset.generator(), aug_config)):\n",
    "        data[i], targets[i] = datum, target\n",
    "        if i + 1 == num_data:\n",
    "            break\n",
    "    return data, targets\n",
    "\n",
    "VAL_DATA = dump_dataset(DATASET['val'], num_data=len(DATASET['val'].data_ids), aug_config=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First train only Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_weights = \"/home/docker/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "logdir = os.path.join(\"/data/log/fcn-crfrnn/anadarko/first/{:04d}\".format(np.random.randint(0, 9999)))\n",
    "!mkdir -p \"$logdir/models\"\n",
    "best_path = os.path.join(logdir, \"models/best.{epoch:03d}-{val_loss:.4f}.h5\")\n",
    "print(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = K.tf.get_default_graph()\n",
    "g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abyss_deep_learning.keras.tensorboard import kernel_sparsity, avg_update_ratio\n",
    "\n",
    "exp = None\n",
    "K.clear_session()\n",
    "exp = Experiment()\n",
    "exp.batch_size = 2\n",
    "exp.create_model(\n",
    "    ARGS['num_classes'], ARGS['image_dims'],\n",
    "    upsample='train',\n",
    "    num_iterations=0)\n",
    "exp.load_model(imagenet_weights)\n",
    "\n",
    "layers = [layer.name for layer in exp.model.layers]\n",
    "train_layers = layers[layers.index('fc6'):]\n",
    "predictions_kernel = exp.model.get_layer(name='upsample').trainable_weights[0] # Used in a scalar callback\n",
    "\n",
    "exp.compile_model(train_layers=train_layers, parallel=ARGS['use_parallel'])\n",
    "exp.callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, cooldown=5, verbose=1),\n",
    "        ModelCheckpoint(\n",
    "            best_path, monitor='val_loss', verbose=1,\n",
    "            save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "        ImprovedTensorBoard(\n",
    "            log_dir=logdir,\n",
    "            histogram_freq=5, batch_size=exp.batch_size,\n",
    "            scalars={\n",
    "                'learning_rate': exp.get_train_model().optimizer.lr,\n",
    "                'feature_sparsity': kernel_sparsity(exp.get_train_model()),\n",
    "                'prediction_UW_ratio': avg_update_ratio(exp.get_train_model(), predictions_kernel)\n",
    "            },\n",
    "            groups={\n",
    "                'performance': {\n",
    "                    'loss': ['loss', 'val_loss'],\n",
    "                    'accuracy': [r'.*accuracy.*'],\n",
    "                    'Mean Per-Class Average Accuracy': [r'.*mpca.*'],\n",
    "                    'Mean Avg Precision': [r'.*PR.*'],\n",
    "                    'ROC AUC': [r'.*ROC.*']\n",
    "                }\n",
    "            },\n",
    "            pr_curve=False,\n",
    "            num_classes=VAL_DATA[1].shape[1],\n",
    "#             write_graph=True,\n",
    "#             write_grads=True,\n",
    "#             write_images=False,\n",
    "#             embeddings_freq=10,\n",
    "#             embeddings_layer_names=['predictions', 'features'],\n",
    "#             embeddings_metadata=(logdir + \"/data_labels.tsv\"),\n",
    "#             embeddings_data=VAL_DATA[0],\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss', min_delta=0.0, patience=10, verbose=1, mode='auto')\n",
    "]\n",
    "# Test to see if LR causes loss explosion\n",
    "K.set_value(exp.get_train_model().optimizer.lr, 5e-4)\n",
    "try:\n",
    "    exp.train(200, val_data=VAL_DATA)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "except:\n",
    "    raise\n",
    "# Save the weights and epoch for next training step\n",
    "initial_epoch = exp.callbacks[3].stopped_epoch + 1 if exp.callbacks[3].stopped_epoch else 16\n",
    "initial_lr = K.eval(exp.get_train_model().optimizer.lr)\n",
    "exp.model.save_weights('/data/tmp/blah_weights.h5')\n",
    "# raise RuntimeError(\"Stop Run All\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save weights, reload and train all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = None\n",
    "K.clear_session()\n",
    "exp = Experiment()\n",
    "exp.create_model(\n",
    "    ARGS['num_classes'], ARGS['image_dims'],\n",
    "    upsample='train',\n",
    "    num_iterations=5)\n",
    "exp.batch_size = 1\n",
    "exp.load_model('/data/tmp/blah_weights.h5')\n",
    "\n",
    "layers = [layer.name for layer in exp.model.layers]\n",
    "train_layers = layers[layers.index('fc6'):]\n",
    "predictions_kernel = exp.model.get_layer(name='upsample').trainable_weights[0] # Used in a scalar callback\n",
    "\n",
    "exp.compile_model(train_layers=train_layers, parallel=ARGS['use_parallel'])\n",
    "exp.callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, cooldown=5, verbose=1),\n",
    "        ModelCheckpoint(\n",
    "            best_path, monitor='val_loss', verbose=1,\n",
    "            save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "        ImprovedTensorBoard(\n",
    "            log_dir=logdir,\n",
    "            histogram_freq=5, batch_size=exp.batch_size,\n",
    "            scalars={\n",
    "                'learning_rate': exp.get_train_model().optimizer.lr,\n",
    "                'feature_sparsity': kernel_sparsity(exp.get_train_model()),\n",
    "                'prediction_UW_ratio': avg_update_ratio(exp.get_train_model(), predictions_kernel)\n",
    "            },\n",
    "            groups={\n",
    "                'performance': {\n",
    "                    'loss': ['loss', 'val_loss'],\n",
    "                    'accuracy': ['acc', 'val_acc'],\n",
    "                    'Mean Per-Class Average Accuracy': [r'.*mpca.*'],\n",
    "                    'Mean Avg Precision': [r'.*PR.*'],\n",
    "                    'ROC AUC': [r'.*ROC.*']\n",
    "                }\n",
    "            },\n",
    "            pr_curve=False,\n",
    "            num_classes=VAL_DATA[1].shape[1],\n",
    "#             write_graph=True,\n",
    "#             write_grads=True,\n",
    "#             write_images=False,\n",
    "#             embeddings_freq=10,\n",
    "#             embeddings_layer_names=['predictions', 'features'],\n",
    "#             embeddings_metadata=(logdir + \"/data_labels.tsv\"),\n",
    "#             embeddings_data=VAL_DATA[0],\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss', min_delta=0.0, patience=10, verbose=1, mode='auto')\n",
    "]\n",
    "# Test to see if LR causes loss explosion\n",
    "exp.model.layers[-1].trainable = False\n",
    "K.set_value(exp.get_train_model().optimizer.lr, 5e-4)\n",
    "try:\n",
    "    exp.train(200, val_data=VAL_DATA, initial_epoch=2)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "except:\n",
    "    raise\n",
    "# Save the weights and epoch for next training step\n",
    "initial_epoch = exp.callbacks[3].stopped_epoch + 1 if exp.callbacks[3].stopped_epoch else 16\n",
    "initial_lr = K.eval(exp.get_train_model().optimizer.lr)\n",
    "exp.model.save_weights('/data/tmp/blah_weights2.h5')\n",
    "# raise RuntimeError(\"Stop Run All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = exp.model.layers[-1]\n",
    "a, a.get_output_shape_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = DATASET['test'].sample()\n",
    "print(img.shape, label.shape)\n",
    "y_pred = exp.model.predict(img[np.newaxis, ...])\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test(self, output_fn=np.argmax):\n",
    "        gen = DATASET['test'].generator(shuffle_ids=True)\n",
    "        for i, (rgb, target) in enumerate(gen):\n",
    "            print(\"rgb.shape\", rgb.shape)\n",
    "            print(\"rgb min/max\", np.min(rgb), np.max(rgb))\n",
    "            print(\"target.shape\", target.shape)\n",
    "            print(\"target min/max\", np.min(target), np.max(target))\n",
    "\n",
    "            rgb8 = ((rgb + 1) / 2 * 255).astype(np.uint8)\n",
    "            Y_pred = self.model.predict(rgb[np.newaxis, ...])\n",
    "            plt.figure()\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.title(\"RGB\")\n",
    "            plt.imshow(rgb8)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.title(\"Ground Truth\")\n",
    "            plt.imshow(label2rgb(target.argmax(-1), rgb8, bg_label=0))\n",
    "            plt.subplot(2, 2, (3, 4))\n",
    "            plt.imshow(label2rgb(np.argmax(Y_pred[0], axis=-1), rgb8, bg_label=0))\n",
    "            plt.title(\"Predicted\")\n",
    "#             plt.title(\"CRF IoU={:.2f}\".format(\n",
    "#                 jaccard_index(output_fn(target, axis=-1), np.argmax(Y_pred[0], axis=-1))))\n",
    "            plt.tight_layout()\n",
    "            break\n",
    "plot_test(exp)\n",
    "# exp.plot_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "y_pred = exp.model.predict(x=test_data[0], batch_size=exp.batch_size)\n",
    "ap_micro = average_precision_score(\n",
    "    test_data[1][..., 1:].reshape((-1, test_data[1].shape[-1] - 1)),\n",
    "    y_pred[..., 1:].reshape((-1, test_data[1].shape[-1] - 1)),\n",
    "    average='micro')\n",
    "print(\"Micro average precision of FG classes is {:.4f}\".format(ap_micro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Trained Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN Upsample Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at upsampling weights\n",
    "layer_names = ['score2', 'score4', 'upsample']\n",
    "for name in layer_names:\n",
    "    layer = exp.model.get_layer(name=name)\n",
    "    v = layer.get_weights()[0]\n",
    "    print(v.shape)\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(v[:, :, 0, 0])\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(v[:, :, 0, 1])\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(v[:, :, 1, 0])\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(v[:, :, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.get_train_model().get_layer(name='crfrnn').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
