{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/lib64:' + os.environ['LD_LIBRARY_PATH']\n",
    "from abyss_deep_learning.utils import config_gpu\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from skimage.color import label2rgb\n",
    "from keras import Model\n",
    "from keras.optimizers import Nadam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from abyss_deep_learning.keras.segmentation import SegmentationDataset, augmentation_gen, jaccard_index\n",
    "from abyss_deep_learning.keras.utils import initialize_conv_transpose2d, lambda_gen\n",
    "\n",
    "from crfrnn.crfrnn_model import get_crfrnn_model_def\n",
    "\n",
    "config_gpu([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### If you don't have the imagenet weights below it will auto download them\n",
    "if not os.path.exists(\"~/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"):\n",
    "    from keras.applications.vgg16 import VGG16\n",
    "    vgg = VGG16(include_top=False)\n",
    "    del vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "parallel = False # Use multiple GPUs\n",
    "num_classes = 6\n",
    "image_dims = (500, 500, 3) # Can't be changed for crfrnn\n",
    "use_class_weights = False\n",
    "use_balanced_set = False\n",
    "use_cached = True\n",
    "aug_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dir = \"/data/abyss\"\n",
    "dataset_name = \"swc_pipeline\"\n",
    "'/data/ab'\n",
    "dataset_files = {\n",
    "    'train': os.path.join(database_dir, \"{:s}/swc_pipeline-coco2_train.json\".format(dataset_name)),\n",
    "    'val': os.path.join(database_dir, \"{:s}/swc_pipeline-coco2_val.json\".format(dataset_name)),\n",
    "    'test': os.path.join(database_dir, \"{:s}/swc_pipeline-coco2_val.json\".format(dataset_name))\n",
    "}\n",
    "dataset_name = dataset_name.replace(\"/\", \"-\")\n",
    "\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, target):\n",
    "    image = resize(image, image_dims, preserve_range=True, mode='constant')\n",
    "    target = resize(target, image_dims[0:2], preserve_range=True, mode='constant', order=0)\n",
    "    return preprocess_input(image, mode='tf'), target\n",
    "\n",
    "def postprocess(image, target):\n",
    "    print(image.shape, target.shape)\n",
    "    return ((image + 1) * 127.5).astype(np.uint8)\n",
    "        \n",
    "def pipeline(gen, samples_per_image=1, augment=False):\n",
    "    return (\n",
    "            lambda_gen(\n",
    "                augmentation_gen(\n",
    "#                         fill_mask_gen(\n",
    "                                gen\n",
    "#                         , min_size=3750)\n",
    "                , aug_config=aug_config, enable=augment)\n",
    "            , func=preprocess)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "dataset = {\n",
    "    'names': list(dataset_files.keys()),\n",
    "    'classes': [], # MUST FILL IN\n",
    "    'class_weights': {name: None for name in dataset_files.keys()},\n",
    "    'ids' : {},\n",
    "    'gens': {},\n",
    "    'data': {},\n",
    "    'coco': {}\n",
    "}\n",
    "print(\"Combinations of labels present\")\n",
    "\n",
    "def annotation_filter(ann):\n",
    "    if 'segmentation' not in ann:\n",
    "        return False\n",
    "    if ('annotation_type' in ann) and (ann['annotation_type'] == 'point'):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "for name, path in dataset_files.items():\n",
    "    coco = SegmentationDataset(path, image_dims)\n",
    "    coco.annotation_filter = annotation_filter\n",
    "    ids = list(balanced_set(coco)) if use_balanced_set else coco.image_ids\n",
    "#     if name in ['test']:\n",
    "#         ids = ids[::4] #TODO: REMOVE AFTER TESTING\n",
    "#     if name in ['train']:\n",
    "#         ids = ids[::2] #TODO: REMOVE AFTER TESTING\n",
    "    gen = pipeline(\n",
    "        coco.generator(imgIds=ids, shuffle_ids=True),\n",
    "        coco.num_classes, aug_config if name == 'train' else None)\n",
    "    print(\"{:s}: {:d} images\".format(name, len(ids)))\n",
    "    dataset['coco'][name] = coco\n",
    "    dataset['ids'][name] = ids\n",
    "    dataset['gens'][name] = gen\n",
    "    \n",
    "    if use_cached:\n",
    "        expected_size = 4 * len(ids) * np.product(image_dims)\n",
    "        print(\"Caching {:s} set will take {:.1f} GB\".format(name, expected_size / 1024 ** 3))\n",
    "        dataset['data'][name] = [\n",
    "            np.zeros((len(ids),) + image_dims, dtype=np.float32),\n",
    "            np.zeros((len(ids),) + image_dims[0:2] + (coco.num_classes,), dtype=np.float32)]\n",
    "        \n",
    "#         dataset['data'][name] = gen_dump_data(gen, len(ids))\n",
    "        def procedure(a):\n",
    "            idx, img_id = a\n",
    "            image, caption = preprocess(coco.load_image(img_id), coco.load_segmentation(img_id))\n",
    "#             caption = set_to_multihot({caption_map[i] for i in caption if i in captions}, coco.num_classes)\n",
    "            return idx, img_id, image, caption\n",
    "        \n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            for idx, img_id, image, segm in executor.map(procedure, enumerate(ids)):\n",
    "                dataset['data'][name][0][idx] = image\n",
    "                dataset['data'][name][1][idx] = np.array(segm)\n",
    "        print(\"Dataset {:s} has {:d} classes\".format(name, dataset['data'][name][1].shape[-1]))\n",
    "    \n",
    "\n",
    "def data_source(name):\n",
    "    if dataset['data'] and name in dataset['data']:\n",
    "        return dataset['data'][name]\n",
    "    return dataset['gens'][name]\n",
    "\n",
    "def data_sample(name, size=None):\n",
    "    source = data_source(name)\n",
    "    if isinstance(source, list):\n",
    "        if dataset['data'][name]:\n",
    "            idx = np.random.choice(np.arange(dataset['data'][name][0].shape[0]), size=size)\n",
    "            images = dataset['data'][name][0][idx]\n",
    "            labels = dataset['data'][name][1][idx]\n",
    "#             if size == None:\n",
    "#                 images, labels = images[0], labels[0]\n",
    "            return images, labels\n",
    "    for image, label in source:\n",
    "        return image, label\n",
    "# print(np.unique(\n",
    "#     [i \n",
    "#      for image in coco_train.imgs.values()\n",
    "#     for i in coco_train.load_caption(image['id'])]\n",
    "# ))\n",
    "\n",
    "dataset['classes'] = sorted([cat['id'] for cat in dataset['coco']['train'].cats.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import label2rgb\n",
    "plt.figure()\n",
    "num_rows = 3\n",
    "print(\"Left to right: ground truth samples from \", end='')\n",
    "for j in range(num_rows):\n",
    "    for i, name in enumerate(dataset['names']):\n",
    "        plt.subplot(num_rows, 3, 3 * j + i + 1)\n",
    "        image, target = data_sample(name, None)\n",
    "#         print(image.dtype, image.shape, target.shape)\n",
    "        plt.imshow(label2rgb(target.argmax(axis=2), postprocess(image, target), alpha=0.2))\n",
    "#         plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(label)]))\n",
    "        print(name, end=', ')\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell intentionally left blank due to display bug above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "###################\n",
    "def label_encoding(y, mode):\n",
    "    if mode == 'multihot':\n",
    "        return np.argwhere(y)[:, 1]\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    #   return np.sum(y * (2 ** np.arange(y.shape[1])[::-1]), axis=1)\n",
    "\n",
    "def noop(args, **kwargs):\n",
    "    return args\n",
    "    \n",
    "\n",
    "if use_class_weights:\n",
    "    for name, coco in dataset['coco'].items():\n",
    "        print(\"{:s} {:s} class stats {:s}\".format('=' * 8, name, '=' * 8))\n",
    "        labels = [coco.load_caption(image['id'])\n",
    "                  for image in coco.imgs.values() if image['id'] in dataset['ids'][name]]\n",
    "        y = [l for fields in labels for l in fields]\n",
    "        print(np.unique(y), dataset['classes'])\n",
    "        count = np.array(list(dict(sorted(Counter(y).items(), key=lambda x: x[0])).values()))\n",
    "        spread = {i: float(v.round(2)) for i, v in enumerate(count / np.sum(count))}\n",
    "        print(sum([i not in dataset['classes'] for i in y]))\n",
    "        class_weights = compute_class_weight('balanced', dataset['classes'], y)\n",
    "        class_weights = {i: float(np.round(v, 3)) for i, v in enumerate(class_weights)}\n",
    "        dataset['class_weights'][name] = class_weights\n",
    "        a = np.array(list(dataset['class_weights'][name].values()))\n",
    "        \n",
    "        print(\"class weights:\".format(name))\n",
    "        print(\" \", class_weights)\n",
    "        trivial = np.mean(a / np.max(a))\n",
    "        print(\"trivial result accuracy:\\n  {:.2f} or {:.2f}\".format(trivial, 1-trivial))\n",
    "        print(\"class cover fractions:\\n  \", spread )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abyss_deep_learning.keras.utils import batching_gen, gen_dump_data\n",
    "\n",
    "num_val_data = len(dataset['ids']['val'])\n",
    "if use_cached:\n",
    "    print(\"use_cached\")\n",
    "    test_data = dataset['data']['test']\n",
    "    val_data = dataset['data']['val']\n",
    "else:\n",
    "    val_data = gen_dump_data(dataset['gens']['val'], num_val_data)\n",
    "    test_data = gen_dump_data(dataset['gens']['test'], len(dataset['ids']['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(object):\n",
    "    def __init__(self):\n",
    "        self.batch_size = 2\n",
    "        self.model_parallel = None\n",
    "        self.has_crf = False\n",
    "    \n",
    "    def get_train_model(self):\n",
    "        return self.model_parallel or self.model\n",
    "        \n",
    "    def plot_test(self, gen, output_fn=np.argmax):\n",
    "        for i, (rgb, target) in enumerate(gen):\n",
    "            print(\"rgb.shape\", rgb.shape)\n",
    "            print(\"rgb min/max\", np.min(rgb), np.max(rgb))\n",
    "            print(\"target.shape\", target.shape)\n",
    "            print(\"target min/max\", np.min(target), np.max(target))\n",
    "\n",
    "            rgb8 = ((rgb + 1) / 2 * 255).astype(np.uint8)\n",
    "            Y_pred = self.model.predict(rgb[np.newaxis, ...])\n",
    "            plt.figure()\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(rgb8)\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(label2rgb(target[ ..., 1], rgb8, bg_label=-1))\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.imshow(Y_pred[0, ..., 0])\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.imshow(label2rgb(np.argmax(Y_pred[0], axis=-1), rgb8, bg_label=0))\n",
    "            plt.title(\"CRF IoU={:.2f}\".format(\n",
    "                jaccard_index(output_fn(target, axis=-1), np.argmax(Y_pred[0], axis=-1))))\n",
    "            plt.tight_layout()\n",
    "            break\n",
    "\n",
    "    def init_crf(self):\n",
    "        crf_params = ['crfrnn/spatial_ker_weights:0',\n",
    "                  'crfrnn/bilateral_ker_weights:0',\n",
    "                  'crfrnn/compatibility_matrix:0']\n",
    "        self.model.set_weights([\n",
    "            np.eye(2), np.eye(2), 1 - np.eye(2)\n",
    "        ])\n",
    "        \n",
    "    def create_model(self, num_classes, image_dims, upsample='new', num_iterations=0):\n",
    "        '''\n",
    "        crf can be one of 'new', 'load', 'train' or 'none'\n",
    "        upsample can be one of 'new', 'load' or 'train\n",
    "        '''\n",
    "        self.has_crf = num_iterations > 0\n",
    "        self.model = None\n",
    "        self.model_parallel = None\n",
    "        K.clear_session()\n",
    "        print(\"Making model with {:d} classes and {} input shape\".format(num_classes, str(image_dims)))\n",
    "        self.model = get_crfrnn_model_def(\n",
    "            num_classes=(num_classes + 1), input_shape=image_dims,\n",
    "            num_iterations=num_iterations, with_crf=self.has_crf)\n",
    "        if upsample in ['bilinear', 'train']:\n",
    "            initialize_conv_transpose2d(\n",
    "                self.model,\n",
    "                ['score2', 'score4', 'upsample'],\n",
    "                trainable=True)\n",
    "        if self.has_crf:\n",
    "            init_crf(self.model.get_layer(name='crfrnn'))\n",
    "            \n",
    "    def load_model(self, model_path):\n",
    "        if model_path: \n",
    "            self.model.load_weights(model_path, by_name=True)\n",
    "        if self.has_crf:\n",
    "            init_crf(self.model.get_layer(name='crfrnn'))\n",
    "\n",
    "    def compile_model(self, train_layers=None, parallel=False):\n",
    "        if train_layers:\n",
    "            for layer in self.model.layers:\n",
    "                layer.trainable = layer.name in train_layers\n",
    "        if parallel:\n",
    "            from keras.utils import multi_gpu_model\n",
    "            self.model_parallel = multi_gpu_model(self.model, gpus=2)#, cpu_merge=True, cpu_relocation=False)\n",
    "        self.get_train_model().compile(optimizer='nadam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    def train(self, epochs, initial_epoch=0, val_data=None):\n",
    "        steps_per_epoch = len(dataset['ids']['train']) // self.batch_size\n",
    "        steps_per_epoch_val = 100 // self.batch_size #len(dataset['ids']['val']) // batch_size\n",
    "        print(\"Steps per epoch:\", steps_per_epoch)\n",
    "        print(\"Steps per steps_per_epoch_val:\", steps_per_epoch_val)\n",
    "\n",
    "        source = data_source('train')\n",
    "        common = {\n",
    "            \"class_weight\": dataset['class_weights']['train'],\n",
    "            \"callbacks\": self.callbacks,\n",
    "            \"epochs\": epochs,\n",
    "            \"verbose\": 1,\n",
    "            \"initial_epoch\": initial_epoch,\n",
    "#             \"steps_per_epoch\": steps_per_epoch\n",
    "        }\n",
    "        if isinstance(source, list): # Cached data\n",
    "            print(\"Training cached data\")\n",
    "            self.history = self.get_train_model().fit(\n",
    "                x=source[0], y=source[1],\n",
    "                batch_size=self.batch_size,\n",
    "                validation_data=tuple(data_source('val')),\n",
    "                shuffle=True,\n",
    "                **common)\n",
    "        elif val_data:\n",
    "            # Generator training with static val data\n",
    "            self.history = self.get_train_model().fit_generator(\n",
    "                batching_gen(source, batch_size=exp.batch_size),\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=steps_per_epoch_val,\n",
    "                validation_data=val_data,\n",
    "                workers=10,\n",
    "                **common)\n",
    "        else:\n",
    "            self.history = self.get_train_model().fit_generator(\n",
    "                batching_gen(source, batch_size=exp.batch_size),\n",
    "                validation_data=batching_gen(\n",
    "                    data_source('val'), batch_size=exp.batch_size),\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=steps_per_epoch_val,\n",
    "                workers=10,\n",
    "                **common)\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First train only Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imagenet_weights = \"~/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "logdir = os.path.join(\"/data/log/fcn-crfrnn/test-swc/{:04d}\".format(np.random.randint(0, 9999)))\n",
    "!mkdir -p \"$logdir/models\"\n",
    "best_path = os.path.join(logdir, \"models/best.{epoch:03d}-{val_loss:.4f}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = None\n",
    "K.clear_session()\n",
    "exp = Experiment()\n",
    "exp.create_model(\n",
    "    len(dataset['classes']), image_dims,\n",
    "    upsample='train',\n",
    "    num_iterations=0)\n",
    "exp.batch_size = 4\n",
    "exp.load_model(imagenet_weights)\n",
    "\n",
    "layers = [layer.name for layer in exp.model.layers]\n",
    "train_layers = layers[layers.index('fc6'):]\n",
    "\n",
    "exp.compile_model(train_layers=train_layers, parallel=parallel)\n",
    "exp.callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, cooldown=5, verbose=1),\n",
    "        ModelCheckpoint(\n",
    "            best_path, monitor='val_loss', verbose=1,\n",
    "            save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "        TensorBoard(\n",
    "            log_dir=logdir, histogram_freq=0, batch_size=8,\n",
    "            write_graph=False, write_grads=False, write_images=False),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss', min_delta=0.0, patience=10, verbose=1, mode='auto')\n",
    "]\n",
    "# Test to see if LR causes loss explosion\n",
    "K.set_value(exp.get_train_model().optimizer.lr, 1e-4)\n",
    "try:\n",
    "    exp.train(200, val_data=val_data)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "except:\n",
    "    raise\n",
    "# Save the weights and epoch for next training step\n",
    "initial_epoch = exp.callbacks[3].stopped_epoch + 1 if exp.callbacks[3].stopped_epoch else 16\n",
    "initial_lr = K.eval(exp.get_train_model().optimizer.lr)\n",
    "exp.model.save_weights('/data/tmp/blah_weights.h5')\n",
    "# raise RuntimeError(\"Stop Run All\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save weights, reload and train all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "exp = Experiment()\n",
    "exp.create_model(\n",
    "    len(dataset['classes']), image_dims,\n",
    "    upsample='train',\n",
    "    num_iterations=0)\n",
    "exp.batch_size = 4\n",
    "exp.model.load_weights('/data/tmp/blah_weights.h5')\n",
    "\n",
    "layers = [layer.name for layer in exp.model.layers]\n",
    "train_layers = None #layers[layers.index('block2_conv1'):]\n",
    "exp.compile_model(train_layers=train_layers, parallel=parallel)\n",
    "\n",
    "exp.callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, cooldown=10, verbose=1),\n",
    "        ModelCheckpoint(\n",
    "            best_path, monitor='val_loss', verbose=1,\n",
    "            save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "        TensorBoard(\n",
    "            log_dir=logdir, histogram_freq=5, batch_size=8,\n",
    "            write_graph=False, write_grads=False, write_images=False),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss', min_delta=0.0, patience=20, verbose=1, mode='auto')\n",
    "]\n",
    "\n",
    "K.set_value(exp.get_train_model().optimizer.lr, initial_lr)\n",
    "try:\n",
    "    exp.train(200, val_data=val_data, initial_epoch=initial_epoch)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_test(dataset['gens']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "y_pred = exp.model.predict(x=test_data[0], batch_size=exp.batch_size)\n",
    "ap_micro = average_precision_score(\n",
    "    test_data[1][..., 1:].reshape((-1, test_data[1].shape[-1] - 1)),\n",
    "    y_pred[..., 1:].reshape((-1, test_data[1].shape[-1] - 1)),\n",
    "    average='micro')\n",
    "print(\"Micro average precision of FG classes is {:.4f}\".format(ap_micro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Trained Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN Upsample Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at upsampling weights\n",
    "layer_names = ['score2', 'score4', 'upsample']\n",
    "for name in layer_names:\n",
    "    layer = exp.model.get_layer(name=name)\n",
    "    v = layer.get_weights()[0]\n",
    "    print(v.shape)\n",
    "    plt.figure()\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(v[:, :, 0, 0])\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(v[:, :, 0, 1])\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(v[:, :, 1, 0])\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(v[:, :, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.get_train_model().get_layer(name='crfrnn').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
