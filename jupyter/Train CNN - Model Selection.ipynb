{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.applications.imagenet_utils import _IMAGENET_MEAN\n",
    "# from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "# from keras.applications.mobilenet import preprocess_input, MobileNet\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import Nadam\n",
    "from pycocotools.coco import COCO\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "from abyss_deep_learning.keras.classification import (\n",
    "    ClassificationDataset, caption_map_gen, onehot_gen, augmentation_gen, PRTensorBoard)\n",
    "from abyss_deep_learning.keras.utils import batching_gen, lambda_gen\n",
    "import abyss_deep_learning.abyss_dataset as dataset_model\n",
    "from herbicide.utils import vis_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### CONFIGURE THIS ########################\n",
    "# num_classes assumed from caption_map entries\n",
    "# image_dims = (224, 224, 3) # Preset for Mobilenet\n",
    "image_dims = (299, 299, 3) # Preset for InceptionV3\n",
    "batch_size = 4\n",
    "NN_DTYPE = np.float32\n",
    "\n",
    "# maps caption strings to class numbers (ensure minimal set of class numbers)\n",
    "# eg use {0, 1, 2} not {4, 7, 8}\n",
    "\n",
    "# Caption type can be either \"single\" or \"multi\".\n",
    "# This sets up various parameters in the system.\n",
    "# If conversion between single and multi is required this should be done explicitly and presented\n",
    "# in a separate json file. The internal representation of all the labels is one-hot encoding.\n",
    "caption_type = \"multi\" \n",
    "caption_map = {\n",
    "    \"IP\": 0,\n",
    "    \"JD_ML\": 1,\n",
    "    \"DD\": 2,\n",
    "    \"JD_S\": 3,\n",
    "    \"ED_All\": 4\n",
    "}\n",
    "# caption_map = {\n",
    "#     'f': 1,\n",
    "#     's': 0\n",
    "# }\n",
    "coco_train = ClassificationDataset(caption_map, \"/data/abyss/projectmax/feature-detection/2/all2_train.json\")\n",
    "coco_val = ClassificationDataset(caption_map, \"/data/abyss/projectmax/feature-detection/2/all2_val.json\")\n",
    "coco_test = ClassificationDataset(caption_map, \"/data/abyss/projectmax/feature-detection/2/all2_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert instances to categories\n",
    "# from abyss_deep_learning.coco_classes import CocoDataset\n",
    "# ds = CocoDataset.from_COCO(coco_train)\n",
    "# ds.convert_instances_to_captions()\n",
    "# ds.save(\"/data/abyss/projectmax/feature-detection/2/training2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_map_r = {val: key for key, val in caption_map.items()}\n",
    "num_classes = len(caption_map)\n",
    "steps_per_epoch = coco_train.num_images() // batch_size\n",
    "steps_per_epoch_val = coco_val.num_images() // batch_size\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Steps per epoch:\", steps_per_epoch)\n",
    "print(\"Steps per steps_per_epoch_val:\", steps_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, caption):\n",
    "    image = resize(image, image_dims, preserve_range=True)\n",
    "    return preprocess_input(image.astype(NN_DTYPE), mode='tf'), caption\n",
    "\n",
    "def postprocess(image):\n",
    "    return ((image + 1) * 127.5).astype(np.uint8)\n",
    "\n",
    "def cast_dtype_gen(gen, input_dtype, target_dtype):\n",
    "    for inputs, targets in gen:\n",
    "        yield inputs.astype(input_dtype), targets.astype(target_dtype)\n",
    "\n",
    "def pipeline(gen, aug_config=None):\n",
    "    return (\n",
    "        augmentation_gen(\n",
    "            onehot_gen(\n",
    "                lambda_gen(\n",
    "                    caption_map_gen(gen, caption_map, background='background', skip_bg=True)\n",
    "                , func=preprocess)\n",
    "            , num_classes=num_classes)\n",
    "        , aug_config, enable=(aug_config is not None))\n",
    "    )\n",
    "\n",
    "def augmentation_gen(gen, aug_config, enable=True):\n",
    "    '''\n",
    "    Data augmentation for classification task.\n",
    "    Target is untouched.\n",
    "    '''\n",
    "    if not enable:\n",
    "        while True:\n",
    "            yield from gen\n",
    "    aug_list = []\n",
    "    if 'flip_lr_percentage' in aug_config:\n",
    "        aug_list += [iaa.Fliplr(aug_config['flip_lr_percentage'])]\n",
    "    if 'flip_ud_percentage' in aug_config:\n",
    "        aug_list += [iaa.Flipud(aug_config['flip_ud_percentage'])]\n",
    "    if 'affine' in aug_config:\n",
    "        aug_list += [iaa.Affine(**aug_config['affine'])]\n",
    "#     if 'color' in aug_config: #  Color aug not working  yet\n",
    "#         aug_list += [iaa.Sometimes(\n",
    "#             aug_config['color']['probability'], iaa.Sequential([\n",
    "#             iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "#             iaa.WithChannels(0, iaa.Add(aug_config['color']['hue'])),\n",
    "#             iaa.WithChannels(1, iaa.Add(aug_config['color']['saturation'])),\n",
    "#             iaa.WithChannels(2, iaa.Add(aug_config['color']['value'])),\n",
    "#             iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\")\n",
    "#         ]))]\n",
    "    seq = iaa.Sequential(aug_list)\n",
    "    for image, target in gen:\n",
    "        yield seq.augment_image(image), target\n",
    "        \n",
    "aug_config = {\n",
    "    'flip_lr_percentage': 0.5,\n",
    "    'flip_ud_percentage': 0.5,\n",
    "    'affine': {\n",
    "        \"order\": 1,\n",
    "        'scale': {\n",
    "            \"x\": (0.8, 1.2),\n",
    "            \"y\": (0.8, 1.2)\n",
    "        },\n",
    "        \"rotate\": (-10, 10),\n",
    "        \"shear\": (-5, 5),\n",
    "        \"mode\": 'constant'\n",
    "    },\n",
    "#     'color': {\n",
    "#         'probability': 1.00,\n",
    "#         'hue': (0, 0),\n",
    "#         'saturation': (0, 0),\n",
    "#         'value': (0, 0)\n",
    "#     }\n",
    "}\n",
    "# aug_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = pipeline(\n",
    "    coco_train.generator(shuffle_ids=True),\n",
    "    aug_config=aug_config)\n",
    "val_gen = pipeline(coco_val.generator(shuffle_ids=True))\n",
    "test_gen = pipeline(coco_test.generator(shuffle_ids=True))\n",
    "    \n",
    "for i, (train, val, test) in enumerate(zip(train_gen, val_gen, test_gen)):\n",
    "    for data in (train, val, test):\n",
    "        print(data[0].shape, data[1], (np.min(data[0]), np.max(data[0])))\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(postprocess(train[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(train[1])]))\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(postprocess(val[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(val[1])]))\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(postprocess(test[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(test[1])]))\n",
    "    \n",
    "    if i >= 0:\n",
    "        break\n",
    "print(\"Left to right: ground truth samples from train, val test\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dump_data(gen, num_images):\n",
    "    data = [[],[]]\n",
    "    for i, (image, caption) in enumerate(gen):\n",
    "        data[0].append(image)\n",
    "        data[1].append(caption)\n",
    "        if i >= num_images:\n",
    "            break\n",
    "    data = (\n",
    "        np.concatenate([i[np.newaxis, ...] for i in data[0]], axis=0),\n",
    "        np.concatenate([i[np.newaxis, ...] for i in data[1]], axis=0)\n",
    "    )\n",
    "    return data\n",
    "\n",
    "def count_labels_single(data):\n",
    "    return Counter([int(j) for i in data[1] for j in np.argwhere(i)])\n",
    "\n",
    "def count_labels_multi(data):\n",
    "    values = np.sum(data[1], axis=0).tolist()\n",
    "    keys = np.arange(len(values))\n",
    "    return dict(zip(keys, values))\n",
    "\n",
    "def calc_class_weights(gen, coco):\n",
    "    data = gen_dump_data(gen, coco.num_images())\n",
    "    counts = count_function(data)\n",
    "    class_weights =  np.array([j for i, j in sorted(counts.items(), key=lambda x: x[0])], dtype=NN_DTYPE)\n",
    "    class_weights /= np.max(class_weights)\n",
    "    class_weights = dict(zip(sorted(counts.keys()), class_weights.tolist()))\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_function = count_labels_single if caption_type == \"single\" else count_labels_multi\n",
    "\n",
    "for label, gen, coco in zip(\n",
    "        [\"train\", \"val\", \"test\"],\n",
    "        [train_gen, val_gen, test_gen],\n",
    "        [coco_train, coco_val, coco_test]):\n",
    "    data = gen_dump_data(gen, coco.num_images())\n",
    "    counter = count_function(data)\n",
    "    print(label, counter)\n",
    "\n",
    "val_data = gen_dump_data(val_gen, coco_val.num_images())\n",
    "class_weights = calc_class_weights(train_gen, coco_train)\n",
    "print(\"training class weights:\")\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.initializers\n",
    "import keras.regularizers\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D, ZeroPadding2D, Dropout, BatchNormalization, Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_head(\n",
    "    base_model, num_classes, caption_type,\n",
    "    pooling=None, num_hidden_neurons=1024, num_hidden_layers=2,\n",
    "    dropout=None,\n",
    "    train_features=False, opt_params={}, l2_reg=None):\n",
    "    '''make sure base_model has include_top=False'''\n",
    "\n",
    "    global model_name    \n",
    "    \n",
    "    model_name += \"_P\" + str(pooling).lower()\n",
    "    model_name += \"_L{:d}_U{:d}\".format(num_hidden_layers, num_hidden_neurons)\n",
    "    \n",
    "    if not opt_params:\n",
    "        opt_params = {\"optimizer\": \"Nadam\"}\n",
    "    \n",
    "    if caption_type == \"single\":\n",
    "        opt_params['loss'] = \"categorical_crossentropy\" \n",
    "    elif caption_type == \"multi\":\n",
    "        weights = np.array([i[1] for i in sorted(class_weights.items())])[np.newaxis, ...] \\\n",
    "            if class_weights else 1.0\n",
    "        opt_params['loss'] = binary_crossentropy #lambda y_true, y_pred: \\\n",
    "        \n",
    "    activation = \"softmax\" if caption_type == \"single\" else \"sigmoid\"\n",
    "    \n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    \n",
    "    if pooling == 'avg':\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "    elif pooling == 'max':\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "    else:\n",
    "        x = Flatten()(x)\n",
    "    for i in range(num_hidden_layers):\n",
    "        x = Dense(num_hidden_neurons, activation='relu', \n",
    "                  kernel_initializer=keras.initializers.he_uniform())(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "    predictions = Dense(\n",
    "        num_classes,\n",
    "        activation=activation,\n",
    "        kernel_initializer=keras.initializers.he_uniform(),\n",
    "        name='class_logits')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    for layer in model.layers[11:]: # keep first 3 layers of conv\n",
    "        layer.trainable = train_features\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    \n",
    "    if l2_reg:\n",
    "        for layer in model.layers[11:]:\n",
    "            if not layer.trainable:\n",
    "                continue\n",
    "            if hasattr(layer, 'kernel_regularizer'):\n",
    "                layer.activity_regularizer = keras.regularizers.l2(l2_reg)\n",
    "                layer.kernel_initializer = keras.initializers.he_uniform()\n",
    "#             if hasattr(layer, 'activity_regularizer'):\n",
    "#                 layer.activity_regularizer = keras.regularizers.l1(l2_reg)\n",
    "    \n",
    "    print(\"Compiling model:\")\n",
    "    print(\"   l2 reg :\", l2_reg)\n",
    "    print(\"   activation:\", activation)\n",
    "    print(\"   optimizer:\", opt_params)\n",
    "    model.compile(**opt_params, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(model):\n",
    "    def multi_label_decision(y_true, y_pred, thresh=0.5):\n",
    "        return (y_true > thresh) == (y_pred > thresh)\n",
    "    def single_label_decision(y_true, y_pred):\n",
    "        return np.argmax(y_true, axis=-1) == np.argmax(y_pred, axis=-1)\n",
    "\n",
    "    decision_function = single_label_decision if caption_type == 'single' else multi_label_decision\n",
    "    thresh = 0.5 # Used for multi-label decisions\n",
    "\n",
    "    test_data = gen_dump_data(test_gen, coco_test.num_images())\n",
    "    Y_true = test_data[1]\n",
    "    Y_pred = model.predict(test_data[0])\n",
    "    TP = decision_function(Y_true, Y_pred)\n",
    "    test_accuracy = accuracy_score(Y_true.astype(np.bool), Y_pred > thresh)\n",
    "    print(\"Test accuracy for {:d} samples: {:.2f}\".format(len(test_data[0]), test_accuracy))\n",
    "    # for i, (image, true_caption, pred_caption) in enumerate(zip(test_data[0], test_data[1], Y_pred)):\n",
    "    #     if i % 4 == 0:\n",
    "    #         if i > 0:\n",
    "    #             plt.tight_layout()\n",
    "    #         if i >= 4:\n",
    "    #             break\n",
    "    #         if i < len(test_data[0]):\n",
    "    #             plt.figure()\n",
    "    #     plt.subplot(2, 2, 1 + (i % 4))\n",
    "    #     plt.imshow(postprocess(image))\n",
    "    #     plt.title(\"T: {:s}; P: {:s}\".format(\n",
    "    #         ', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(true_caption > thresh)]),\n",
    "    #         ', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(pred_caption > thresh)])\n",
    "    #     ))\n",
    "    test_metrics = model.evaluate(test_data[0], test_data[1])\n",
    "    print(\"test_metrics\", test_metrics)\n",
    "    print(TP.sum(axis=0) / Y_true.sum(axis=0))\n",
    "    return Y_true, Y_pred, TP, test_metrics\n",
    "\n",
    "def display_performance(Y_true, Y_pred, TP):\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(num_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(Y_true[:, i],\n",
    "                                                            Y_pred[:, i])\n",
    "        average_precision[i] = average_precision_score(Y_true[:, i], Y_pred[:, i])\n",
    "\n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_true.ravel(),\n",
    "        Y_pred.ravel())\n",
    "    average_precision[\"micro\"] = average_precision_score(Y_true, Y_pred,\n",
    "                                                         average=\"micro\")\n",
    "    print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "          .format(average_precision[\"micro\"]))\n",
    "    print(\"Accuracy:\", accuracy_score(Y_true, Y_pred > 0.5))\n",
    "    \n",
    "    # setup plot details\n",
    "    colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "    lines = []\n",
    "    labels = []\n",
    "    for f_score in f_scores:\n",
    "        x = np.linspace(0.01, 1)\n",
    "        y = f_score * x / (2 * x - f_score)\n",
    "        l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "        plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "    lines.append(l)\n",
    "    labels.append('iso-f1 curves')\n",
    "    l, = plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('micro-average Precision-recall (area = {0:0.2f})'\n",
    "                  ''.format(average_precision[\"micro\"]))\n",
    "\n",
    "    for i, color in zip(range(num_classes), colors):\n",
    "        l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n",
    "        lines.append(l)\n",
    "        labels.append('{0} (area = {1:0.2f})'\n",
    "                      ''.format(caption_map_r[i], average_precision[i]))\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.subplots_adjust(bottom=0.25)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Micro Average Precision vs. Recall')\n",
    "    plt.legend(lines, labels, loc=(0, -.4), prop=dict(size=14))\n",
    "    plt.show()\n",
    "    plt.savefig(model_plot_path, dpi=150)\n",
    "    \n",
    "def save_model(model, name, class_map_r, prediction_type,\n",
    "               model_weights_path, model_def_path, model_info_path, history,\n",
    "               test_metrics=None, description=\"\"):\n",
    "    from abyss.utils import JsonNumpyEncoder\n",
    "    def merged(a, b):\n",
    "        merged = dict(a)\n",
    "        merged.update(b)\n",
    "        return merged\n",
    "        \n",
    "    model_info = {\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"weights\": model_weights_path,\n",
    "        \"prediction_type\": caption_type,\n",
    "        \"model\": model_def_path,\n",
    "        \"classes\": class_map_r,\n",
    "        \"architecture\": {\n",
    "            \"backbone\": \"inceptionv3\",\n",
    "            \"logit_activation\": model.get_layer(\"class_logits\").activation.__name__,\n",
    "            \"input_shape\": image_dims\n",
    "        },\n",
    "        \"metrics\": {\n",
    "            \"loss_function\": str(history.model.loss),\n",
    "            \"train\": merged(\n",
    "                history.history,\n",
    "                {\n",
    "                    \"epoch\": history.epoch,\n",
    "                    \"params\": history.params\n",
    "                })\n",
    "        }\n",
    "    }\n",
    "    if test_metrics:\n",
    "        model_info['metrics']['test'] = test_metrics\n",
    "    \n",
    "    print(\"Writing model def to \" + model_def_path)\n",
    "    with open(model_def_path, \"w\") as file:\n",
    "        file.write(model.to_json())\n",
    "        \n",
    "    print(\"Writing model weights to \" + model_weights_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "    \n",
    "    print(\"Writing model info to \" + model_info_path)\n",
    "    with open(model_info_path, \"w\") as file:\n",
    "        file.write(json.dumps(model_info, cls=JsonNumpyEncoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_resnet(input_shape, weights='imagenet'):\n",
    "    global model_name\n",
    "    model_name = 'model_resnet'\n",
    "    return ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "def test_model(input_shape, dropout=0, activation=None, weights=None):\n",
    "    global model_name\n",
    "    model_name = 'test_model' + ('_' + activation if activation else '')\n",
    "\n",
    "    def unit(x, filters, convs=1):\n",
    "        reg = keras.regularizers.l2(l2) if l2 else None\n",
    "        for i in range(convs):\n",
    "            x = Conv2D(filters, (3, 3),\n",
    "                       kernel_regularizer=reg,\n",
    "                       kernel_initializer=keras.initializers.he_uniform())(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            if activation:\n",
    "                x = Activation(activation)(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "        return x\n",
    "    \n",
    "    x_in = Input(shape=input_shape)\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x_in)\n",
    "    for i, convs in zip(range(3), [3, 2, 1]):\n",
    "        x = unit(x, int(64 * 2 ** i), convs=convs)\n",
    "        x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    model = Model(x_in, x)\n",
    "    return model\n",
    "\n",
    "def test_model_linear(input_shape):\n",
    "    global model_name\n",
    "    model_name = 'test_model_linear'\n",
    "    x_in = Input(shape=input_shape)\n",
    "    x = ZeroPadding2D(padding=(5, 5))(x_in)\n",
    "    x = Conv2D(32, (3, 3), kernel_initializer=keras.initializers.he_uniform())(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), kernel_initializer=keras.initializers.he_uniform())(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), kernel_initializer=keras.initializers.he_uniform())(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(256, (3, 3), kernel_initializer=keras.initializers.he_uniform())(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    model = Model(x_in, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(model, train_features, pooling, dropout, l2_reg, num_hidden_layers, num_hidden_neurons, activation=None):\n",
    "    def default_model():\n",
    "        return test_model(input_shape=image_dims, activation=activation, dropout=dropout)\n",
    "    \n",
    "    if model is None:\n",
    "        model = default_model()\n",
    "    return create_new_head(\n",
    "        model,\n",
    "#         model_resnet(input_shape=image_dims),\n",
    "#         InceptionV3(include_top=False, weights='imagenet', input_shape=image_dims),\n",
    "#         MobileNet(input_shape=image_dims, include_top=False),\n",
    "        num_classes, caption_type,\n",
    "        num_hidden_layers=num_hidden_layers, num_hidden_neurons=num_hidden_neurons,\n",
    "        pooling=pooling, train_features=train_features,\n",
    "        dropout=dropout, l2_reg=l2_reg,\n",
    "        opt_params={'optimizer': Nadam(clipnorm=5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history_data = {}\n",
    "class_weights__ = class_weights\n",
    "for attempt_no in range(200):\n",
    "    model_activation = np.random.choice([None, 'relu'])\n",
    "    learning_rate = 10 ** np.random.uniform(-6, -3)\n",
    "    l2 = 10 ** np.random.uniform(-3, -0.7)\n",
    "    dropout = np.random.uniform(0.1, 0.6)\n",
    "    train_features = True #np.random.choice([True, False])\n",
    "    pooling = np.random.choice(['avg', 'max'])\n",
    "    num_hidden_layers = np.random.choice([1, 2])\n",
    "    num_hidden_neurons = int(2 ** np.floor(np.random.uniform(3, 13)))\n",
    "    \n",
    "    K.clear_session()\n",
    "    model = make_model(\n",
    "        None,\n",
    "        train_features, pooling,\n",
    "        dropout, l2,\n",
    "        num_hidden_layers, num_hidden_neurons, activation=model_activation)\n",
    "    \n",
    "    key = (model_name, float(learning_rate), float(l2 or 0), bool(train_features))\n",
    "    experiment_name = \"{:s}--{:s}--CW{:d}--BS{:d}--LR{:.2e}_sched--reg{:.2e}\".format(\n",
    "        model_name,\n",
    "        'all' if train_features else 'heads',\n",
    "        1 if class_weights__ else 0,\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        l2 or 0)\n",
    "    log_dir = \"/data/log/cnn/fd/wednesday-search/\" + experiment_name\n",
    "    best_path = os.path.join(log_dir, \"models/best.{epoch:03d}-{val_loss:.4f}.h5\")\n",
    "    !mkdir -p $log_dir/models\n",
    "    print(experiment_name)\n",
    "    print(log_dir)\n",
    "    callbacks=[\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=8, cooldown=0, verbose=1),\n",
    "            ModelCheckpoint(\n",
    "                best_path, monitor='val_loss', verbose=1,\n",
    "                save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "            ModelCheckpoint(\n",
    "                best_path, monitor='val_loss', verbose=1,\n",
    "                save_best_only=False, save_weights_only=True, mode='auto', period=20),\n",
    "            PRTensorBoard(\n",
    "                log_dir=log_dir, \n",
    "                histogram_freq=10, batch_size=batch_size,\n",
    "                write_graph=True,\n",
    "                write_grads=True,\n",
    "                write_images=True),\n",
    "#             EarlyStopping(\n",
    "#                 monitor='val_loss', min_delta=0.0, patience=25, verbose=1, mode='auto')\n",
    "    ]\n",
    "    K.set_value(model.optimizer.lr, learning_rate)\n",
    "    history_data[key] = model.fit_generator(\n",
    "        batching_gen(train_gen, batch_size=batch_size),\n",
    "        validation_data=tuple(val_data),\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=steps_per_epoch_val,\n",
    "        class_weight=class_weights__,\n",
    "        callbacks=callbacks, \n",
    "        epochs=50,\n",
    "        verbose=0, initial_epoch=0, workers=10)\n",
    "    \n",
    "    # Fill in the relevant params below    \n",
    "    model_def_path = os.path.join(log_dir, \"model_def.json\")\n",
    "    model_weights_path = os.path.join(log_dir, \"model_weights.h5\")\n",
    "    model_info_path = os.path.join(log_dir, \"model.json\")\n",
    "    model_plot_path = os.path.join(log_dir, \"precision-recall.png\")\n",
    "    (Y_true, Y_pred, TP, test_metrics) = evaluate_model(model)\n",
    "    display_performance(Y_true, Y_pred, TP)\n",
    "    \n",
    "    save_model(\n",
    "        model, name=experiment_name,\n",
    "        class_map_r=caption_map_r, prediction_type=caption_type,\n",
    "        model_weights_path=model_weights_path, model_def_path=model_def_path, model_info_path=model_info_path,\n",
    "        test_metrics=test_metrics, history=history_data[key],\n",
    "        description=\"Test model for 5 FDs\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Search\n",
    "Model must be constant by this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = make_model(\n",
    "    None,\n",
    "    train_features, pooling,\n",
    "    dropout, l2,\n",
    "    num_hidden_layers, num_hidden_neurons)\n",
    "model.save_weights(\"/data/tmp/base.h5\")\n",
    "\n",
    "# train_data = gen_dump_data(train_gen, coco_train.num_images())\n",
    "# history_lr = {}\n",
    "for lr in 10 ** np.random.uniform(-7.85, -6.25, size=3):\n",
    "    model.load_weights(\"/data/tmp/base.h5\")\n",
    "    history = model.fit(\n",
    "        train_data[0], train_data[1],\n",
    "        class_weight=class_weights__, batch_size=batch_size,\n",
    "        validation_data=val_data,\n",
    "        epochs=5, verbose=1)\n",
    "    history_lr[float(lr)] = history.history\n",
    "# del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "lrs = [lr for lr, val  in sorted(history_lr.items(), key=lambda x: x[0])]\n",
    "val_loss = [history['val_loss'][-1] for lr, history  in sorted(history_lr.items(), key=lambda x: x[0])]\n",
    "loss = [history['val_loss'][-1] for lr, history  in sorted(history_lr.items(), key=lambda x: x[0])]\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogx(lrs, loss, '.')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogx(lrs, val_loss, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training specific model\n",
    "K.set_value(model.optimizer.lr, 3e-4)\n",
    "model.fit_generator(\n",
    "    batching_gen(train_gen, batch_size=batch_size),\n",
    "    validation_data=tuple(val_data),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=steps_per_epoch_val,\n",
    "    class_weight=class_weights__,\n",
    "    callbacks=[\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=6, cooldown=2, verbose=1),\n",
    "            ModelCheckpoint(\n",
    "                best_path, monitor='val_loss', verbose=1,\n",
    "                save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "            ModelCheckpoint(\n",
    "                best_path, monitor='val_loss', verbose=1,\n",
    "                save_best_only=False, save_weights_only=True, mode='auto', period=20),\n",
    "            PRTensorBoard(\n",
    "                log_dir=log_dir, \n",
    "                histogram_freq=0, batch_size=batch_size,\n",
    "                write_graph=True,\n",
    "                write_grads=False,\n",
    "                write_images=False),\n",
    "    ], \n",
    "    epochs=200,\n",
    "    verbose=1, initial_epoch=80, workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(Y_true, Y_pred, TP, test_metrics) = evaluate_model(model)\n",
    "display_performance(Y_true, Y_pred, TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{caption_map_r[i]:v for i, v in class_weights__.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TP_mask = np.logical_and.reduce(TP, axis=1)\n",
    "right = test_data[0][TP_mask]\n",
    "wrong = test_data[0][~TP_mask]\n",
    "wrong.shape\n",
    "plt.figure()\n",
    "vis_square(wrong)\n",
    "plt.title(\"Incorrectly Predicted\")\n",
    "plt.figure()\n",
    "vis_square(right)\n",
    "plt.title(\"Correctly Predicted\")\n",
    "\n",
    "# Binary coded the labels then count them wrt TP/FP\n",
    "coded = np.sum(test_data[1][~TP_mask] * 2 ** np.arange(num_classes)[::-1], axis=1).astype(int)\n",
    "print(\"binary coded class error count:\", dict(sorted(Counter(coded).items(), key=lambda x: x[0])))\n",
    "coded = np.sum(test_data[1][TP_mask] * 2 ** np.arange(num_classes)[::-1], axis=1).astype(int)\n",
    "print(\"binary coded class correct count:\", dict(sorted(Counter(coded).items(), key=lambda x: x[0])))\n",
    "print(Y_pred[~TP_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model (pretty important!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in history.history.items():\n",
    "    print(key, type(val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# # Fill in the relevant params below    \n",
    "# model_def_path = os.path.join(log_dir, \"model_def.json\")\n",
    "# model_weights_path = os.path.join(log_dir, \"model_weights.h5\")\n",
    "# model_info_path = os.path.join(log_dir, \"model.json\")\n",
    "# model_plot_path = os.path.join(log_dir, \"precision-recall.png\")\n",
    "# (Y_true, Y_pred, TP, test_metrics) = evaluate_model(model)\n",
    "# display_performance(Y_true, Y_pred, TP)\n",
    "# save_model(\n",
    "#     model, name=experiment_name,\n",
    "#     class_map_r=caption_map_r, prediction_type=caption_type,\n",
    "#     model_weights_path=model_weights_path, model_def_path=model_def_path, model_info_path=model_info_path,\n",
    "#     test_metrics=test_metrics, history=history,\n",
    "#     description=\"Model for detecting whether camera is forwards or sidewards facing in a pipe.\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def learning_curve(dataset, lr, steps, val_data, log_dir):\n",
    "    def save_model(path):\n",
    "        print(\"Saving\", path)\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        model.save_weights(path)\n",
    "    def setup_callbacks():\n",
    "        return [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, cooldown=5, verbose=1),\n",
    "                ModelCheckpoint(\n",
    "                    model_best_path, monitor='val_loss', verbose=1,\n",
    "                    save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "#                 ModelCheckpoint(\n",
    "#                     best_path, monitor='val_loss', verbose=1,\n",
    "#                     save_best_only=False, save_weights_only=True, mode='auto', period=50),\n",
    "                PRTensorBoard(\n",
    "                    log_dir=model_log_dir,\n",
    "                    histogram_freq=0,\n",
    "                    batch_size=batch_size,\n",
    "                    write_graph=False,\n",
    "                    write_grads=False,\n",
    "                    write_images=False),\n",
    "        #         EarlyStopping(\n",
    "        #             monitor='val_loss', min_delta=0.0, patience=40, verbose=1, mode='auto')\n",
    "        ]\n",
    "    def create_new_model(load_base=False):\n",
    "        K.clear_session()\n",
    "        model = create_new_head(\n",
    "            InceptionV3(include_top=False, weights='imagenet', input_shape=image_dims),\n",
    "            num_classes, caption_type, opt_params={'optimizer': Nadam()},\n",
    "            class_weights=None, train_features=False, l2_reg=None)\n",
    "        if load_base:\n",
    "            print(\"Loading base model\")\n",
    "            model.load_weights(base_model_path, by_name=True)\n",
    "        return model\n",
    "\n",
    "    def train():\n",
    "        print(\"Training\")\n",
    "        K.set_value(model.optimizer.lr, lr)\n",
    "        history[subset_size] = model.fit_generator(\n",
    "            batching_gen(gen, batch_size=batch_size),\n",
    "            validation_data=tuple(val_data),\n",
    "            steps_per_epoch=(subset_size // batch_size),\n",
    "            validation_steps=steps_per_epoch_val,\n",
    "            class_weight=model_class_weights,\n",
    "            callbacks=setup_callbacks(), \n",
    "            epochs=50,\n",
    "            verbose=1)\n",
    "    model_class_weights = None\n",
    "    model = None\n",
    "    model_path = None\n",
    "    image_ids = [image['id'] for image in dataset.imgs.values()]\n",
    "    np.random.shuffle(image_ids)\n",
    "    num_images = len(image_ids)\n",
    "    print(\"num_images\", num_images)\n",
    "    history = {}\n",
    "    base_model_path = os.path.join(log_dir, \"base\", \"weights.h5\")\n",
    "    model_path = base_model_path\n",
    "    for subset_size in np.linspace(0, num_images, steps + 1).astype(int):\n",
    "        if subset_size > 0:\n",
    "            imgIds = image_ids[:subset_size]\n",
    "            gen = pipeline(\n",
    "                dataset.generator(shuffle_ids=False, imgIds=imgIds),\n",
    "                aug_config=None)\n",
    "            model_class_weights = calc_class_weights(gen, dataset)\n",
    "\n",
    "            model_path = os.path.join(log_dir, \"subset-of-{:d}/weights.h5\".format(subset_size))\n",
    "            model_log_dir = os.path.dirname(model_path)\n",
    "            model_best_path = os.path.join(log_dir, \"subset-of-{:d}/best.h5\".format(subset_size))\n",
    "            os.makedirs(model_log_dir, exist_ok=True)\n",
    "\n",
    "            print(\"learning curve(lr={:.3e}, size={:d})\".format(lr, subset_size))\n",
    "            print(\"model_log_dir\", model_log_dir)\n",
    "            print(\"training class weights\")\n",
    "            print(model_class_weights)\n",
    "        model = create_new_model(load_base=(subset_size > 0))\n",
    "        if subset_size:\n",
    "            train()\n",
    "        save_model(model_path)\n",
    "    return history\n",
    "\n",
    "model = None\n",
    "lr = 1e-5\n",
    "learning_curve_dir = \"/data/log/cnn/fd/learning_curve_5--{:.2e}\".format(lr)\n",
    "lc_history = learning_curve(coco_train, lr, 5, val_data, learning_curve_dir)\n",
    "val_loss = np.array([(size, h.history['val_loss'][-1]) for size, h in lc_history.items()])\n",
    "train_loss = np.array([(size, h.history['loss'][-1]) for size, h in lc_history.items()])\n",
    "plt.figure()\n",
    "plt.plot(train_loss[:, 0], train_loss[:, 1], 'b.')\n",
    "plt.plot(val_loss[:, 0], val_loss[:, 1], 'r.')\n",
    "plt.xlabel(\"Number of Training Samples\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(os.path.join(learning_curve_dir, \"plot.png\"), dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -R /data/log/cnn/fd/learning-curve/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = None\n",
    "for images, labels in batching_gen(train_gen, batch_size=batch_size):\n",
    "    print(images.shape, labels.shape)\n",
    "    \n",
    "    pred = model.predict(images)\n",
    "    print(labels)\n",
    "    print(pred)\n",
    "    print(K.eval(K.tf.losses.sigmoid_cross_entropy(labels, pred)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Update/Weight Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_gradients(model):\n",
    "    \"\"\"Return the gradient of every trainable weight in model\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    model : a keras model instance\n",
    "\n",
    "    First, find all tensors which are trainable in the model. Surprisingly,\n",
    "    `model.trainable_weights` will return tensors for which\n",
    "    trainable=False has been set on their layer (last time I checked), hence the extra check.\n",
    "    Next, get the gradients of the loss with respect to the weights.\n",
    "\n",
    "    \"\"\"\n",
    "    weights = [tensor for tensor in model.trainable_weights \n",
    "               if model.trainable_weights]\n",
    "    optimizer = model.optimizer\n",
    "\n",
    "    return weights, optimizer.get_gradients(model.total_loss, weights)\n",
    "\n",
    "# K.set_value(model.optimizer.lr, 1e-3)\n",
    "# model.fit(images, labels, batch_size=10)\n",
    "weights, grads = get_gradients(model)\n",
    "feed_dict = {\n",
    "    \"class_logits_sample_weights:0\": np.ones(2),\n",
    "    \"input_1:0\": images,\n",
    "    \"class_logits_target:0\": labels\n",
    "}\n",
    "\n",
    "for i, (w, g) in enumerate(zip(weights, grads)):\n",
    "    grad_norm = np.linalg.norm(g.eval(feed_dict, K.get_session()))\n",
    "    weight_norm = np.linalg.norm(w.eval(K.get_session()))\n",
    "    rate = grad_norm / weight_norm\n",
    "    print(i, rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from herbicide.utils import vis_square\n",
    "for layer in model.layers:\n",
    "    if not layer.trainable_weights:\n",
    "        continue\n",
    "    for weight in layer.trainable_weights: #  Assumes FD is not trainable\n",
    "        if 'kernel' not in weight.name:\n",
    "            continue\n",
    "        print(weight.name)\n",
    "        value = K.eval(weight.value())\n",
    "        print(value.shape)\n",
    "    \n",
    "    plt.figure()\n",
    "    vis_square(value.transpose((3, 0, 1, 2)))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
