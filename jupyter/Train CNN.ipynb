{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from collections import Counter\n",
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from pycocotools.coco import COCO\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "from abyss_deep_learning.keras.classification import ClassificationDataset, caption_map_gen, onehot_gen, augmentation_gen\n",
    "from abyss_deep_learning.keras.utils import batching_gen, lambda_gen\n",
    "import abyss_deep_learning.abyss_dataset as dataset_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### CONFIGURE THIS ########################\n",
    "# num_classes assumed from caption_map entries\n",
    "image_dims = (299, 299, 3) # Preset for InceptionV3\n",
    "batch_size = 5\n",
    "log_dir = \"/data/log/cnn/cso-sigmoid\"\n",
    "\n",
    "# maps caption strings to class numbers (ensure minimal set of class numbers)\n",
    "# eg use {0, 1, 2} not {4, 7, 8}\n",
    "caption_map = {\n",
    "    'f': 1,\n",
    "    's': 0\n",
    "}\n",
    "coco_train = ClassificationDataset(caption_map, \"/data/abyss/projectmax/cso/dataset_train.json\")\n",
    "coco_val = ClassificationDataset(caption_map, \"/data/abyss/projectmax/cso/dataset_val.json\")\n",
    "coco_test = ClassificationDataset(caption_map, \"/data/abyss/projectmax/cso/dataset_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_map_r = {val: key for key, val in caption_map.items()}\n",
    "num_classes = len(caption_map)\n",
    "steps_per_epoch = coco_train.num_images() // batch_size\n",
    "steps_per_epoch_val = coco_val.num_images() // batch_size\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Steps per epoch:\", steps_per_epoch)\n",
    "print(\"Steps per steps_per_epoch_val:\", steps_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, caption):\n",
    "    image = resize(image, image_dims, preserve_range=True)\n",
    "    return preprocess_input(image.astype(np.float32)), caption\n",
    "def postprocess(image):\n",
    "    return ((image + 1) * 127).astype(np.uint8)\n",
    "\n",
    "def pipeline(gen, aug_config=None):\n",
    "    return (\n",
    "        augmentation_gen(\n",
    "            onehot_gen(\n",
    "                lambda_gen(\n",
    "                    caption_map_gen(gen, caption_map)\n",
    "                , func=preprocess)\n",
    "            , num_classes=num_classes)\n",
    "        , aug_config, enable=(aug_config is not None))\n",
    "    )\n",
    "\n",
    "def augmentation_gen(gen, aug_config, enable=True):\n",
    "    '''\n",
    "    Data augmentation for classification task.\n",
    "    Target is untouched.\n",
    "    '''\n",
    "    if not enable:\n",
    "        while True:\n",
    "            yield from gen\n",
    "    aug_list = []\n",
    "    if 'flip_lr_percentage' in aug_config:\n",
    "        aug_list += [iaa.Fliplr(aug_config['flip_lr_percentage'])]\n",
    "    if 'flip_ud_percentage' in aug_config:\n",
    "        aug_list += [iaa.Flipud(aug_config['flip_ud_percentage'])]\n",
    "    if 'affine' in aug_config:\n",
    "        aug_list += [iaa.Affine(**aug_config['affine'])]\n",
    "#     if 'color' in aug_config: #  Color aug not working  yet\n",
    "#         aug_list += [iaa.Sometimes(\n",
    "#             aug_config['color']['probability'], iaa.Sequential([\n",
    "#             iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n",
    "#             iaa.WithChannels(0, iaa.Add(aug_config['color']['hue'])),\n",
    "#             iaa.WithChannels(1, iaa.Add(aug_config['color']['saturation'])),\n",
    "#             iaa.WithChannels(2, iaa.Add(aug_config['color']['value'])),\n",
    "#             iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\")\n",
    "#         ]))]\n",
    "    seq = iaa.Sequential(aug_list)\n",
    "    for image, target in gen:\n",
    "        yield seq.augment_image(image), target\n",
    "        \n",
    "aug_config = {\n",
    "    'flip_lr_percentage': 0.5,\n",
    "    'flip_ud_percentage': 0.5,\n",
    "    'affine': {\n",
    "        \"order\": 1,\n",
    "        'scale': {\n",
    "            \"x\": (0.8, 1.2),\n",
    "            \"y\": (0.8, 1.2)\n",
    "        },\n",
    "        \"rotate\": (-10, 10),\n",
    "        \"shear\": (-5, 5),\n",
    "        \"mode\": 'constant'\n",
    "    },\n",
    "#     'color': {\n",
    "#         'probability': 1.00,\n",
    "#         'hue': (0, 0),\n",
    "#         'saturation': (0, 0),\n",
    "#         'value': (0, 0)\n",
    "#     }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = pipeline(\n",
    "    coco_train.generator(shuffle_ids=True),\n",
    "    aug_config=aug_config)\n",
    "val_gen = pipeline(coco_val.generator(shuffle_ids=True))\n",
    "test_gen = pipeline(coco_test.generator(shuffle_ids=True))\n",
    "    \n",
    "for i, (train, val, test) in enumerate(zip(train_gen, val_gen, test_gen)):\n",
    "    print(train[0].shape, train[1])\n",
    "    print(val[0].shape, val[1])\n",
    "    print(test[0].shape, test[1])\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(postprocess(train[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(train[1])]))\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(postprocess(val[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(val[1])]))\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(postprocess(test[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(test[1])]))\n",
    "    \n",
    "    if i >= 0:\n",
    "        break\n",
    "print(\"Left to right: ground truth samples from train, val test\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dump_data(gen, num_images):\n",
    "    data = [[],[]]\n",
    "    for i, (image, caption) in enumerate(gen):\n",
    "        data[0].append(image)\n",
    "        data[1].append(caption)\n",
    "        if i >= num_images:\n",
    "            break\n",
    "    data = (\n",
    "        np.concatenate([i[np.newaxis, ...] for i in data[0]], axis=0),\n",
    "        np.concatenate([i[np.newaxis, ...] for i in data[1]], axis=0)\n",
    "    )\n",
    "    return data\n",
    "\n",
    "def count_labels_multi(data):\n",
    "    return Counter([int(j) for i in data[1] for j in np.argwhere(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gen_dump_data(train_gen, coco_train.num_images())\n",
    "val_data = gen_dump_data(val_gen, coco_val.num_images())\n",
    "test_data = gen_dump_data(test_gen, coco_test.num_images())\n",
    "\n",
    "for label, data in zip(\n",
    "        [\"train\", \"val\", \"test\"],\n",
    "        [train_data, val_data, test_data]):\n",
    "    counter = count_labels_multi(data)\n",
    "    print(label, counter)\n",
    "    \n",
    "train_counts = count_labels_multi(train_data)\n",
    "class_weights =  1 / np.array([j for i, j in sorted(train_counts.items(), key=lambda x: x[0])], dtype=np.float32)\n",
    "class_weights /= np.linalg.norm(class_weights)\n",
    "class_weights = dict(zip(sorted(train_counts.keys()), class_weights.tolist()))\n",
    "print(\"class_weights:\")\n",
    "print(class_weights)\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_head(base_model, num_classes, train_features=False, activation='softmax', opt_params={}):\n",
    "    '''make sure base_model has include_top=False'''\n",
    "    from keras.layers import Dense, MaxPooling2D, Dropout, Flatten\n",
    "    from keras.models import Model\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation=activation, name='class_logits')(x)\n",
    "\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = train_features\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(**opt_params, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTANT:\n",
    "###    When single-label training use a 'softmax' activation and 'categorical_crossentropy' loss\n",
    "###    When multi-label training use a 'sigmoid' activation and 'binary_crossentropy' loss\n",
    "\n",
    "K.clear_session()\n",
    "model = create_new_head(\n",
    "    InceptionV3(\n",
    "        include_top=False, weights='imagenet', input_shape=image_dims),\n",
    "    num_classes, train_features=False, activation='sigmoid',\n",
    "    opt_params={'optimizer': \"Nadam\", 'loss': \"binary_crossentropy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path = os.path.join(log_dir, \"models/best.{epoch:03d}-{val_loss:.4f}.h5\")\n",
    "\n",
    "callbacks=[\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=9, cooldown=6, verbose=1),\n",
    "        ModelCheckpoint(\n",
    "            best_path, monitor='val_loss', verbose=1,\n",
    "            save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "        TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=0,\n",
    "            batch_size=batch_size,\n",
    "            write_graph=False,\n",
    "            write_grads=False,\n",
    "            write_images=False),\n",
    "#         EarlyStopping(\n",
    "#             monitor='val_loss', min_delta=0.0, patience=40, verbose=1, mode='auto')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train with initial LR\n",
    "learning_rate = 1e-4\n",
    "K.set_value(model.optimizer.lr, learning_rate)\n",
    "model.fit_generator(\n",
    "    batching_gen(train_gen, batch_size=batch_size),\n",
    "    validation_data=tuple(val_data),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=steps_per_epoch_val,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks, \n",
    "    epochs=100,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly save model weights (note it is auto saved in the callback)\n",
    "# model.save_weights(\"/tmp/where_you_want_it.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "Y_true = test_data[1]\n",
    "Y_pred = model.predict(test_data[0])\n",
    "TP = (Y_pred > thresh) == (Y_true > thresh)\n",
    "print(\"Test accuracy: {:.2f}\".format(np.count_nonzero(TP) / TP.size))\n",
    "\n",
    "for i, (image, true_caption, pred_caption) in enumerate(zip(test_data[0], test_data[1], Y_pred)):\n",
    "    if i % 4 == 0:\n",
    "        plt.tight_layout()\n",
    "        plt.figure(figsize=(5, 5))\n",
    "#     if i >= 4:\n",
    "#         break\n",
    "    plt.subplot(2, 2, 1 + (i % 4))\n",
    "    plt.imshow(postprocess(image))\n",
    "    plt.title(\"T: {:s}; P: {:s}\".format(\n",
    "        ', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(true_caption > thresh)]),\n",
    "        ', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(pred_caption > thresh)])\n",
    "    ))\n",
    "    print(pred_caption)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
