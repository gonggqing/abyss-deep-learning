{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import cycle\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.layers import (\n",
    "    Flatten, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, Dense, Dropout)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam\n",
    "from pycocotools.coco import COCO\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import keras.backend as K\n",
    "import keras.initializers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from herbicide.utils import vis_square\n",
    "\n",
    "from abyss_deep_learning.keras.classification import (\n",
    "    ClassificationDataset, caption_map_gen, multihot_gen, augmentation_gen, PRTensorBoard, Inference)\n",
    "from abyss_deep_learning.keras.utils import (\n",
    "    batching_gen, lambda_gen, calc_class_weights, count_labels_multi, count_labels_single, gen_dump_data)\n",
    "import abyss_deep_learning.abyss_dataset as dataset_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### CONFIGURE ALL VARIABLES IN THIS CELL ########################\n",
    "# num_classes assumed from caption_map entries\n",
    "# image_dims = (224, 224, 3) # Preset for Mobilenet\n",
    "image_dims = (480, 640, 3) # Preset for InceptionV3\n",
    "batch_size = 2\n",
    "NN_DTYPE = np.float32\n",
    "\n",
    "# maps caption strings to class numbers (ensure minimal set of class numbers)\n",
    "# eg use {0, 1, 2} not {4, 7, 8}\n",
    "\n",
    "# Caption type can be either \"single\" or \"multi\".\n",
    "# This sets up various parameters in the system.\n",
    "# If conversion between single and multi is required this should be done explicitly and presented\n",
    "# in a separate json file. The internal representation of all the labels is one-hot encoding.\n",
    "caption_type = \"multi\" \n",
    "caption_map = {\n",
    "    \"IP\": 0,\n",
    "#     \"JD_ML\": 1,\n",
    "#     \"DD\": 2,\n",
    "#     \"JD_S\": 3,\n",
    "    \"ED\": 1\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class AbyssCaptionTranslator(ClassificationDataset.AnnotationTranslator):\n",
    "    '''Translates the CloudFactory labels into a form that works with this script'''\n",
    "    def filter(self, annotation):\n",
    "        return 'caption' in annotation and 'type' in annotation and annotation['type'] == 'class_labels'\n",
    "    def translate(self, annotation):\n",
    "        return annotation['caption'].split(\",\")\n",
    "translator = AbyssCaptionTranslator()\n",
    "\n",
    "dataset_name = \"ip_ed_fromCF\"\n",
    "coco_train = ClassificationDataset(\n",
    "    caption_map, translator,\n",
    "    \"/data/abyss/projectmax/feature-detection/ip-ed-fromCF/train.json\")\n",
    "coco_val = ClassificationDataset(\n",
    "    caption_map, translator,\n",
    "    \"/data/abyss/projectmax/feature-detection/ip-ed-fromCF/val.json\")\n",
    "coco_test = ClassificationDataset(\n",
    "    caption_map, translator,\n",
    "    \"/data/abyss/projectmax/feature-detection/ip-ed-fromCF/val.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train\", set([tuple(coco_train.load_caption(image['id'])) for image in coco_train.imgs.values()]))\n",
    "print(\"val\", set([tuple(coco_train.load_caption(image['id'])) for image in coco_val.imgs.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Convert instances to categories ####\n",
    "\n",
    "# from abyss_deep_learning.coco_classes import CocoDataset\n",
    "# ds = CocoDataset.from_COCO(coco_val)\n",
    "# ds.convert_instances_to_captions()\n",
    "# ds.save(\"/data/abyss/projectmax/feature-detection/2/validation3.json\")\n",
    "# # coco_val = ClassificationDataset(caption_map, \"/data/abyss/projectmax/feature-detection/2/validation3.json\")\n",
    "# # print(len(coco_train.anns))\n",
    "# # coco_train.anns[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find a balanced set\n",
    "def balanced_set(coco):\n",
    "    captions = [caption \n",
    "            for ann in coco.anns.values() if 'caption' in ann\n",
    "           for caption in ann['caption'].split(',') if caption != \"background\"]\n",
    "    smallest_caption, smallest_caption_value = min(Counter(captions).items(), key=lambda x: x[1])\n",
    "    \n",
    "    unique_captions = np.unique(captions)\n",
    "#     print(\"unique_captions\", unique_captions)\n",
    "    # Count how many images are in each label\n",
    "    images_in_caption = {\n",
    "        caption: [ann['image_id'] for ann in coco.anns.values() if caption in ann['caption'].split(',')]\n",
    "        for caption in unique_captions}\n",
    "    \n",
    "    for images in images_in_caption.values():\n",
    "        np.random.shuffle(images)\n",
    "    \n",
    "    # Count how many captions are in each image\n",
    "    captions_in_image = {\n",
    "        image_id: ([\n",
    "            caption\n",
    "            for ann in coco.anns.values() if ann['image_id'] == image_id and 'caption' in ann\n",
    "            for caption in ann['caption'].split(',') if caption != \"background\"])\n",
    "        for image_id in coco.imgs}\n",
    "    print(\"captions_in_image\")\n",
    "    print([len(captions) for image_id, captions in captions_in_image.items()])\n",
    "    \n",
    "#     print(\"smallest\", smallest_caption, smallest_caption_value)\n",
    "    balanced = []\n",
    "    out = {caption: [] for caption in unique_captions}\n",
    "    \n",
    "    def add_to_counts(image_id):\n",
    "        # Increment counts for all captions in image\n",
    "        for caption in captions_in_image[image_id]:\n",
    "            out[caption].append(image_id)\n",
    "        # Remove image_id from all images_in_caption\n",
    "        for images in images_in_caption.values():\n",
    "            if image_id in images:\n",
    "                images.pop(images.index(image_id))\n",
    "    \n",
    "    while any([len(out[caption]) < smallest_caption_value for caption in unique_captions]):\n",
    "        least = min(out.items(), key=lambda x: len(x[1]))\n",
    "        image_id = images_in_caption[least[0]].pop()\n",
    "        add_to_counts(image_id)\n",
    "        \n",
    "    out = [j\n",
    "           for i in out.values()\n",
    "          for j in i]\n",
    "    return set(out)\n",
    "\n",
    "balanced_image_ids_train = balanced_set(coco_train)\n",
    "balanced_image_ids_val = balanced_set(coco_val)\n",
    "balanced_image_ids_test = balanced_set(coco_test)\n",
    "print(\"balanced train set size\", len(balanced_image_ids_train))\n",
    "print(\"balanced val set size\", len(balanced_image_ids_val))\n",
    "print(\"balanced test set size\", len(balanced_image_ids_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_map_r = {val: key for key, val in caption_map.items()}\n",
    "num_classes = len(caption_map)\n",
    "steps_per_epoch = coco_train.num_images() // batch_size\n",
    "steps_per_epoch_val = coco_val.num_images() // batch_size\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Steps per epoch:\", steps_per_epoch)\n",
    "print(\"Steps per steps_per_epoch_val:\", steps_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, caption):\n",
    "    image = resize(image, image_dims, preserve_range=True)\n",
    "    return preprocess_input(image.astype(NN_DTYPE), mode='tf'), caption\n",
    "\n",
    "def postprocess(image):\n",
    "    return ((image + 1) * 127.5).astype(np.uint8)\n",
    "     \n",
    "def pipeline(gen, aug_config=None):\n",
    "    return (\n",
    "        augmentation_gen(\n",
    "            multihot_gen(\n",
    "                lambda_gen(\n",
    "                    caption_map_gen(gen, caption_map, background='background', skip_bg=True)\n",
    "                , func=preprocess)\n",
    "            , num_classes=num_classes)\n",
    "        , aug_config, enable=(aug_config is not None))\n",
    "    )\n",
    "\n",
    "\n",
    "aug_config = {\n",
    "    'flip_lr_percentage': 0.5,\n",
    "    'flip_ud_percentage': 0.5,\n",
    "    'affine': {\n",
    "        \"order\": 1,\n",
    "        'scale': {\n",
    "            \"x\": (0.8, 1.2),\n",
    "            \"y\": (0.8, 1.2)\n",
    "        },\n",
    "        \"rotate\": (-10, 10),\n",
    "        \"shear\": (-5, 5),\n",
    "        \"mode\": 'constant'\n",
    "    },\n",
    "#     'color': {\n",
    "#         'probability': 1.00,\n",
    "#         'hue': (0, 0),\n",
    "#         'saturation': (0, 0),\n",
    "#         'value': (0, 0)\n",
    "#     }\n",
    "}\n",
    "# aug_config = None # Uncomment to remove augmentation (goes around 50% faster but much worse results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = pipeline(\n",
    "    coco_train.generator(imgIds=list(balanced_image_ids_train), shuffle_ids=True),\n",
    "    aug_config=aug_config)\n",
    "val_gen = pipeline(coco_val.generator(imgIds=list(balanced_image_ids_val), shuffle_ids=True))\n",
    "test_gen = pipeline(coco_test.generator(imgIds=list(balanced_image_ids_test), shuffle_ids=True))\n",
    "    \n",
    "for i, (train, val, test) in enumerate(zip(train_gen, val_gen, test_gen)):\n",
    "    for data in (train, val, test):\n",
    "        print(data[0].shape, data[1], (np.min(data[0]), np.max(data[0])))\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(postprocess(train[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(train[1])]))\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(postprocess(val[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(val[1])]))\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(postprocess(test[0]))\n",
    "    plt.title(', '.join([caption_map_r[int(cap_id)] for cap_id in np.argwhere(test[1])]))\n",
    "    \n",
    "    if i >= 0:\n",
    "        break\n",
    "print(\"Left to right: ground truth samples from train, val test\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell intentionally left blank due to display bug above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_function = count_labels_single if caption_type == \"single\" else count_labels_multi\n",
    "\n",
    "for label, gen, coco, balanced_image_ids in zip(\n",
    "        [\"train\", \"val\", \"test\"],\n",
    "        [train_gen, val_gen, test_gen],\n",
    "        [coco_train, coco_val, coco_test],\n",
    "        [balanced_image_ids_train, balanced_image_ids_val, balanced_image_ids_test]):\n",
    "    data = gen_dump_data(gen, len(balanced_image_ids))\n",
    "    counter = count_function(data)\n",
    "    print(label, counter)\n",
    "\n",
    "val_data = gen_dump_data(val_gen, len(balanced_image_ids_val))\n",
    "test_data = val_data\n",
    "class_weights = None\n",
    "# Uncomment below line to use class weights, not needed if using balanced_set\n",
    "# class_weights = calc_class_weights(gen_dump_data(train_gen, len(balanced_image_ids_train)), caption_type)\n",
    "\n",
    "print(\"training class weights:\")\n",
    "print(class_weights)\n",
    "\n",
    "print(\"Binary accuracy if you were to output all 0s\")\n",
    "print((val_data[1] == 0).sum() / val_data[1].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_head(\n",
    "    base_model, num_classes, caption_type, model_params, opt_params=None):\n",
    "    '''make sure base_model has include_top=False. If loss=None then it is determined.'''\n",
    "    \n",
    "    if not opt_params:\n",
    "        opt_params = {\"optimizer\": Nadam(clipnorm=1)}\n",
    "    \n",
    "    if model_params.loss is None:\n",
    "        if caption_type == \"single\":\n",
    "            opt_params['loss'] = \"categorical_crossentropy\" \n",
    "        elif caption_type == \"multi\":\n",
    "            # weights = np.array([\n",
    "                # i[1] for i in sorted(model_params.class_weights.items())])[np.newaxis, ...] \\\n",
    "                # if model_params.class_weights else 1.0\n",
    "            opt_params['loss'] = 'binary_crossentropy'\n",
    "    else:\n",
    "        opt_params['loss'] = model_params.loss\n",
    "        \n",
    "    if caption_type == \"single\":\n",
    "        activation = \"softmax\" \n",
    "    else:\n",
    "        activation = \"sigmoid\"\n",
    "    \n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    \n",
    "    if model_params.pooling == 'avg':\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "    elif model_params.pooling == 'max':\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "    else:\n",
    "        x = Flatten()(x)\n",
    "    for _ in range(model_params.num_hidden_layers):\n",
    "        x = Dense(model_params.num_hidden_neurons, activation=activation,\n",
    "                  kernel_initializer=keras.initializers.he_uniform())(x)\n",
    "#         x = relu(x, alpha=0.3, max_value=2.5)\n",
    "        if model_params.dropout:\n",
    "            x = Dropout(model_params.dropout)(x)\n",
    "            \n",
    "    predictions = Dense(\n",
    "        num_classes,\n",
    "        activation=activation,\n",
    "        kernel_initializer=keras.initializers.he_uniform(),\n",
    "        name='class_logits')(x)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = model_params.train_features\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if not layer.trainable:\n",
    "            continue\n",
    "        if hasattr(layer, 'kernel_regularizer') and model_params.kernel_regularizer:\n",
    "            layer.kernel_regularizer = model_params.kernel_regularizer\n",
    "        if hasattr(layer, 'activity_regularizer') and model_params.activity_regularizer:\n",
    "            layer.activity_regularizer = model_params.activity_regularizer\n",
    "    \n",
    "    print(\"Compiling model:\")\n",
    "    print(\"   activation:\", activation)\n",
    "    print(\"   optimizer:\", opt_params)\n",
    "    model.compile(**opt_params, metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(model):\n",
    "    \"\"\"Get the gradients of the loss with respect to the weights.\"\"\"\n",
    "    weights = [tensor for tensor in model.trainable_weights \n",
    "               if model.trainable_weights]\n",
    "    return weights, model.optimizer.get_gradients(model.total_loss, weights)\n",
    "\n",
    "def evaluate_model(model, test_data, thresh=0.5):\n",
    "    def multi_label_decision(y_true, y_pred):\n",
    "        return (y_true > thresh) == (y_pred > thresh)\n",
    "    def single_label_decision(y_true, y_pred):\n",
    "        return np.argmax(y_true, axis=-1) == np.argmax(y_pred, axis=-1)\n",
    "    decision_function = single_label_decision if caption_type == 'single' else multi_label_decision\n",
    "\n",
    "    Y_true = test_data[1]\n",
    "    Y_pred = model.predict(test_data[0])\n",
    "    TP = decision_function(Y_true, Y_pred)\n",
    "    acc = np.count_nonzero(TP) / TP.size\n",
    "    \n",
    "    print(\"Test using {:d} samples:\".format(len(test_data[0])))\n",
    "    print(\"accuracy\", acc)\n",
    "    return Y_true, Y_pred, TP\n",
    "\n",
    "def display_performance(Y_true, Y_pred, TP):\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(num_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(Y_true[:, i],\n",
    "                                                            Y_pred[:, i])\n",
    "        average_precision[i] = average_precision_score(Y_true[:, i], Y_pred[:, i])\n",
    "\n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_true.ravel(),\n",
    "        Y_pred.ravel())\n",
    "    average_precision[\"micro\"] = average_precision_score(Y_true, Y_pred,\n",
    "                                                         average=\"micro\")\n",
    "    print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "          .format(average_precision[\"micro\"]))\n",
    "\n",
    "    z = np.all((Y_pred > 0.5) == Y_true, axis=1)\n",
    "    acc = np.count_nonzero(z) / z.size\n",
    "    print(\"exact accuracy\", acc)\n",
    "    z = ((Y_pred > 0.5) == Y_true)\n",
    "    acc = np.count_nonzero(z) / z.size\n",
    "    print(\"binary accuracy\", acc)\n",
    "    \n",
    "    # setup plot details\n",
    "    colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "    lines = []\n",
    "    labels = []\n",
    "    for f_score in f_scores:\n",
    "        x = np.linspace(0.01, 1)\n",
    "        y = f_score * x / (2 * x - f_score)\n",
    "        l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "        plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "    lines.append(l)\n",
    "    labels.append('iso-f1 curves')\n",
    "    l, = plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('micro-average Precision-recall (area = {0:0.2f})'\n",
    "                  ''.format(average_precision[\"micro\"]))\n",
    "\n",
    "    for i, color in zip(range(num_classes), colors):\n",
    "        l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n",
    "        lines.append(l)\n",
    "        labels.append('{0} (area = {1:0.2f})'\n",
    "                      ''.format(caption_map_r[i], average_precision[i]))\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.subplots_adjust(bottom=0.25)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Micro Average Precision vs. Recall')\n",
    "    plt.legend(lines, labels, loc=(0, -.4), prop=dict(size=14))\n",
    "    plt.show()\n",
    "    plt.savefig(model_plot_path, dpi=150)\n",
    "    \n",
    "def save_model(model, name, class_map_r, prediction_type,\n",
    "               model_weights_path, model_def_path, model_info_path, history,\n",
    "               test_metrics=None, description=\"\"):\n",
    "    from abyss.utils import JsonNumpyEncoder\n",
    "    def merged(a, b):\n",
    "        merged = dict(a)\n",
    "        merged.update(b)\n",
    "        return merged\n",
    "        \n",
    "    model_info = {\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"weights\": model_weights_path,\n",
    "        \"prediction_type\": caption_type,\n",
    "        \"model\": model_def_path,\n",
    "        \"classes\": class_map_r,\n",
    "        \"architecture\": {\n",
    "            \"backbone\": \"inceptionv3\",\n",
    "            \"logit_activation\": model.get_layer(\"class_logits\").activation.__name__,\n",
    "            \"input_shape\": image_dims\n",
    "        },\n",
    "        \"metrics\": {\n",
    "            \"loss_function\": str(history.model.loss),\n",
    "            \"train\": merged(\n",
    "                history.history,\n",
    "                {\n",
    "                    \"epoch\": history.epoch,\n",
    "                    \"params\": history.params\n",
    "                })\n",
    "        }\n",
    "    }\n",
    "    if test_metrics:\n",
    "        model_info['metrics']['test'] = test_metrics\n",
    "    \n",
    "    print(\"Writing model def to \" + model_def_path)\n",
    "    with open(model_def_path, \"w\") as file:\n",
    "        file.write(model.to_json())\n",
    "        \n",
    "    print(\"Writing model weights to \" + model_weights_path)\n",
    "    model.save_weights(model_weights_path)\n",
    "    \n",
    "    print(\"Writing model info to \" + model_info_path)\n",
    "    with open(model_info_path, \"w\") as file:\n",
    "        file.write(json.dumps(model_info, cls=JsonNumpyEncoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * (1 - y_pred) + (1 - y_true) * y_pred)\n",
    "\n",
    "def setup_callbacks(log_dir, hist=False):\n",
    "    !mkdir -p $log_dir/models\n",
    "    best_path = os.path.join(log_dir, \"models/best.{epoch:03d}-{val_loss:.4f}.h5\")\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=6, cooldown=0, verbose=1),\n",
    "        ModelCheckpoint(\n",
    "            best_path, monitor='val_loss', verbose=1,\n",
    "            save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "            ModelCheckpoint(\n",
    "                best_path, monitor='val_loss', verbose=1,\n",
    "                save_best_only=False, save_weights_only=True, mode='auto', period=20),\n",
    "        PRTensorBoard(\n",
    "            log_dir=log_dir, \n",
    "            histogram_freq=(hist or 0), batch_size=batch_size,\n",
    "            write_graph=False,\n",
    "            write_grads=(hist is not None),\n",
    "            write_images=False),\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss', min_delta=0.0, patience=20, verbose=1, mode='auto')\n",
    "    ]\n",
    "    return callbacks\n",
    "\n",
    "def go(epochs, class_weights, initial_epoch=0):\n",
    "    return model.fit_generator(\n",
    "        batching_gen(train_gen, batch_size=batch_size),\n",
    "        validation_data=tuple(val_data),\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=steps_per_epoch_val,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks, \n",
    "        epochs=epochs,\n",
    "        verbose=1, initial_epoch=initial_epoch, workers=10)\n",
    "\n",
    "def check_gradients(model):\n",
    "    grad_test = None\n",
    "    for image, label in train_gen:\n",
    "        grad_test = (image, label)\n",
    "        break\n",
    "    rates = []\n",
    "    weights, grads = get_gradients(model)\n",
    "    feed_dict = {\n",
    "        \"class_logits_sample_weights:0\": np.ones(2),\n",
    "        \"input_1:0\": grad_test[0][np.newaxis, ...],\n",
    "        \"class_logits_target:0\": grad_test[1][np.newaxis, ...]\n",
    "    }\n",
    "    for i, (w, g) in enumerate(zip(weights, grads)):\n",
    "        if 'bias' in w.name:\n",
    "            continue\n",
    "        grad_norm = np.linalg.norm(g.eval(feed_dict, K.get_session()))\n",
    "        weight_norm = np.linalg.norm(w.eval(K.get_session()))\n",
    "        rate = grad_norm / weight_norm\n",
    "        rates.append(rate)\n",
    "    if np.mean(rates) < 5e-4 or np.mean(rates) > 3e-1: # These values change with network structure\n",
    "        print(\"Bad gradients ({:.3e}).\".format(np.mean(rates)))\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this class to change search parameters\n",
    "class ExperimentParameters(object):\n",
    "    def __init__(self, data_name, model_name, batch_size):\n",
    "        from keras.regularizers import l1_l2\n",
    "        self.data_name = data_name\n",
    "        self.learning_rate = 10 ** np.random.uniform(-7, -3)\n",
    "        self.loss = 'binary_crossentropy'\n",
    "        self.dropout = 0.5\n",
    "        self.train_features = False\n",
    "        self.pooling = 'avg'\n",
    "        self.num_hidden_layers = 1\n",
    "        self.num_hidden_neurons = 1024\n",
    "        self.pretrained_weights = 'imagenet'\n",
    "        self.class_weights = None\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        self.kernel_regularizer = l1_l2(0, 10 ** np.random.uniform(-3, -1))\n",
    "        self.activity_regularizer = l1_l2(10 ** np.random.uniform(-3, -1), 0)\n",
    "\n",
    "    def experiment_name(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '-'.join([\n",
    "            ':'.join([key, str(value)]) \n",
    "            for key, value in [\n",
    "                (\"data\", self.data_name),\n",
    "                (\"model\", self.model_name),\n",
    "                (\"head\", \"{:d}x{:d}\".format(self.num_hidden_layers, self.num_hidden_neurons)),\n",
    "                (\"train\", 'all' if self.train_features else 'heads'),\n",
    "                (\"from\", str(self.pretrained_weights)),\n",
    "                (\"loss\", self.loss.__name__ if callable(self.loss) else str(self.loss)),\n",
    "                (\"init_lr\", \"{:.3e}\".format(self.learning_rate)),\n",
    "                (\"act_reg\", \"{:.3e},{:.3e}\".format(params.activity_regularizer.l1, params.activity_regularizer.l2)),\n",
    "                (\"ker_reg\", \"{:.3e},{:.3e}\".format(params.kernel_regularizer.l1, params.kernel_regularizer.l2)),\n",
    "                (\"dropout\", \"{:.1f}\".format(self.dropout or 0)),\n",
    "                (\"pool\", str(self.pooling)),\n",
    "                (\"CW\", str(True if self.class_weights else False))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_output_dir = \"/data/log/cnn/fd/wednesday2\" # Change this output dir.\n",
    "base_model = [ResNet50, InceptionV3, VGG16][0] # Choose one\n",
    "history_data = {}\n",
    "for attempt_no in range(100):\n",
    "    K.clear_session()\n",
    "    params = ExperimentParameters(dataset_name, base_model.__name__, batch_size)\n",
    "    base_model = base_model(include_top=False, weights=params.pretrained_weights, input_shape=image_dims)\n",
    "    model = create_new_head(\n",
    "        base_model, num_classes, caption_type, params, \n",
    "        opt_params={'optimizer': Nadam(clipnorm=1, clipvalue=1)}\n",
    "    )\n",
    "\n",
    "    experiment_name = str(params) + \"-{:03d}\".format(np.random.randint(0, 999))\n",
    "    log_dir = os.path.join(search_output_dir, experiment_name)\n",
    "    model_def_path = os.path.join(log_dir, \"model_def.json\")\n",
    "    model_weights_path = os.path.join(log_dir, \"model_weights.h5\")\n",
    "    model_info_path = os.path.join(log_dir, \"model.json\")\n",
    "    model_plot_path = os.path.join(log_dir, \"precision-recall.png\")\n",
    "    print(experiment_name)\n",
    "    print(\"Training: {:d} layers\".format(len([1 for layer in model.layers if layer.trainable])))\n",
    "    print(log_dir)\n",
    "    \n",
    "    callbacks = setup_callbacks(log_dir, hist=None)\n",
    "    K.set_value(model.optimizer.lr, params.learning_rate)\n",
    "    history_data[experiment_name] = go(1, params.class_weights)\n",
    "\n",
    "#     if not check_gradients(model): # Disabled as I only know what to expect for VGG16\n",
    "#         print(\"Bad gradients. Continuing to next model.\")\n",
    "\n",
    "    callbacks = setup_callbacks(log_dir, hist=None)\n",
    "    history_data[experiment_name] = go(29, params.class_weights, initial_epoch=1)\n",
    "    (Y_true, Y_pred, TP) = evaluate_model(model, test_data, thresh=0.5)\n",
    "    display_performance(Y_true, Y_pred, TP)\n",
    "    \n",
    "    save_model(\n",
    "        model, name=experiment_name,\n",
    "        class_map_r=caption_map_r, prediction_type=caption_type,\n",
    "        model_weights_path=model_weights_path, model_def_path=model_def_path, model_info_path=model_info_path,\n",
    "        test_metrics=None, history=history_data[experiment_name],\n",
    "        description=\"Test model for 5 FDs\"\n",
    "    )\n",
    "    \n",
    "with open(os.path.join(search_output_dir, \"history-100epoch.pkl\"), \"wb\") as file:\n",
    "    pickle.dump({key: history.history for key, history in history_data.items()}, file)\n",
    "### Should you need to load this pkl:\n",
    "# with open(os.path.join(search_output_dir, \"history-100epoch.pkl\"), \"rb\") as file:\n",
    "#     history = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [key[1] for key, val  in sorted(history_data.items(), key=lambda x: x[0])]\n",
    "val_loss = [history.history['val_loss'][-1] for key, history  in sorted(history_data.items(), key=lambda x: x[0])]\n",
    "loss = [history.history['loss'][-1] for lr, history  in sorted(history_data.items(), key=lambda x: x[0])]\n",
    "acc = [history.history['binary_accuracy'][-1] for lr, history  in sorted(history_data.items(), key=lambda x: x[0])]\n",
    "val_acc = [history.history['val_binary_accuracy'][-1] for lr, history  in sorted(history_data.items(), key=lambda x: x[0])]\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogx(lrs, loss, '.b', label='loss')\n",
    "plt.semilogx(lrs, val_loss, '.r', label='val_loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Vs. LR (100 Epoch)\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogx(lrs, acc, '.b', label='binary_accuracy')\n",
    "plt.semilogx(lrs, val_acc, '.r', label='val_binary_accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Vs. LR (100 Epoch)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue training specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_instance = \"data:ip_ed_fromCF-model:resnet50-head:1x1024-train:heads-from:imagenet-loss:binary_crossentropy-init_lr:3.803e-07-act_reg:9.917e-03,0.000e+00-ker_reg:0.000e+00,1.166e-02-dropout:0.5-pool:avg-CW:False-296\"\n",
    "model_best_weight = \"best.300-0.7164.h5\"\n",
    "model_initial_learning_rate = 1e-7 ##### IMPORTANT TO SET THIS FROM TENSORBOARD\n",
    "num_epoch = 200\n",
    "class_weights = None # Can't currently resume training with imbalance data #TODO\n",
    "\n",
    "model_weights_in_path = os.path.join(search_output_dir, model_instance, \"models\", model_best_weight)\n",
    "log_dir = os.path.join(search_output_dir, model_instance, \"continued\")\n",
    "best_path = os.path.join(log_dir, \"models/best.{epoch:03d}-{val_loss:.4f}.h5\")\n",
    "model_def_path = os.path.join(log_dir, \"model_def.json\")\n",
    "model_info_path = os.path.join(log_dir, \"model.json\")\n",
    "model_plot_path = os.path.join(log_dir, \"precision-recall.png\")\n",
    "!mkdir -p $log_dir/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = Inference(os.path.join(search_output_dir, model_instance, \"model.json\")).model\n",
    "model.load_weights(os.path.join(search_output_dir, model_instance, \"model_weights.h5\"))\n",
    "\n",
    "model.compile( # TODO, load this from JSON, manually change this if you are doing single label\n",
    "    Nadam(clipnorm=1),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'])\n",
    "\n",
    "print(\"Training: {:d} layers\".format(len([1 for layer in model.layers if layer.trainable])))\n",
    "print(log_dir)\n",
    "\n",
    "callbacks = setup_callbacks(log_dir, hist=None)\n",
    "K.set_value(model.optimizer.lr, model_initial_learning_rate)\n",
    "history_data[experiment_name] = go(num_epoch, class_weights, initial_epoch=0)\n",
    "(Y_true, Y_pred, TP) = evaluate_model(model, test_data, thresh=0.5)\n",
    "display_performance(Y_true, Y_pred, TP)\n",
    "\n",
    "save_model(\n",
    "    model, name=experiment_name,\n",
    "    class_map_r=caption_map_r, prediction_type=caption_type,\n",
    "    model_weights_path=model_weights_path, model_def_path=model_def_path, model_info_path=model_info_path,\n",
    "    test_metrics=None, history=history_data[experiment_name],\n",
    "    description=\"Test model for 5 FDs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is untested with new changes, don't use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TP_mask = np.logical_and.reduce(TP, axis=1)\n",
    "right = test_data[0][TP_mask]\n",
    "wrong = test_data[0][~TP_mask]\n",
    "wrong.shape\n",
    "plt.figure()\n",
    "vis_square(wrong)\n",
    "plt.title(\"Incorrectly Predicted\")\n",
    "plt.figure()\n",
    "vis_square(right)\n",
    "plt.title(\"Correctly Predicted\")\n",
    "\n",
    "# Binary coded the labels then count them wrt TP/FP\n",
    "coded = np.sum(test_data[1][~TP_mask] * 2 ** np.arange(num_classes)[::-1], axis=1).astype(int)\n",
    "print(\"binary coded class error count:\", dict(sorted(Counter(coded).items(), key=lambda x: x[0])))\n",
    "coded = np.sum(test_data[1][TP_mask] * 2 ** np.arange(num_classes)[::-1], axis=1).astype(int)\n",
    "print(\"binary coded class correct count:\", dict(sorted(Counter(coded).items(), key=lambda x: x[0])))\n",
    "print(Y_pred[~TP_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def learning_curve(dataset, lr, steps, val_data, log_dir):\n",
    "    def save_model(path):\n",
    "        print(\"Saving\", path)\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        model.save_weights(path)\n",
    "    def setup_callbacks():\n",
    "        return [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, cooldown=5, verbose=1),\n",
    "                ModelCheckpoint(\n",
    "                    model_best_path, monitor='val_loss', verbose=1,\n",
    "                    save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "#                 ModelCheckpoint(\n",
    "#                     best_path, monitor='val_loss', verbose=1,\n",
    "#                     save_best_only=False, save_weights_only=True, mode='auto', period=50),\n",
    "                PRTensorBoard(\n",
    "                    log_dir=model_log_dir,\n",
    "                    histogram_freq=0,\n",
    "                    batch_size=batch_size,\n",
    "                    write_graph=False,\n",
    "                    write_grads=False,\n",
    "                    write_images=False),\n",
    "        #         EarlyStopping(\n",
    "        #             monitor='val_loss', min_delta=0.0, patience=40, verbose=1, mode='auto')\n",
    "        ]\n",
    "    def create_new_model(load_base=False):\n",
    "        K.clear_session()\n",
    "        model = create_new_head(\n",
    "            InceptionV3(include_top=False, weights='imagenet', input_shape=image_dims),\n",
    "            num_classes, caption_type, opt_params={'optimizer': Nadam()},\n",
    "            class_weights=None, train_features=False, l2_reg=None)\n",
    "        if load_base:\n",
    "            print(\"Loading base model\")\n",
    "            model.load_weights(base_model_path, by_name=True)\n",
    "        return model\n",
    "\n",
    "    def train():\n",
    "        print(\"Training\")\n",
    "        K.set_value(model.optimizer.lr, lr)\n",
    "        history[subset_size] = model.fit_generator(\n",
    "            batching_gen(gen, batch_size=batch_size),\n",
    "            validation_data=tuple(val_data),\n",
    "            steps_per_epoch=(subset_size // batch_size),\n",
    "            validation_steps=steps_per_epoch_val,\n",
    "            class_weight=model_class_weights,\n",
    "            callbacks=setup_callbacks(), \n",
    "            epochs=50,\n",
    "            verbose=1)\n",
    "    model_class_weights = None\n",
    "    model = None\n",
    "    model_path = None\n",
    "    image_ids = [image['id'] for image in dataset.imgs.values()]\n",
    "    np.random.shuffle(image_ids)\n",
    "    num_images = len(image_ids)\n",
    "    print(\"num_images\", num_images)\n",
    "    history = {}\n",
    "    base_model_path = os.path.join(log_dir, \"base\", \"weights.h5\")\n",
    "    model_path = base_model_path\n",
    "    for subset_size in np.linspace(0, num_images, steps + 1).astype(int):\n",
    "        if subset_size > 0:\n",
    "            imgIds = image_ids[:subset_size]\n",
    "            gen = pipeline(\n",
    "                dataset.generator(shuffle_ids=False, imgIds=imgIds),\n",
    "                aug_config=None)\n",
    "            model_class_weights = calc_class_weights(gen, dataset) # TODO\n",
    "\n",
    "            model_path = os.path.join(log_dir, \"subset-of-{:d}/weights.h5\".format(subset_size))\n",
    "            model_log_dir = os.path.dirname(model_path)\n",
    "            model_best_path = os.path.join(log_dir, \"subset-of-{:d}/best.h5\".format(subset_size))\n",
    "            os.makedirs(model_log_dir, exist_ok=True)\n",
    "\n",
    "            print(\"learning curve(lr={:.3e}, size={:d})\".format(lr, subset_size))\n",
    "            print(\"model_log_dir\", model_log_dir)\n",
    "            print(\"training class weights\")\n",
    "            print(model_class_weights)\n",
    "        model = create_new_model(load_base=(subset_size > 0))\n",
    "        if subset_size:\n",
    "            train()\n",
    "        save_model(model_path)\n",
    "    return history\n",
    "\n",
    "model = None\n",
    "lr = 1e-5\n",
    "learning_curve_dir = \"/data/log/cnn/fd/learning_curve_5--{:.2e}\".format(lr)\n",
    "lc_history = learning_curve(coco_train, lr, 5, val_data, learning_curve_dir)\n",
    "val_loss = np.array([(size, h.history['val_loss'][-1]) for size, h in lc_history.items()])\n",
    "train_loss = np.array([(size, h.history['loss'][-1]) for size, h in lc_history.items()])\n",
    "plt.figure()\n",
    "plt.plot(train_loss[:, 0], train_loss[:, 1], 'b.')\n",
    "plt.plot(val_loss[:, 0], val_loss[:, 1], 'r.')\n",
    "plt.xlabel(\"Number of Training Samples\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(os.path.join(learning_curve_dir, \"plot.png\"), dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -R /data/log/cnn/fd/learning-curve/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = None\n",
    "for images, labels in batching_gen(train_gen, batch_size=batch_size):\n",
    "    print(images.shape, labels.shape)\n",
    "    \n",
    "    pred = model.predict(images)\n",
    "    print(labels)\n",
    "    print(pred)\n",
    "    print(K.eval(K.tf.losses.sigmoid_cross_entropy(labels, pred)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for unique_label in np.unique(val_data[1], axis=0):\n",
    "    unique_data = [val_data[0][i] for i in range(len(val_data[0])) if np.all(val_data[1][i] == unique_label)]\n",
    "    num_data = len(unique_data)\n",
    "    print(unique_label, num_data)\n",
    "    plt.figure()\n",
    "    vis_square(np.array(unique_data))\n",
    "    plt.title(unique_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Update/Weight Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, (w, g) in enumerate(zip(weights, grads)):\n",
    "    grad_norm = np.linalg.norm(g.eval(feed_dict, K.get_session()))\n",
    "    weight_norm = np.linalg.norm(w.eval(K.get_session()))\n",
    "    rate = grad_norm / weight_norm\n",
    "    print(i, rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from herbicide.utils import vis_square\n",
    "for layer in model.layers:\n",
    "    if not layer.trainable_weights:\n",
    "        continue\n",
    "    for weight in layer.trainable_weights: #  Assumes FD is not trainable\n",
    "        if 'kernel' not in weight.name:\n",
    "            continue\n",
    "        print(weight.name)\n",
    "        value = K.eval(weight.value())\n",
    "        print(value.shape)\n",
    "    \n",
    "    plt.figure()\n",
    "    vis_square(value.transpose((3, 0, 1, 2)))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "caption_stats = []\n",
    "for i, (image, caption) in enumerate(coco_train.generator(imgIds=balanced_image_ids_train)):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(str(caption))\n",
    "    if i == 10:\n",
    "        break\n",
    "    caption_stats.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(caption_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
