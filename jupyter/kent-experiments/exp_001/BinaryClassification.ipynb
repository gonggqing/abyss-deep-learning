{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras.applications.xception import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from abyss_deep_learning.datasets.coco import ImageClassificationDataset\n",
    "from abyss_deep_learning.datasets.translators import CocoCaptionTranslator\n",
    "from abyss_deep_learning.keras.classification import caption_map_gen, onehot_gen, hamming_loss\n",
    "from abyss_deep_learning.keras.utils import lambda_gen, batching_gen\n",
    "from abyss_deep_learning.keras.models import ImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current working directory of binary classification (/home/users/khu/src/abyss/deep-learning/jupyter/kent-experiments/exp_001)\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "TRAIN = \"train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds = ImageClassificationDataset(os.path.join(DATA_DIR, TRAIN),\n",
    "                                      cached=False,\n",
    "                                      translator=CocoCaptionTranslator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel non 'RI' captions as 'NR' \n",
    "# for binary classification of root/non-root\n",
    "\n",
    "for idx, ann in ds.coco.anns.items():\n",
    "    if ann['caption'] != 'RI':\n",
    "        ann['caption'] = 'NR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample image and caption\n",
    "image, caption = ds.sample()\n",
    "print(caption)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_map = {\n",
    "    'NR': 0,\n",
    "    'RI': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_map_r = {value: key for key, value in caption_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_shuffled = np.random.permutation(len(ds.coco.imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_split = int(np.floor(split_ratio*len(ds.coco.imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 80% of data to be in training set\n",
    "train_ids = idx_shuffled[0:idx_split]\n",
    "# Randomly select 20% of data to be in validation set\n",
    "val_ids = idx_shuffled[(idx_split+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_gen = ds.generator(data_ids=list(train_ids),endless=True, shuffle_ids=True)\n",
    "val_gen = ds.generator(data_ids=list(val_ids),endless=True, shuffle_ids=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 299\n",
    "num_cols = 299\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "steps_per_epoch = len(train_ids) // batch_size\n",
    "validation_steps = len(val_ids) // batch_size\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "init_lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(gen):\n",
    "    \"\"\"\n",
    "        caption_map_gen:\n",
    "            Maps ['NR', 'RI'] to [0, 1]\n",
    "        onehot_gen:\n",
    "            Create a one hot vector from input of either 0 or 1\n",
    "        lambda_gen:\n",
    "            Preprocess image to be in compatible format for Xception\n",
    "        batching_gen:\n",
    "            Generate batches of 5 images to pass in fit_generator\n",
    "    \"\"\"\n",
    "    return batching_gen(lambda_gen(onehot_gen(caption_map_gen(gen, caption_map), len(caption_map)), \n",
    "                                   lambda x, y: (preprocess_input(cv2.resize(x, (num_rows, num_cols))), y)), batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model default uses Xception model\n",
    "model = ImageClassifier(init_lr=init_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(pipeline(train_gen),\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=pipeline(val_gen),\n",
    "                    validation_steps=validation_steps,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, caption = ds.sample()\n",
    "print(caption_map_r[model.predict(np.expand_dims(cv2.resize(image, (299,299)), 0))[0]])\n",
    "print(caption.pop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWC = \"/mnt/rhino/ssd1/processed/industry-data/swc/train_1/cloudfactory/datasets/with-bg/notebook-ready/train-nb.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swc_ds = ImageClassificationDataset(SWC,\n",
    "                                    cached=False,\n",
    "                                    translator=CocoCaptionTranslator(separator=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equialent SWC labels for a root\n",
    "roots = ['SeRB', 'SeRF', 'SeRJ', 'SeRM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swc_gen = swc_ds.generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swc_pipeline(gen):\n",
    "    gen1 = lambda_gen(gen, lambda x, y: (preprocess_input(cv2.resize(x, (num_rows, num_cols))),\n",
    "                                         ['RI' if any(label in roots for label in list(y)) else 'NR']))\n",
    "    map_gen = caption_map_gen(gen1, caption_map)\n",
    "    gen2 = onehot_gen(map_gen, len(caption_map))\n",
    "    return batching_gen(gen2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image)\n",
    "    return preprocess_input(np.expand_dims(cv2.resize(image, (num_rows, num_cols)), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through SWC generator and calculate probabilities of either class root/non-root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, caption = next(swc_gen)\n",
    "preds = model.predict_proba(process_image(image))[0]\n",
    "labelled = np.array(['RI' if any(label in roots for label in list(caption)) else 'NR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for image, caption in swc_gen:\n",
    "    pred = model.predict_proba(process_image(image))[0]\n",
    "    preds = np.vstack((preds, pred))\n",
    "    label = np.array(['RI' if any(label in roots for label in list(caption)) else 'NR'])\n",
    "    labelled = np.vstack((labelled, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (pred, label) in enumerate(zip(preds, labelled)):\n",
    "    print(idx, pred, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
