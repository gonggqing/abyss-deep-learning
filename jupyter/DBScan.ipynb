{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from abyss_deep_learning.datasets.translators import CloudFactoryCaptionTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(iterable, max_dist):\n",
    "    prev = None\n",
    "    group = []\n",
    "    for item in iterable:\n",
    "        if not prev or item[1] - prev <= max_dist:\n",
    "            group.append(item)\n",
    "        else:\n",
    "            yield group\n",
    "            group = [item]\n",
    "        prev = item[1]\n",
    "    if group:\n",
    "        yield group\n",
    "# numbers = [123, 124, 128, 160, 167, 213, 215, 230, 245, 255, 257, 400, 401, 402, 430]\n",
    "# dict(enumerate(grouper(numbers,50), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_ids_to_keep = []\n",
    "# for vid in imgs:\n",
    "#     clumps = dict(enumerate(grouper(imgs[vid],12),1))\n",
    "#     for c in clumps:\n",
    "#         rand_sample = clumps[c][random.randint(0,len(clumps[c])-1)]\n",
    "#         print(vid, c, rand_sample, clumps[c])\n",
    "#         img_ids_to_keep.append(rand_sample[0])\n",
    "# sorted(img_ids_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_caption_map(input_json, translator):\n",
    "    caption_map = []\n",
    "    for ann_idx, ann in enumerate(input_json['annotations']):\n",
    "        if 'caption' not in ann or not translator.filter(ann):\n",
    "            continue\n",
    "        caption_map.append(translator.translate(ann))\n",
    "    return {l: k for k, l in enumerate(sorted(list(set([j for i in caption_map for j in i]))))}\n",
    "\n",
    "def extract_timestamps(input_json, translator, caption_map):\n",
    "    imgs = {}\n",
    "    idxs = []\n",
    "    img_id_map = {img['id']: idx for idx, img in enumerate(input_json['images'])} # map id to idx\n",
    "    for ann_idx, ann in enumerate(input_json['annotations']):\n",
    "        if 'caption' not in ann:\n",
    "            continue\n",
    "        idxs.append((ann_idx, ann['image_id']))\n",
    "    for ann_idx, img_id in idxs:\n",
    "        ann = input_json['annotations'][ann_idx]\n",
    "        img = input_json['images'][img_id_map[img_id]]\n",
    "        img_id = img['id']\n",
    "        file_list = img['file_name'][:-4].split('_')\n",
    "        file = '_'.join(file_list[:-1])\n",
    "        frame_num = int(file_list[-1])\n",
    "        fps = (25 / 6 if 'reduced' in file else 25)\n",
    "        if file not in imgs:\n",
    "            imgs[file] = []\n",
    "        if not translator.filter(ann):\n",
    "            continue\n",
    "        for caption in translator.translate(ann):\n",
    "            imgs[file].append(\n",
    "                (img_id, frame_num, frame_num / fps, caption_map[caption]))\n",
    "    return imgs\n",
    "\n",
    "def unique_instances(input_json, seconds=1):\n",
    "    imgs = extract_timestamps(input_json)\n",
    "    img_ids_to_keep = []\n",
    "    \n",
    "    for name, vid in imgs.items():\n",
    "        print(name)\n",
    "        max_dist = fps * seconds\n",
    "        clumps = dict(enumerate(grouper(vid, max_dist), 1))\n",
    "        for c in clumps:\n",
    "            rand_sample = clumps[c][random.randint(0,len(clumps[c])-1)]\n",
    "            img_ids_to_keep.append(rand_sample[0])\n",
    "    return sorted(img_ids_to_keep)\n",
    "\n",
    "\n",
    "# extract_timestamps(json.load(open(json_path, 'r')), translator, caption_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0,\n",
       " 'ED': 1,\n",
       " 'F': 2,\n",
       " 'IP': 3,\n",
       " 'JD': 4,\n",
       " 'RI': 5,\n",
       " 'SJ': 6,\n",
       " 'SO': 7,\n",
       " 'U': 8,\n",
       " 'X': 9,\n",
       " 'background': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_time_diff = 10\n",
    "seconds_per_sample = 10\n",
    "json_file = json.load(open(json_path, 'r'))\n",
    "translator = CloudFactoryCaptionTranslator()\n",
    "caption_map = calc_caption_map(json_file, translator)\n",
    "caption_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D_list = []\n",
    "def lograndom(low, high, size=None):\n",
    "    return 10 ** np.random.uniform(low, high, size)\n",
    "keep_ids = []\n",
    "for name, data in extract_timestamps(json_file, translator, caption_map).items():\n",
    "    data = np.array(data)\n",
    "    print(name, data.shape)\n",
    "    plt.figure()\n",
    "    cls = DBSCAN(eps=max_time_diff, min_samples=1)\n",
    "    n_samples = data.shape[0]\n",
    "    n_components = n_samples // 2\n",
    "\n",
    "    X = data[:, 2:4]\n",
    "#     plt.scatter(X[:, 0], 1 + X[:, 1], c=X[:, 1])\n",
    "    \n",
    "    for label in caption_map.values():\n",
    "        mask = X[:, 1] == label\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        X2 = X[mask, ...]\n",
    "        y2 = cls.fit_predict(X2).ravel()\n",
    "        mask2 = y2 >= 0\n",
    "        X2 = X2[mask2, ...]\n",
    "        y2 = y2[mask2]\n",
    "        \n",
    "        keep_ids += [\n",
    "            int(i)\n",
    "            for l in np.unique(y2)\n",
    "            for i in np.random.choice(\n",
    "                data[mask][mask2][y2 == l, 0],\n",
    "                size=(int(np.round((X2[y2 == l, 1].max() - X2[y2 == l, 1].min()) / seconds_per_sample)) + 1))\n",
    "        ]\n",
    "        plot_samples = np.array([\n",
    "            int(i)\n",
    "            for l in np.unique(y2)\n",
    "            for i in np.random.choice(\n",
    "                data[mask][mask2][y2 == l, 0],\n",
    "                size=(int(np.round((X2[y2 == l, 1].max() - X2[y2 == l, 1].min()) / seconds_per_sample)) + 1))\n",
    "        ])\n",
    "        plt.scatter(X2[:, 0], label * np.ones_like(y2), c=y2, cmap='Paired')\n",
    "        plt.plot(plot_samples, 0 * plot_samples, '+k', ms=10, fillstyle='none')\n",
    "    \n",
    "        \n",
    "#         plt.plot(X2_discard[:, 0], label * np.ones_like(X2_discard[:, 0]),  'kx')\n",
    "\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin_json_unique(working_json, seconds, save_here=False, save_to=None):\n",
    "    \n",
    "    working = json.load(open(working_json,'r'))\n",
    "    \n",
    "    if 'categories' in working:\n",
    "        new_json = {'info':working['info'],'licenses':working['licenses'],'categories':working['categories'],'captions':[],'annotations':[],'images':[]}\n",
    "    else:\n",
    "        new_json = {'info':working['info'],'licenses':working['licenses'],'annotations':[],'images':[]}\n",
    "\n",
    "    conversion_dict = {}\n",
    "    for uid in unique_instances(working, seconds=seconds):\n",
    "#         print(id, len(new_json['images'])+1)\n",
    "        img = working['images'][uid-1]\n",
    "        if uid != img['id']:\n",
    "            print(\"{} != {}\".format(uid,img['id']))\n",
    "        img['id'] = len(new_json['images'])+1\n",
    "        new_json['images'].append(img)\n",
    "        if uid in conversion_dict:\n",
    "            print('{} already in conversion_dict with val {}, trying to add {}'.format(uid,conversion_dict[uid],img['id']))\n",
    "        conversion_dict[uid] = img['id']\n",
    "\n",
    "    if 'captions' in working:  \n",
    "        for cap in working['captions']:\n",
    "            if cap['image_id'] in conversion_dict:\n",
    "                cap['image_id'] = conversion_dict[cap['image_id']]\n",
    "                new_json['captions'].append(cap)\n",
    "\n",
    "    for ann in working['annotations']:\n",
    "        if ann['image_id'] in conversion_dict:\n",
    "            ann['image_id'] = conversion_dict[ann['image_id']]\n",
    "            new_json['annotations'].append(ann)\n",
    "\n",
    "    if save_here is True:\n",
    "        split = os.path.splitext(working_json)\n",
    "        save_path = split[0]+\"-unique.json\"\n",
    "        with open(save_path,\"w\") as f:\n",
    "            json.dump(new_json,f)\n",
    "    elif save_to is not None:\n",
    "        with open(save_to,\"w\") as f:\n",
    "            json.dump(new_json,f)\n",
    "            \n",
    "    return new_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = '/mnt/ssd1/processed/industry-data/project-max/ml/cloud-factory-data/with-bg/binary-datasets/forwards/IP/earl-originals/ip-bg-forwards-train.json'\n",
    "# working = json.load(open(fp,'r'))\n",
    "# for i, img in enumerate(working['images']):\n",
    "#     print(i,img['id']-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_timestamps() missing 2 required positional arguments: 'translator' and 'caption_map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ec925b1fcbe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthin_json_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-dc7ccf390de4>\u001b[0m in \u001b[0;36mthin_json_unique\u001b[0;34m(working_json, seconds, save_here, save_to)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mconversion_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0muid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#         print(id, len(new_json['images'])+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworking\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a2014e2e3f2b>\u001b[0m in \u001b[0;36munique_instances\u001b[0;34m(input_json, seconds)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munique_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_timestamps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mimg_ids_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: extract_timestamps() missing 2 required positional arguments: 'translator' and 'caption_map'"
     ]
    }
   ],
   "source": [
    "json_path = '/data/abyss/projectmax/feature-detection/large-fromCF/alltogether/test.json.2'\n",
    "with open(json_path, 'r') as file:\n",
    "    old = json.load(file)\n",
    "new = thin_json_unique(json_path, seconds=5)\n",
    "print(len(old['images']), len(new['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_json_unique(json_path, seconds=5, save_here=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
