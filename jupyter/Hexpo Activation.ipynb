{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # Use CPU\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "from abyss_deep_learning.keras.activations import Hexpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = 1, 1, 1, 1\n",
    "input_shape = (100, 1)\n",
    "x_data = np.linspace(-2.5, 2.5, input_shape[0])[..., np.newaxis]\n",
    "\n",
    "with K.tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    x = K.tf.placeholder(K.tf.float32, shape=((None,) + input_shape[1:]),name='x')\n",
    "    feed_dict = {x: x_data}\n",
    "    hexpo_y = Hexpo._activation(x, a, b, c, d)\n",
    "    hexpo_dy = K.tf.gradients(hexpo_y, x)\n",
    "    result = sess.run([hexpo_y, hexpo_dy], feed_dict=feed_dict)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(feed_dict[x], result[0])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(feed_dict[x].squeeze(), np.array(result[1]).squeeze(), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "input_shape = (48, 64, 1)\n",
    "func = lambda x: np.sin(x) + 1\n",
    "x_train = np.random.uniform(-1, 1, size=((N,) + input_shape))\n",
    "x_test = np.random.uniform(-1, 1, size=((N,) + input_shape))\n",
    "y_train = func(x_train)\n",
    "y_test = func(x_test)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import PReLU\n",
    "def make_model(input_shape):\n",
    "    from keras.layers import Input, Dense\n",
    "    from keras.models import Model\n",
    "    a, b, c, d = 1, 1, 1, 1\n",
    "    x = Input(shape=input_shape)\n",
    "    y = Hexpo(shared_axes=(1, 2))(Dense(1)(x))\n",
    "    y = Hexpo(shared_axes=(1, 2))(Dense(1)(y))\n",
    "    return Model(x, y)\n",
    "\n",
    "model = make_model(input_shape)\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "model.fit(x_train, y_train, verbose=1, epochs=10, validation_split=0.1)\n",
    "y_pred = model.predict(x_test, batch_size=100)\n",
    "# y_train\n",
    "# plt.figure()\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(feed_dict[x], result[0])\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.semilogy(feed_dict[x].squeeze(), np.array(result[1]).squeeze(), 'r')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.get_config())\n",
    "\n",
    "for w in model.get_layer(name='hexpo_1').trainable_weights:\n",
    "    print(K.eval(w))\n",
    "    \n",
    "model.get_layer(name='hexpo_1').get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
